{
  "dataset_columns": [
    "Age",
    "Sex",
    "ChestPainType",
    "RestingBP",
    "Cholesterol",
    "FastingBS",
    "RestingECG",
    "MaxHR",
    "ExerciseAngina",
    "Oldpeak",
    "ST_Slope",
    "HeartDisease"
  ],
  "questions": [
    {
      "question": "Identify the numeric column that has the highest variance and treat it as the target variable. Then determine the three other numeric columns that show the largest absolute correlation with this target. Fit an ordinary least squares regression using these three columns as predictors for the target. Provide the results in a JSON object with exactly the following keys: \"target\" (the name of the target column), \"predictors\" (a list of the three predictor column names), \"r_squared\" (the R\u2011squared of the fitted model, rounded to 4 decimal places), \"adj_r_squared\" (the adjusted R\u2011squared, rounded to 4 decimal places), \"n_significant\" (the number of predictors whose p\u2011value is less than 0.05), \"coefficients\" (a dictionary mapping each predictor name to its regression coefficient, rounded to 4 decimal places), and \"p_values\" (a dictionary mapping each predictor name to its p\u2011value, rounded to 6 decimal places). Example format: {\"target\": \"price\", \"predictors\": [\"sqft\", \"bedrooms\", \"age\"], \"r_squared\": 0.7234, \"adj_r_squared\": 0.7156, \"n_significant\": 2, \"coefficients\": {\"sqft\": 123.45, \"bedrooms\": 5000.12, \"age\": -200.34}, \"p_values\": {\"sqft\": 0.000001, \"bedrooms\": 0.023456, \"age\": 0.156789}}",
      "hint": "Compute variance for each numeric column to select the target, then calculate absolute correlations with the target to pick the top three predictors before running an OLS regression.",
      "n_steps": 10,
      "difficulty": "VERY_HARD",
      "template_name": "multiple_regression_top_predictors",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 6 keys: \"target\" (column name), \"predictors\" (list of 3 column names), \"r_squared\" (rounded to 4 decimals), \"adj_r_squared\" (rounded to 4 decimals), \"n_significant\" (integer count of predictors with p < 0.05), \"coefficients\" (dict mapping predictor names to coefficients rounded to 4 decimals), and \"p_values\" (dict mapping predictor names to p-values rounded to 6 decimals). Example: {\"target\": \"price\", \"predictors\": [\"sqft\", \"bedrooms\", \"age\"], \"r_squared\": 0.7234, \"adj_r_squared\": 0.7156, \"n_significant\": 2, \"coefficients\": {\"sqft\": 123.45, \"bedrooms\": 5000.12, \"age\": -200.34}, \"p_values\": {\"sqft\": 0.000001, \"bedrooms\": 0.023456, \"age\": 0.156789}}",
      "ground_truth_hash": "2addb290ac542f0f",
      "_ground_truth": {
        "target": "Cholesterol",
        "predictors": [
          "FastingBS",
          "MaxHR",
          "HeartDisease"
        ],
        "r_squared": 0.1192,
        "adj_r_squared": 0.1163,
        "n_significant": 3,
        "coefficients": {
          "FastingBS": -54.2347,
          "MaxHR": 0.7034,
          "HeartDisease": -24.4347
        },
        "p_values": {
          "FastingBS": 0.0,
          "MaxHR": 2e-06,
          "HeartDisease": 0.001486
        }
      },
      "_template": "multiple_regression_top_predictors"
    },
    {
      "question": "Among all numeric columns, find the column with the highest absolute skewness. For this most skewed column, report its name, the absolute skewness value (rounded to 4 decimal places), the original sample mean (rounded to 4 decimal places), the lower and upper bounds of a 95% confidence interval for the mean obtained via bootstrap resampling with 1000 samples (each bound rounded to 4 decimal places), the bootstrap standard error of the mean (rounded to 4 decimal places), and the number of bootstrap samples used. Provide your answer as a JSON object with exactly the following keys: \"column\" (string), \"skewness\" (float), \"mean\" (float), \"ci_lower\" (float), \"ci_upper\" (float), \"std_error\" (float), and \"n_bootstrap\" (integer). Example format: {\"column\": \"income\", \"skewness\": 2.3456, \"mean\": 50000.1234, \"ci_lower\": 48500.5678, \"ci_upper\": 51500.9012, \"std_error\": 750.3456, \"n_bootstrap\": 1000}.",
      "hint": "Compute the skewness of each numeric column, take the absolute values, and select the column with the largest one. Then use bootstrap sampling (1000 resamples) on that column to estimate the mean, its confidence interval, and standard error.",
      "n_steps": 9,
      "difficulty": "VERY_HARD",
      "template_name": "bootstrap_ci_discovered",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 7 keys: \"column\" (name of most skewed column), \"skewness\" (rounded to 4 decimals), \"mean\" (rounded to 4 decimals), \"ci_lower\" (lower bound of 95% CI, rounded to 4 decimals), \"ci_upper\" (upper bound, rounded to 4 decimals), \"std_error\" (bootstrap standard error, rounded to 4 decimals), and \"n_bootstrap\" (integer, the number of bootstrap samples). Example: {\"column\": \"income\", \"skewness\": 2.3456, \"mean\": 50000.1234, \"ci_lower\": 48500.5678, \"ci_upper\": 51500.9012, \"std_error\": 750.3456, \"n_bootstrap\": 1000}",
      "ground_truth_hash": "4cdfeb0df8d9528d",
      "_ground_truth": {
        "column": "FastingBS",
        "skewness": 1.2645,
        "mean": 0.2331,
        "ci_lower": 0.2059,
        "ci_upper": 0.2593,
        "std_error": 0.0138,
        "n_bootstrap": 1000
      },
      "_template": "bootstrap_ci_discovered"
    },
    {
      "question": "Identify the numeric column that has the highest variance among all numeric columns in the dataset. Then, from the categorical columns that contain between 3 and 10 distinct categories, select one (e.g., the first that meets this criterion) to serve as a grouping variable. Using the selected numeric column as the target and the chosen categorical column as the grouping factor, conduct a one\u2011way ANOVA. Provide your answer as a JSON object with exactly the following 11 keys:\n- \"target_column\": name of the numeric column with highest variance\n- \"grouping_column\": name of the categorical column used for grouping\n- \"n_groups\": integer count of distinct groups\n- \"f_statistic\": F\u2011statistic rounded to 4 decimal places\n- \"p_value\": p\u2011value rounded to 6 decimal places\n- \"significant\": true if the p\u2011value is less than 0.05, otherwise false\n- \"best_group\": the group with the highest mean of the target variable\n- \"best_mean\": that mean rounded to 4 decimal places\n- \"worst_group\": the group with the lowest mean of the target variable\n- \"worst_mean\": that mean rounded to 4 decimal places\n- \"eta_squared\": effect size (eta\u2011squared) rounded to 4 decimal places.\nThe JSON you return should match this exact structure.",
      "hint": "Start by calculating the variance of each numeric column to find the one with the greatest spread, then count unique values in each categorical column to locate a column with 3\u201110 categories before performing the ANOVA.",
      "n_steps": 9,
      "difficulty": "VERY_HARD",
      "template_name": "anova_discovered_groups",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 11 keys: \"target_column\", \"grouping_column\", \"n_groups\" (integer), \"f_statistic\" (rounded to 4 decimals), \"p_value\" (rounded to 6 decimals), \"significant\" (boolean), \"best_group\" (category with highest mean), \"best_mean\" (rounded to 4 decimals), \"worst_group\" (category with lowest mean), \"worst_mean\" (rounded to 4 decimals), and \"eta_squared\" (effect size, rounded to 4 decimals). Example: {\"target_column\": \"sales\", \"grouping_column\": \"region\", \"n_groups\": 4, \"f_statistic\": 15.2345, \"p_value\": 0.000012, \"significant\": true, \"best_group\": \"West\", \"best_mean\": 1234.5678, \"worst_group\": \"East\", \"worst_mean\": 890.1234, \"eta_squared\": 0.1523}",
      "ground_truth_hash": "6022ac77c6220272",
      "_ground_truth": {
        "target_column": "Cholesterol",
        "grouping_column": "ChestPainType",
        "n_groups": 4,
        "f_statistic": 7.9697,
        "p_value": 3e-05,
        "significant": "True",
        "best_group": "ATA",
        "best_mean": 233.0462,
        "worst_group": "ASY",
        "worst_mean": 186.6452,
        "eta_squared": 0.0255
      },
      "_template": "anova_discovered_groups"
    },
    {
      "question": "Identify the numeric column with the highest variance in the dataset and treat it as the target variable. Among the remaining numeric columns, find the one that has the highest absolute Pearson correlation with this target. Compute the absolute correlation value, fit an ordinary least squares regression predicting the target from this best predictor (using rows without missing values), and report the target column name, the best predictor column name, the correlation (rounded to 3 decimals), the R\u2011squared of the regression (rounded to 4 decimals), the regression coefficient for the predictor (rounded to 4 decimals), and the p\u2011value for that coefficient (rounded to 6 decimals). Provide your answer as a JSON object with keys \"target\", \"best_predictor\", \"correlation\", \"r_squared\", \"coefficient\", and \"p_value\".",
      "hint": "Compute variances of all numeric columns to pick the target, then calculate absolute correlations with the remaining numeric columns to find the strongest predictor, and finally fit a simple OLS model to obtain R\u2011squared, coefficient, and p\u2011value.",
      "n_steps": 8,
      "difficulty": "HARD",
      "template_name": "regression_most_predictive",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 6 keys: \"target\" (column name), \"best_predictor\" (column name), \"correlation\" (rounded to 3 decimals), \"r_squared\" (rounded to 4 decimals), \"coefficient\" (rounded to 4 decimals), and \"p_value\" (rounded to 6 decimals). Example: {\"target\": \"price\", \"best_predictor\": \"sqft\", \"correlation\": 0.834, \"r_squared\": 0.6956, \"coefficient\": 135.2847, \"p_value\": 0.000001}",
      "ground_truth_hash": "c4753fafe6c088a4",
      "_ground_truth": {
        "target": "Cholesterol",
        "best_predictor": "FastingBS",
        "correlation": 0.261,
        "r_squared": 0.0681,
        "coefficient": -67.4784,
        "p_value": 0.0
      },
      "_template": "regression_most_predictive"
    },
    {
      "question": "Using the given dataset, identify the numeric column with the highest variance. Then find a categorical column that contains exactly two distinct values (if none exists, create a binary grouping from another numeric column by splitting at its median). Using this binary grouping, compute the mean of the high\u2011variance numeric column for each of the two groups, perform an independent two\u2011sample t\u2011test, and determine whether the difference is statistically significant at \u03b1 = 0.05. Provide your answer as a JSON object with exactly nine keys: \"target_column\", \"grouping_column\", \"group1\", \"group2\", \"mean1\" (rounded to 4 decimal places), \"mean2\" (rounded to 4 decimal places), \"t_statistic\" (rounded to 4 decimal places), \"p_value\" (rounded to 6 decimal places), and \"significant\" (boolean, true if p < 0.05).",
      "hint": "First compute variances of all numeric columns to pick the target column, then look for a categorical column with two unique categories to use as the grouping variable.",
      "n_steps": 8,
      "difficulty": "HARD",
      "template_name": "ttest_discovered_groups",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 9 keys: \"target_column\", \"grouping_column\", \"group1\", \"group2\", \"mean1\" (rounded to 4 decimals), \"mean2\" (rounded to 4 decimals), \"t_statistic\" (rounded to 4 decimals), \"p_value\" (rounded to 6 decimals), and \"significant\" (boolean, true if p < 0.05). Example: {\"target_column\": \"score\", \"grouping_column\": \"gender\", \"group1\": \"M\", \"group2\": \"F\", \"mean1\": 75.4321, \"mean2\": 78.1234, \"t_statistic\": -2.3456, \"p_value\": 0.019234, \"significant\": true}",
      "ground_truth_hash": "5bf30a22ece9dcd7",
      "_ground_truth": {
        "target_column": "Cholesterol",
        "grouping_column": "Sex",
        "group1": "M",
        "group2": "F",
        "mean1": 187.5131,
        "mean2": 241.1969,
        "t_statistic": -6.1809,
        "p_value": 0.0,
        "significant": "True"
      },
      "_template": "ttest_discovered_groups"
    },
    {
      "question": "Identify the numeric column that has the highest variance in the dataset. Test whether the values in this column follow a normal distribution. If the distribution is normal, output a JSON object with keys \"distribution\" set to \"normal\", \"mean\" (rounded to 3 decimal places), and \"std\" (rounded to 3 decimal places). If the distribution is not normal, output a JSON object with keys \"distribution\" set to \"non-normal\", \"median\" (rounded to 3 decimal places), and \"iqr\" (rounded to 3 decimal places, where IQR = Q3 - Q1). The answer must follow exactly one of these two JSON formats.",
      "hint": "First compute variances of all numeric columns to find the one with the maximum variance, then apply a normality test (e.g., Shapiro\u2011Wilk) on its values, sampling if the sample size is large.",
      "n_steps": 5,
      "difficulty": "HARD",
      "template_name": "conditional_normality",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 3 keys. If normal: {\"distribution\": \"normal\", \"mean\": <number>, \"std\": <number>}. If non-normal: {\"distribution\": \"non-normal\", \"median\": <number>, \"iqr\": <number>}. The \"iqr\" value is Q3 minus Q1 as a single number. All numeric values rounded to 3 decimal places.",
      "ground_truth_hash": "bfce6ce94f1e3b3a",
      "_ground_truth": {
        "distribution": "non-normal",
        "median": 223.0,
        "iqr": 93.75
      },
      "_template": "conditional_normality"
    },
    {
      "question": "In the dataset, identify the numeric column that has the highest variance. Then select a categorical column that contains a moderate number of distinct categories (between 2 and 20 unique values). Compute the mean of the high\u2011variance numeric column for each category of the chosen categorical column and determine which category yields the highest mean. Provide your answer as a JSON object with exactly four keys: \"category_column\" (the name of the categorical column used), \"best_category\" (the category value with the highest mean), \"target_column\" (the name of the numeric column with the highest variance), and \"mean_value\" (the highest mean rounded to three decimal places).",
      "hint": "First calculate the variance of all numeric columns to find the one with the greatest spread, then look at categorical columns and pick one with a reasonable cardinality, finally group by that column and compute the average of the selected numeric column to locate the category with the maximum mean.",
      "n_steps": 5,
      "difficulty": "HARD",
      "template_name": "category_highest_target_mean",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 4 keys: \"category_column\" (the grouping column name), \"best_category\" (the category value with highest mean), \"target_column\" (the numeric column analyzed), and \"mean_value\" (rounded to 3 decimal places). Example: {\"category_column\": \"region\", \"best_category\": \"West\", \"target_column\": \"sales\", \"mean_value\": 1234.567}",
      "ground_truth_hash": "128e9f34e2e8edfa",
      "_ground_truth": {
        "category_column": "Sex",
        "best_category": "F",
        "target_column": "Cholesterol",
        "mean_value": 241.197
      },
      "_template": "category_highest_target_mean"
    },
    {
      "question": "Identify the pair of numeric columns that have the strongest absolute correlation in the dataset. Report the names of these two columns (alphabetically sorted), the original correlation value (rounded to three decimals), the number of rows removed as outliers when filtering each column to values within three standard deviations of its mean, and the correlation after this outlier removal (rounded to three decimals). Provide your answer as a JSON object with keys \"columns\" (list of two column names, alphabetically sorted), \"original_correlation\" (rounded to 3 decimals), \"outliers_removed\" (integer), and \"clean_correlation\" (rounded to 3 decimals).",
      "hint": "Compute the absolute correlation matrix for all numeric columns to find the highest pair, then apply a 3\u2011\u03c3 filter on both columns, count the rows excluded, and recompute the correlation on the remaining data.",
      "n_steps": 5,
      "difficulty": "HARD",
      "template_name": "correlation_after_outlier_removal",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 4 keys: \"columns\" (list of 2 column names, alphabetically sorted), \"original_correlation\" (rounded to 3 decimals), \"outliers_removed\" (integer count), and \"clean_correlation\" (rounded to 3 decimals). Example: {\"columns\": [\"col_a\", \"col_b\"], \"original_correlation\": 0.847, \"outliers_removed\": 12, \"clean_correlation\": 0.891}",
      "ground_truth_hash": "06c9bc2d4b1076b3",
      "_ground_truth": {
        "columns": [
          "HeartDisease",
          "Oldpeak"
        ],
        "original_correlation": 0.404,
        "outliers_removed": 7,
        "clean_correlation": 0.416
      },
      "_template": "correlation_after_outlier_removal"
    },
    {
      "question": "Which pair of numeric columns exhibits the highest absolute correlation? Provide your answer as a JSON object with keys \"columns\" (a list of the two column names, alphabetically sorted) and \"correlation\" (the correlation coefficient rounded to 3 decimal places).",
      "hint": "Calculate the absolute correlation matrix for all numeric columns, ignore the diagonal, and identify the maximum off\u2011diagonal value.",
      "n_steps": 4,
      "difficulty": "MEDIUM",
      "template_name": "strongest_correlation",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly two keys: \"columns\" (a list of the two column names, alphabetically sorted) and \"correlation\" (the correlation coefficient rounded to 3 decimal places). Example: {\"columns\": [\"col_a\", \"col_b\"], \"correlation\": 0.847}",
      "ground_truth_hash": "dd7bdaec29a1898f",
      "_ground_truth": {
        "columns": [
          "HeartDisease",
          "Oldpeak"
        ],
        "correlation": 0.404
      },
      "_template": "strongest_correlation"
    },
    {
      "question": "Among all numeric columns, identify the pair (excluding a column with itself) that has the smallest non-zero absolute correlation. Provide your answer as a JSON object with keys \"columns\" (a list of the two column names sorted alphabetically) and \"correlation\" (the absolute correlation value rounded to three decimal places).",
      "hint": "Compute the absolute correlation matrix for the numeric columns, ignore the diagonal entries, and find the minimum correlation value.",
      "n_steps": 4,
      "difficulty": "MEDIUM",
      "template_name": "weakest_correlation",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly two keys: \"columns\" (a list of the two column names, alphabetically sorted) and \"correlation\" (the absolute correlation value rounded to 3 decimal places). Example: {\"columns\": [\"col_a\", \"col_b\"], \"correlation\": 0.012}",
      "ground_truth_hash": "b567a39c001ceef5",
      "_ground_truth": {
        "columns": [
          "Cholesterol",
          "Oldpeak"
        ],
        "correlation": 0.05
      },
      "_template": "weakest_correlation"
    },
    {
      "question": "Considering only the numeric columns in the dataset, determine (1) how many of those columns contain at least one outlier, where an outlier is defined as a value whose absolute deviation from the column mean exceeds three times the column's standard deviation, and (2) the total number of outlier values across all numeric columns. Provide your answer as a JSON object with exactly two keys: \"columns_with_outliers\" (integer) and \"total_outliers\" (integer), e.g., {\"columns_with_outliers\": 3, \"total_outliers\": 47}.",
      "hint": "For each numeric column compute its mean and standard deviation, count values beyond 3\u202f\u00d7\u202fstd, then sum the per\u2011column counts and count how many columns have a non\u2011zero count.",
      "n_steps": 4,
      "difficulty": "MEDIUM",
      "template_name": "count_outlier_columns",
      "template_params": {
        "z_threshold": 3.0
      },
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 2 keys: \"columns_with_outliers\" (integer count of columns containing at least one outlier) and \"total_outliers\" (integer total count of outlier values across all columns). Example: {\"columns_with_outliers\": 3, \"total_outliers\": 47}",
      "ground_truth_hash": "b95f6a22ea78fb2f",
      "_ground_truth": {
        "columns_with_outliers": 4,
        "total_outliers": 19
      },
      "_template": "count_outlier_columns"
    },
    {
      "question": "How many numeric columns contain at least one outlier (a value whose absolute deviation from the column mean exceeds 2.5 times the column standard deviation), and what is the total number of outlier values across all numeric columns? Provide your answer as a JSON object with keys \"columns_with_outliers\" (integer) and \"total_outliers\" (integer).",
      "hint": "For each numeric column compute its mean and standard deviation, count rows where |value\u2011mean| > 2.5\u202f\u00d7\u202fstd, then tally how many columns have a non\u2011zero count and sum all counts.",
      "n_steps": 4,
      "difficulty": "MEDIUM",
      "template_name": "count_outlier_columns",
      "template_params": {
        "z_threshold": 2.5
      },
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 2 keys: \"columns_with_outliers\" (integer count of columns containing at least one outlier) and \"total_outliers\" (integer total count of outlier values across all columns). Example: {\"columns_with_outliers\": 3, \"total_outliers\": 47}",
      "ground_truth_hash": "1b6a01e82547f901",
      "_ground_truth": {
        "columns_with_outliers": 5,
        "total_outliers": 63
      },
      "_template": "count_outlier_columns"
    },
    {
      "question": "What is the mean of the numeric column with the highest variance? Provide your answer as a single number rounded to 3 decimal places.",
      "hint": "Calculate the variance for each numeric column, identify the column with the largest variance, then compute the mean of that column.",
      "n_steps": 3,
      "difficulty": "MEDIUM",
      "template_name": "max_variance_mean",
      "template_params": null,
      "output_type": "scalar",
      "output_schema": "A single number (the mean), rounded to 3 decimal places",
      "ground_truth_hash": "9cb18cf82ddd8632",
      "_ground_truth": 198.8,
      "_template": "max_variance_mean"
    },
    {
      "question": "What is the standard deviation of the numeric column that has the smallest mean? Provide your answer as a single number rounded to 3 decimal places.",
      "hint": "Calculate the mean for each numeric column, find the column with the lowest mean, then compute that column's standard deviation.",
      "n_steps": 3,
      "difficulty": "MEDIUM",
      "template_name": "min_mean_column_std",
      "template_params": null,
      "output_type": "scalar",
      "output_schema": "A single number (the standard deviation), rounded to 3 decimal places",
      "ground_truth_hash": "1632b097f34d9c16",
      "_ground_truth": 0.423,
      "_template": "min_mean_column_std"
    },
    {
      "question": "How many columns in the dataset have more than 5% missing values? Provide your answer as a JSON object with exactly two keys: \"count\" (an integer) and \"columns\" (an alphabetically sorted list of the column names that meet this condition).",
      "hint": "Calculate the missing\u2011value percentage for each column and count those exceeding the 5% threshold.",
      "n_steps": 3,
      "difficulty": "EASY",
      "template_name": "count_high_missing_columns",
      "template_params": {
        "missing_threshold": 5.0
      },
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 2 keys: \"count\" (integer) and \"columns\" (list of column names, alphabetically sorted). Example: {\"count\": 3, \"columns\": [\"col_a\", \"col_b\", \"col_c\"]}",
      "ground_truth_hash": "2c42c4348e535666",
      "_ground_truth": {
        "count": 0,
        "columns": []
      },
      "_template": "count_high_missing_columns"
    },
    {
      "question": "Identify how many columns in the dataset have more than 10% missing values and list the names of those columns in alphabetical order. Provide your answer as a JSON object with exactly two keys: \"count\" (an integer) and \"columns\" (a list of column names, sorted alphabetically).",
      "hint": "Calculate the percentage of missing entries for each column, then filter to keep only those exceeding a 10% threshold.",
      "n_steps": 3,
      "difficulty": "EASY",
      "template_name": "count_high_missing_columns",
      "template_params": {
        "missing_threshold": 10.0
      },
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 2 keys: \"count\" (integer) and \"columns\" (list of column names, alphabetically sorted). Example: {\"count\": 3, \"columns\": [\"col_a\", \"col_b\", \"col_c\"]}",
      "ground_truth_hash": "2c42c4348e535666",
      "_ground_truth": {
        "count": 0,
        "columns": []
      },
      "_template": "count_high_missing_columns"
    }
  ]
}