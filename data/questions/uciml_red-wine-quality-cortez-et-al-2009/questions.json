{
  "dataset_columns": [
    "fixed acidity",
    "volatile acidity",
    "citric acid",
    "residual sugar",
    "chlorides",
    "free sulfur dioxide",
    "total sulfur dioxide",
    "density",
    "pH",
    "sulphates",
    "alcohol",
    "quality"
  ],
  "questions": [
    {
      "question": "Using the provided dataset, perform the following steps and return the results in the exact JSON format shown below:\n1. Identify the numeric column with the highest variance and treat it as the target variable.\n2. Among the remaining numeric columns, find the three that have the largest absolute correlation with this target.\n3. Fit an ordinary least squares (OLS) regression model predicting the target from these three predictors.\n4. Report:\n   - the name of the target column,\n   - the list of the three predictor column names (ordered by decreasing absolute correlation with the target),\n   - the model's R-squared and adjusted R-squared (rounded to 4 decimal places),\n   - the count of predictors whose p\u2011value is less than 0.05,\n   - for each predictor, its regression coefficient (rounded to 4 decimal places) and its p\u2011value (rounded to 6 decimal places).\n\nProvide the answer as a JSON object with the following keys:\n```json\n{\"target\": \"<target column name>\", \"predictors\": [\"<predictor1>\", \"<predictor2>\", \"<predictor3>\"], \"r_squared\": <float>, \"adj_r_squared\": <float>, \"n_significant\": <int>, \"coefficients\": {\"<predictor1>\": <float>, \"<predictor2>\": <float>, \"<predictor3>\": <float>}, \"p_values\": {\"<predictor1>\": <float>, \"<predictor2>\": <float>, \"<predictor3>\": <float>}}\n```",
      "hint": "Compute variances to locate the highest\u2011variance numeric column, then use absolute correlations to rank the remaining numeric columns. Fit the OLS model (e.g., with statsmodels) and extract R-squared, adjusted R-squared, coefficients, and p\u2011values.",
      "n_steps": 10,
      "difficulty": "VERY_HARD",
      "template_name": "multiple_regression_top_predictors",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 6 keys: \"target\" (column name), \"predictors\" (list of 3 column names), \"r_squared\" (rounded to 4 decimals), \"adj_r_squared\" (rounded to 4 decimals), \"n_significant\" (integer count of predictors with p < 0.05), \"coefficients\" (dict mapping predictor names to coefficients rounded to 4 decimals), and \"p_values\" (dict mapping predictor names to p-values rounded to 6 decimals). Example: {\"target\": \"price\", \"predictors\": [\"sqft\", \"bedrooms\", \"age\"], \"r_squared\": 0.7234, \"adj_r_squared\": 0.7156, \"n_significant\": 2, \"coefficients\": {\"sqft\": 123.45, \"bedrooms\": 5000.12, \"age\": -200.34}, \"p_values\": {\"sqft\": 0.000001, \"bedrooms\": 0.023456, \"age\": 0.156789}}",
      "ground_truth_hash": "9ba59bceb123a704",
      "_ground_truth": {
        "target": "total sulfur dioxide",
        "predictors": [
          "free sulfur dioxide",
          "alcohol",
          "residual sugar"
        ],
        "r_squared": 0.4791,
        "adj_r_squared": 0.4782,
        "n_significant": 3,
        "coefficients": {
          "free sulfur dioxide": 2.0105,
          "alcohol": -5.0959,
          "residual sugar": 2.109
        },
        "p_values": {
          "free sulfur dioxide": 0.0,
          "alcohol": 0.0,
          "residual sugar": 1e-06
        }
      },
      "_template": "multiple_regression_top_predictors"
    },
    {
      "question": "Identify the numeric column that has the highest absolute skewness. For that column, report its name, the absolute skewness (rounded to 4 decimals), the sample mean (rounded to 4 decimals), the lower and upper bounds of a 95% confidence interval for the mean obtained via bootstrap resampling with 1000 samples (both rounded to 4 decimals), and the bootstrap standard error (rounded to 4 decimals). Provide your answer as a JSON object with exactly the following keys: \"column\" (string), \"skewness\" (float), \"mean\" (float), \"ci_lower\" (float), \"ci_upper\" (float), \"std_error\" (float), and \"n_bootstrap\" (integer, set to 1000).",
      "hint": "Compute the skewness for each numeric column, pick the one with the largest absolute value, then use bootstrap (1000 resamples) on its non\u2011missing values to estimate the mean, its 95% CI, and the standard error.",
      "n_steps": 9,
      "difficulty": "VERY_HARD",
      "template_name": "bootstrap_ci_discovered",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 7 keys: \"column\" (name of most skewed column), \"skewness\" (rounded to 4 decimals), \"mean\" (rounded to 4 decimals), \"ci_lower\" (lower bound of 95% CI, rounded to 4 decimals), \"ci_upper\" (upper bound, rounded to 4 decimals), \"std_error\" (bootstrap standard error, rounded to 4 decimals), and \"n_bootstrap\" (integer, the number of bootstrap samples). Example: {\"column\": \"income\", \"skewness\": 2.3456, \"mean\": 50000.1234, \"ci_lower\": 48500.5678, \"ci_upper\": 51500.9012, \"std_error\": 750.3456, \"n_bootstrap\": 1000}",
      "ground_truth_hash": "acf108dd7c2c6bd5",
      "_ground_truth": {
        "column": "chlorides",
        "skewness": 5.6803,
        "mean": 0.0875,
        "ci_lower": 0.0853,
        "ci_upper": 0.0898,
        "std_error": 0.0012,
        "n_bootstrap": 1000
      },
      "_template": "bootstrap_ci_discovered"
    },
    {
      "question": "In the given dataset, consider only the numeric columns. First, determine which numeric column has the highest variance and treat it as the target variable. Next, among the remaining numeric columns, identify the one that shows the strongest absolute Pearson correlation with this target. Using these two columns, fit an ordinary least squares regression model of the target on the predictor (including an intercept). Report the following, rounded as indicated, in a JSON object with exactly six keys: \n- \"target\": name of the column with the highest variance, \n- \"best_predictor\": name of the column most correlated with the target, \n- \"correlation\": absolute correlation between them, rounded to 3 decimal places, \n- \"r_squared\": R\u2011squared of the regression, rounded to 4 decimal places, \n- \"coefficient\": regression coefficient for the predictor, rounded to 4 decimal places, \n- \"p_value\": p\u2011value for the predictor\u2019s coefficient, rounded to 6 decimal places. \nExample format: {\"target\": \"...\", \"best_predictor\": \"...\", \"correlation\": 0.123, \"r_squared\": 0.4567, \"coefficient\": 1.2345, \"p_value\": 0.000001}.",
      "hint": "Start by computing the variance of each numeric column to find the target, then calculate absolute correlations with the other numeric columns to pick the best predictor, and finally run a simple OLS regression to obtain R\u2011squared, coefficient and p\u2011value.",
      "n_steps": 8,
      "difficulty": "HARD",
      "template_name": "regression_most_predictive",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 6 keys: \"target\" (column name), \"best_predictor\" (column name), \"correlation\" (rounded to 3 decimals), \"r_squared\" (rounded to 4 decimals), \"coefficient\" (rounded to 4 decimals), and \"p_value\" (rounded to 6 decimals). Example: {\"target\": \"price\", \"best_predictor\": \"sqft\", \"correlation\": 0.834, \"r_squared\": 0.6956, \"coefficient\": 135.2847, \"p_value\": 0.000001}",
      "ground_truth_hash": "f07af0abfbf9aee9",
      "_ground_truth": {
        "target": "total sulfur dioxide",
        "best_predictor": "free sulfur dioxide",
        "correlation": 0.668,
        "r_squared": 0.4458,
        "coefficient": 2.0997,
        "p_value": 0.0
      },
      "_template": "regression_most_predictive"
    },
    {
      "question": "Identify the numeric column that has the highest variance in the dataset. Then, using any other numeric column, create a binary grouping column by labeling rows as \"low\" if the value is less than or equal to that column's median and \"high\" otherwise. For the two groups defined by this binary column, compute the mean of the high\u2011variance numeric column for each group, perform an independent two\u2011sample t\u2011test, and determine if the difference is statistically significant at \u03b1 = 0.05. Provide your answer as a JSON object with exactly nine keys:\n\n- \"target_column\": name of the numeric column with highest variance (string)\n- \"grouping_column\": name of the binary grouping column you created (string)\n- \"group1\": label of the first group (string, either \"low\" or \"high\")\n- \"group2\": label of the second group (string, the other label)\n- \"mean1\": mean of the target column for group1, rounded to 4 decimal places (number)\n- \"mean2\": mean of the target column for group2, rounded to 4 decimal places (number)\n- \"t_statistic\": t\u2011statistic from the t\u2011test, rounded to 4 decimal places (number)\n- \"p_value\": p\u2011value from the t\u2011test, rounded to 6 decimal places (number)\n- \"significant\": true if the p\u2011value is less than 0.05, otherwise false (boolean)\n\nExample format: {\"target_column\": \"colA\", \"grouping_column\": \"_binary_group\", \"group1\": \"low\", \"group2\": \"high\", \"mean1\": 12.3456, \"mean2\": 23.4567, \"t_statistic\": -2.3456, \"p_value\": 0.019234, \"significant\": true}",
      "hint": "First compute the variance of every numeric column to find the one with the largest value. Then pick a different numeric column, calculate its median, and split the rows into \"low\" and \"high\" based on that median to form the binary grouping column.",
      "n_steps": 8,
      "difficulty": "HARD",
      "template_name": "ttest_discovered_groups",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 9 keys: \"target_column\", \"grouping_column\", \"group1\", \"group2\", \"mean1\" (rounded to 4 decimals), \"mean2\" (rounded to 4 decimals), \"t_statistic\" (rounded to 4 decimals), \"p_value\" (rounded to 6 decimals), and \"significant\" (boolean, true if p < 0.05). Example: {\"target_column\": \"score\", \"grouping_column\": \"gender\", \"group1\": \"M\", \"group2\": \"F\", \"mean1\": 75.4321, \"mean2\": 78.1234, \"t_statistic\": -2.3456, \"p_value\": 0.019234, \"significant\": true}",
      "ground_truth_hash": "e062ba0473be6a5f",
      "_ground_truth": {
        "target_column": "total sulfur dioxide",
        "grouping_column": "_binary_group",
        "group1": "low",
        "group2": "high",
        "mean1": 48.4412,
        "mean2": 44.4112,
        "t_statistic": 2.4527,
        "p_value": 0.014285,
        "significant": "True"
      },
      "_template": "ttest_discovered_groups"
    },
    {
      "question": "Identify the numeric column with the highest variance in the dataset. Assess whether this column follows a normal distribution (e.g., using a Shapiro\u2011Wilk test). If it is normal, provide a JSON object with keys \"distribution\": \"normal\", \"mean\": <number>, and \"std\": <number>. If it is not normal, provide a JSON object with keys \"distribution\": \"non-normal\", \"median\": <number>, and \"iqr\": <number>. Round all numeric values to three decimal places.",
      "hint": "First compute the variance of each numeric column to find the one with the maximum variance, then perform a normality test on that column to decide which summary statistics to report.",
      "n_steps": 5,
      "difficulty": "HARD",
      "template_name": "conditional_normality",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 3 keys. If normal: {\"distribution\": \"normal\", \"mean\": <number>, \"std\": <number>}. If non-normal: {\"distribution\": \"non-normal\", \"median\": <number>, \"iqr\": <number>}. The \"iqr\" value is Q3 minus Q1 as a single number. All numeric values rounded to 3 decimal places.",
      "ground_truth_hash": "b6c72e1b0adf168c",
      "_ground_truth": {
        "distribution": "non-normal",
        "median": 38.0,
        "iqr": 40.0
      },
      "_template": "conditional_normality"
    },
    {
      "question": "In the given dataset, find the pair of numeric columns that exhibit the strongest absolute correlation. Then, remove rows that are outliers (more than three standard deviations away from the mean) in both of those columns, and recompute the correlation on the cleaned data. Provide your answer as a JSON object with exactly four keys: \"columns\" (a list of the two column names sorted alphabetically), \"original_correlation\" (the correlation before outlier removal, rounded to three decimal places), \"outliers_removed\" (the number of rows removed as outliers, as an integer), and \"clean_correlation\" (the correlation after outlier removal, rounded to three decimal places).",
      "hint": "Start by computing the absolute correlation matrix for all numeric columns to locate the most correlated pair, then apply a 3\u2011standard\u2011deviation filter on both columns before calculating the new correlation.",
      "n_steps": 5,
      "difficulty": "HARD",
      "template_name": "correlation_after_outlier_removal",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 4 keys: \"columns\" (list of 2 column names, alphabetically sorted), \"original_correlation\" (rounded to 3 decimals), \"outliers_removed\" (integer count), and \"clean_correlation\" (rounded to 3 decimals). Example: {\"columns\": [\"col_a\", \"col_b\"], \"original_correlation\": 0.847, \"outliers_removed\": 12, \"clean_correlation\": 0.891}",
      "ground_truth_hash": "edcdc4e770600285",
      "_ground_truth": {
        "columns": [
          "fixed acidity",
          "pH"
        ],
        "original_correlation": 0.683,
        "outliers_removed": 20,
        "clean_correlation": -0.668
      },
      "_template": "correlation_after_outlier_removal"
    },
    {
      "question": "Which pair of numeric columns has the strongest absolute correlation? Provide your answer as a JSON object with keys \"columns\" (a list of the two column names, alphabetically sorted) and \"correlation\" (the correlation coefficient rounded to 3 decimal places).",
      "hint": "Compute the correlation matrix for all numeric columns and identify the off\u2011diagonal entry with the highest absolute value.",
      "n_steps": 4,
      "difficulty": "MEDIUM",
      "template_name": "strongest_correlation",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly two keys: \"columns\" (a list of the two column names, alphabetically sorted) and \"correlation\" (the correlation coefficient rounded to 3 decimal places). Example: {\"columns\": [\"col_a\", \"col_b\"], \"correlation\": 0.847}",
      "ground_truth_hash": "592ba83c590639b3",
      "_ground_truth": {
        "columns": [
          "fixed acidity",
          "pH"
        ],
        "correlation": 0.683
      },
      "_template": "strongest_correlation"
    },
    {
      "question": "Identify the pair of numeric columns that have the smallest non\u2011zero absolute correlation among all distinct numeric column pairs in the dataset. Provide your answer as a JSON object with exactly two keys: \"columns\" (a list of the two column names, alphabetically sorted) and \"correlation\" (the absolute correlation value rounded to 3 decimal places).",
      "hint": "Compute the absolute correlation matrix for the numeric columns, mask the diagonal and any zero values, then find the minimum remaining correlation.",
      "n_steps": 4,
      "difficulty": "MEDIUM",
      "template_name": "weakest_correlation",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly two keys: \"columns\" (a list of the two column names, alphabetically sorted) and \"correlation\" (the absolute correlation value rounded to 3 decimal places). Example: {\"columns\": [\"col_a\", \"col_b\"], \"correlation\": 0.012}",
      "ground_truth_hash": "e70ed9f779853088",
      "_ground_truth": {
        "columns": [
          "residual sugar",
          "volatile acidity"
        ],
        "correlation": 0.002
      },
      "_template": "weakest_correlation"
    },
    {
      "question": "For each numeric column in the dataset, consider a value an outlier if its absolute deviation from the column mean exceeds three times the column's standard deviation. How many numeric columns contain at least one outlier, and what is the total number of outlier values across all numeric columns? Provide your answer as a JSON object with keys \"columns_with_outliers\" (integer) and \"total_outliers\" (integer).",
      "hint": "Calculate the mean and standard deviation for every numeric column, count values that are farther than 3\u202f\u00d7\u202fstd from the mean, then sum the counts per column and also count how many columns have a non\u2011zero outlier count.",
      "n_steps": 4,
      "difficulty": "MEDIUM",
      "template_name": "count_outlier_columns",
      "template_params": {
        "z_threshold": 3.0
      },
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 2 keys: \"columns_with_outliers\" (integer count of columns containing at least one outlier) and \"total_outliers\" (integer total count of outlier values across all columns). Example: {\"columns_with_outliers\": 3, \"total_outliers\": 47}",
      "ground_truth_hash": "fa88050ed26164db",
      "_ground_truth": {
        "columns_with_outliers": 12,
        "total_outliers": 192
      },
      "_template": "count_outlier_columns"
    },
    {
      "question": "For each numeric column in the dataset, treat a value as an outlier if its absolute deviation from the column mean exceeds 2.5 times the column's standard deviation. How many numeric columns contain at least one outlier, and what is the total number of outlier values across all numeric columns? Provide your answer as a JSON object with keys \"columns_with_outliers\" (integer) and \"total_outliers\" (integer).",
      "hint": "Calculate the mean and standard deviation for each numeric column, then count rows where |value\u2011mean| > 2.5*std; aggregate counts per column and overall.",
      "n_steps": 4,
      "difficulty": "MEDIUM",
      "template_name": "count_outlier_columns",
      "template_params": {
        "z_threshold": 2.5
      },
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 2 keys: \"columns_with_outliers\" (integer count of columns containing at least one outlier) and \"total_outliers\" (integer total count of outlier values across all columns). Example: {\"columns_with_outliers\": 3, \"total_outliers\": 47}",
      "ground_truth_hash": "90839f42cafc7829",
      "_ground_truth": {
        "columns_with_outliers": 12,
        "total_outliers": 385
      },
      "_template": "count_outlier_columns"
    },
    {
      "question": "What is the mean of the numeric column with the highest variance? Provide your answer as a single number rounded to 3 decimal places.",
      "hint": "Calculate the variance for each numeric column, identify the column with the largest variance, and then compute its mean.",
      "n_steps": 3,
      "difficulty": "MEDIUM",
      "template_name": "max_variance_mean",
      "template_params": null,
      "output_type": "scalar",
      "output_schema": "A single number (the mean), rounded to 3 decimal places",
      "ground_truth_hash": "3960d9acc03db8c6",
      "_ground_truth": 46.468,
      "_template": "max_variance_mean"
    },
    {
      "question": "What is the standard deviation of the numeric column that has the lowest mean value? Provide your answer as a single number rounded to 3 decimal places.",
      "hint": "First compute the mean of each numeric column to identify the column with the smallest average, then calculate that column's standard deviation.",
      "n_steps": 3,
      "difficulty": "MEDIUM",
      "template_name": "min_mean_column_std",
      "template_params": null,
      "output_type": "scalar",
      "output_schema": "A single number (the standard deviation), rounded to 3 decimal places",
      "ground_truth_hash": "e5d3e87c0a26675a",
      "_ground_truth": 0.047,
      "_template": "min_mean_column_std"
    },
    {
      "question": "Determine how many columns in the dataset have more than 5% missing values and list the names of those columns. Provide your answer as a JSON object with keys \"count\" (integer) and \"columns\" (alphabetically sorted list of column names).",
      "hint": "Compute the missing\u2011value percentage for each column and select those exceeding the 5% threshold.",
      "n_steps": 3,
      "difficulty": "EASY",
      "template_name": "count_high_missing_columns",
      "template_params": {
        "missing_threshold": 5.0
      },
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 2 keys: \"count\" (integer) and \"columns\" (list of column names, alphabetically sorted). Example: {\"count\": 3, \"columns\": [\"col_a\", \"col_b\", \"col_c\"]}",
      "ground_truth_hash": "2c42c4348e535666",
      "_ground_truth": {
        "count": 0,
        "columns": []
      },
      "_template": "count_high_missing_columns"
    },
    {
      "question": "How many columns in the dataset have more than 10% missing values, and which columns are they? Provide your answer as a JSON object with exactly two keys: \"count\" (an integer) and \"columns\" (a list of column names sorted alphabetically).",
      "hint": "Calculate the missing-value percentage for each column and count those exceeding the 10% threshold.",
      "n_steps": 3,
      "difficulty": "EASY",
      "template_name": "count_high_missing_columns",
      "template_params": {
        "missing_threshold": 10.0
      },
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 2 keys: \"count\" (integer) and \"columns\" (list of column names, alphabetically sorted). Example: {\"count\": 3, \"columns\": [\"col_a\", \"col_b\", \"col_c\"]}",
      "ground_truth_hash": "2c42c4348e535666",
      "_ground_truth": {
        "count": 0,
        "columns": []
      },
      "_template": "count_high_missing_columns"
    }
  ]
}