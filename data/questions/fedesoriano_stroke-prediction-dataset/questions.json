{
  "dataset_columns": [
    "id",
    "gender",
    "age",
    "hypertension",
    "heart_disease",
    "ever_married",
    "work_type",
    "Residence_type",
    "avg_glucose_level",
    "bmi",
    "smoking_status",
    "stroke"
  ],
  "questions": [
    {
      "question": "In the given dataset, consider only the numeric columns. First, select the numeric column that has the highest variance and treat it as the target variable. Next, among the remaining numeric columns, identify the three that show the largest absolute correlation with this target. Using these three columns as predictors, fit an ordinary least squares (OLS) regression model to predict the target. Report the results in a JSON object with exactly the following keys:\n\n- \"target\": name of the target column (string)\n- \"predictors\": list of the three predictor column names (list of strings, ordered from most to least correlated)\n- \"r_squared\": R-squared of the fitted model, rounded to 4 decimal places (number)\n- \"adj_r_squared\": adjusted R-squared of the fitted model, rounded to 4 decimal places (number)\n- \"n_significant\": count of predictors whose p\u2011value is less than 0.05 (integer)\n- \"coefficients\": mapping from each predictor name to its regression coefficient, each rounded to 4 decimal places (object)\n- \"p_values\": mapping from each predictor name to its p\u2011value, each rounded to 6 decimal places (object)\n\nProvide the answer exactly in this JSON format.",
      "hint": "First compute variances of all numeric columns to pick the target, then use absolute correlations to rank the remaining columns, and finally apply an OLS regression (add a constant term) with those top three predictors.",
      "n_steps": 10,
      "difficulty": "VERY_HARD",
      "template_name": "multiple_regression_top_predictors",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 6 keys: \"target\" (column name), \"predictors\" (list of 3 column names), \"r_squared\" (rounded to 4 decimals), \"adj_r_squared\" (rounded to 4 decimals), \"n_significant\" (integer count of predictors with p < 0.05), \"coefficients\" (dict mapping predictor names to coefficients rounded to 4 decimals), and \"p_values\" (dict mapping predictor names to p-values rounded to 6 decimals). Example: {\"target\": \"price\", \"predictors\": [\"sqft\", \"bedrooms\", \"age\"], \"r_squared\": 0.7234, \"adj_r_squared\": 0.7156, \"n_significant\": 2, \"coefficients\": {\"sqft\": 123.45, \"bedrooms\": 5000.12, \"age\": -200.34}, \"p_values\": {\"sqft\": 0.000001, \"bedrooms\": 0.023456, \"age\": 0.156789}}",
      "ground_truth_hash": "2644c421c8d26c14",
      "_ground_truth": {
        "target": "id",
        "predictors": [
          "stroke",
          "hypertension",
          "age"
        ],
        "r_squared": 0.0001,
        "adj_r_squared": -0.0005,
        "n_significant": 0,
        "coefficients": {
          "stroke": 562.1107,
          "hypertension": 172.0977,
          "age": 1.3744
        },
        "p_values": {
          "stroke": 0.692569,
          "hypertension": 0.868708,
          "age": 0.921634
        }
      },
      "_template": "multiple_regression_top_predictors"
    },
    {
      "question": "Identify the numeric column that has the highest absolute skewness. For that column, compute the absolute skewness (rounded to 4 decimal places), the sample mean (rounded to 4 decimal places), a 95% confidence interval for the mean using 1000 bootstrap resamples (report the lower and upper bounds rounded to 4 decimal places), the bootstrap standard error (rounded to 4 decimal places), and the number of bootstrap samples used. Provide your answer as a JSON object with exactly the following keys: \"column\" (the column name), \"skewness\" (float, 4 decimals), \"mean\" (float, 4 decimals), \"ci_lower\" (float, 4 decimals), \"ci_upper\" (float, 4 decimals), \"std_error\" (float, 4 decimals), and \"n_bootstrap\" (integer).",
      "hint": "Calculate the skewness for each numeric column, select the one with the largest absolute value, then perform bootstrap sampling (1000 draws) on its non\u2011missing values to estimate the mean, its 95% CI, and the standard error.",
      "n_steps": 9,
      "difficulty": "VERY_HARD",
      "template_name": "bootstrap_ci_discovered",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 7 keys: \"column\" (name of most skewed column), \"skewness\" (rounded to 4 decimals), \"mean\" (rounded to 4 decimals), \"ci_lower\" (lower bound of 95% CI, rounded to 4 decimals), \"ci_upper\" (upper bound, rounded to 4 decimals), \"std_error\" (bootstrap standard error, rounded to 4 decimals), and \"n_bootstrap\" (integer, the number of bootstrap samples). Example: {\"column\": \"income\", \"skewness\": 2.3456, \"mean\": 50000.1234, \"ci_lower\": 48500.5678, \"ci_upper\": 51500.9012, \"std_error\": 750.3456, \"n_bootstrap\": 1000}",
      "ground_truth_hash": "858ed251688d8ec7",
      "_ground_truth": {
        "column": "stroke",
        "skewness": 4.1933,
        "mean": 0.0487,
        "ci_lower": 0.0429,
        "ci_upper": 0.0544,
        "std_error": 0.0031,
        "n_bootstrap": 1000
      },
      "_template": "bootstrap_ci_discovered"
    },
    {
      "question": "In the given dataset, locate the numeric column that exhibits the highest variance. Then identify a categorical column that contains between three and ten distinct categories. Using these two columns, conduct a one\u2011way ANOVA to assess whether the mean of the numeric column differs across the groups defined by the categorical column. Provide your results as a JSON object with exactly the following keys:\n\n- \"target_column\": name of the numeric column with highest variance\n- \"grouping_column\": name of the selected categorical column\n- \"n_groups\": number of distinct groups (integer)\n- \"f_statistic\": ANOVA F\u2011statistic, rounded to 4 decimal places\n- \"p_value\": ANOVA p\u2011value, rounded to 6 decimal places\n- \"significant\": true if p_value < 0.05, otherwise false\n- \"best_group\": category with the highest group mean\n- \"best_mean\": that highest mean, rounded to 4 decimal places\n- \"worst_group\": category with the lowest group mean\n- \"worst_mean\": that lowest mean, rounded to 4 decimal places\n- \"eta_squared\": effect size (eta\u2011squared), rounded to 4 decimal places\n\nReturn only the JSON object described above.",
      "hint": "Compute variances for all numeric columns to pick the target, then count unique values for each categorical column to find one with 3\u201110 categories. Use scipy.stats.f_oneway on the groups, then calculate group means, identify the extremes, and compute eta\u2011squared as (SS_between / SS_total).",
      "n_steps": 9,
      "difficulty": "VERY_HARD",
      "template_name": "anova_discovered_groups",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 11 keys: \"target_column\", \"grouping_column\", \"n_groups\" (integer), \"f_statistic\" (rounded to 4 decimals), \"p_value\" (rounded to 6 decimals), \"significant\" (boolean), \"best_group\" (category with highest mean), \"best_mean\" (rounded to 4 decimals), \"worst_group\" (category with lowest mean), \"worst_mean\" (rounded to 4 decimals), and \"eta_squared\" (effect size, rounded to 4 decimals). Example: {\"target_column\": \"sales\", \"grouping_column\": \"region\", \"n_groups\": 4, \"f_statistic\": 15.2345, \"p_value\": 0.000012, \"significant\": true, \"best_group\": \"West\", \"best_mean\": 1234.5678, \"worst_group\": \"East\", \"worst_mean\": 890.1234, \"eta_squared\": 0.1523}",
      "ground_truth_hash": "4b999cbd010250df",
      "_ground_truth": {
        "target_column": "id",
        "grouping_column": "gender",
        "n_groups": 3,
        "f_statistic": 0.4401,
        "p_value": 0.644007,
        "significant": "False",
        "best_group": "Other",
        "best_mean": 56156.0,
        "worst_group": "Female",
        "worst_mean": 36479.685,
        "eta_squared": 0.0002
      },
      "_template": "anova_discovered_groups"
    },
    {
      "question": "Identify the numeric column with the highest variance and treat it as the target variable. Among the remaining numeric columns, find the one that has the greatest absolute Pearson correlation with this target. Fit a simple ordinary least squares regression using this most\u2011correlated column as the sole predictor (after dropping any rows with missing values) to predict the target. Report the name of the target column, the name of the best predictor column, the absolute correlation between them (rounded to three decimal places), the R\u2011squared of the regression (rounded to four decimal places), the regression coefficient for the predictor (rounded to four decimal places), and the p\u2011value for that coefficient (rounded to six decimal places). Provide your answer as a JSON object with exactly the keys: \"target\", \"best_predictor\", \"correlation\", \"r_squared\", \"coefficient\", \"p_value\".",
      "hint": "Start by selecting all numeric columns, compute each column's variance to pick the target, then compute absolute correlations of the other numeric columns with this target, and finally run an OLS regression using statsmodels to obtain R\u2011squared, coefficient, and p\u2011value.",
      "n_steps": 8,
      "difficulty": "HARD",
      "template_name": "regression_most_predictive",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 6 keys: \"target\" (column name), \"best_predictor\" (column name), \"correlation\" (rounded to 3 decimals), \"r_squared\" (rounded to 4 decimals), \"coefficient\" (rounded to 4 decimals), and \"p_value\" (rounded to 6 decimals). Example: {\"target\": \"price\", \"best_predictor\": \"sqft\", \"correlation\": 0.834, \"r_squared\": 0.6956, \"coefficient\": 135.2847, \"p_value\": 0.000001}",
      "ground_truth_hash": "7145709584395521",
      "_ground_truth": {
        "target": "id",
        "best_predictor": "stroke",
        "correlation": 0.006,
        "r_squared": 0.0,
        "coefficient": 627.8319,
        "p_value": 0.647997
      },
      "_template": "regression_most_predictive"
    },
    {
      "question": "Identify the numeric column that has the highest variance among all numeric columns. Then locate a categorical column that contains exactly two distinct categories (if none exists, create a binary grouping by thresholding another numeric column). Using the two categories as groups, compute the mean of the high\u2011variance numeric column for each group and perform an independent two\u2011sample t\u2011test comparing the groups. Provide your answer as a JSON object with exactly nine keys: \"target_column\" (the name of the high\u2011variance numeric column), \"grouping_column\" (the name of the binary categorical column), \"group1\" (the first category name), \"group2\" (the second category name), \"mean1\" (mean for group1 rounded to 4 decimals), \"mean2\" (mean for group2 rounded to 4 decimals), \"t_statistic\" (t\u2011statistic rounded to 4 decimals), \"p_value\" (p\u2011value rounded to 6 decimals), and \"significant\" (boolean, true if p\u202f<\u202f0.05).",
      "hint": "Start by computing variances of all numeric columns to find the one with the largest spread, then look for a categorical column with exactly two unique values to serve as the grouping variable before calculating group means and the t\u2011test.",
      "n_steps": 8,
      "difficulty": "HARD",
      "template_name": "ttest_discovered_groups",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 9 keys: \"target_column\", \"grouping_column\", \"group1\", \"group2\", \"mean1\" (rounded to 4 decimals), \"mean2\" (rounded to 4 decimals), \"t_statistic\" (rounded to 4 decimals), \"p_value\" (rounded to 6 decimals), and \"significant\" (boolean, true if p < 0.05). Example: {\"target_column\": \"score\", \"grouping_column\": \"gender\", \"group1\": \"M\", \"group2\": \"F\", \"mean1\": 75.4321, \"mean2\": 78.1234, \"t_statistic\": -2.3456, \"p_value\": 0.019234, \"significant\": true}",
      "ground_truth_hash": "b57858eb1076fc43",
      "_ground_truth": {
        "target_column": "id",
        "grouping_column": "ever_married",
        "group1": "Yes",
        "group2": "No",
        "mean1": 36727.5145,
        "mean2": 36117.6733,
        "t_statistic": 0.9785,
        "p_value": 0.327879,
        "significant": "False"
      },
      "_template": "ttest_discovered_groups"
    },
    {
      "question": "Identify the numeric column with the highest variance in the dataset. Assess whether the values in this column follow a normal distribution using a significance level of 0.05. If the distribution is normal, report its mean and standard deviation; if it is not normal, report its median and interquartile range (IQR). Provide your answer as a JSON object with exactly three keys: for a normal distribution use {\"distribution\": \"normal\", \"mean\": <number>, \"std\": <number>}; for a non\u2011normal distribution use {\"distribution\": \"non-normal\", \"median\": <number>, \"iqr\": <number>}. Round all numeric values to three decimal places.",
      "hint": "First compute variances of all numeric columns to find the one with the largest variance, then apply a normality test (e.g., Shapiro\u2011Wilk) and calculate either mean/std or median/IQR based on the result.",
      "n_steps": 5,
      "difficulty": "HARD",
      "template_name": "conditional_normality",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 3 keys. If normal: {\"distribution\": \"normal\", \"mean\": <number>, \"std\": <number>}. If non-normal: {\"distribution\": \"non-normal\", \"median\": <number>, \"iqr\": <number>}. The \"iqr\" value is Q3 minus Q1 as a single number. All numeric values rounded to 3 decimal places.",
      "ground_truth_hash": "e2eb8057dfcf6740",
      "_ground_truth": {
        "distribution": "non-normal",
        "median": 36932.0,
        "iqr": 36940.75
      },
      "_template": "conditional_normality"
    },
    {
      "question": "Using the dataset, locate the categorical column that has a moderate number of distinct values (at least 2 and at most 20). Then, for each category in that column, compute the mean of the numeric column that shows the highest variance among all numeric columns. Identify the category with the highest mean. Provide your answer as a JSON object with exactly four keys: \"category_column\" (the name of the categorical column you selected), \"best_category\" (the category value with the highest mean), \"target_column\" (the numeric column with the highest variance), and \"mean_value\" (the corresponding mean rounded to three decimal places).",
      "hint": "Start by calculating the variance of each numeric column to find the one with the greatest spread, then pick a categorical column with 2\u201120 unique values for grouping before computing the averages.",
      "n_steps": 5,
      "difficulty": "HARD",
      "template_name": "category_highest_target_mean",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 4 keys: \"category_column\" (the grouping column name), \"best_category\" (the category value with highest mean), \"target_column\" (the numeric column analyzed), and \"mean_value\" (rounded to 3 decimal places). Example: {\"category_column\": \"region\", \"best_category\": \"West\", \"target_column\": \"sales\", \"mean_value\": 1234.567}",
      "ground_truth_hash": "04fcf361411400c3",
      "_ground_truth": {
        "category_column": "gender",
        "best_category": "Other",
        "target_column": "id",
        "mean_value": 56156.0
      },
      "_template": "category_highest_target_mean"
    },
    {
      "question": "Identify the pair of numeric columns that have the highest absolute Pearson correlation in the dataset. For that pair, calculate the original correlation, then remove any rows where either column's value deviates more than three standard deviations from its mean, count how many rows are removed, recompute the Pearson correlation on the remaining rows, and report the results. Provide your answer as a JSON object with exactly four keys: \"columns\" (a list of the two column names sorted alphabetically), \"original_correlation\" (the original correlation rounded to three decimal places), \"outliers_removed\" (the integer number of rows removed), and \"clean_correlation\" (the correlation after outlier removal rounded to three decimal places).",
      "hint": "Compute the absolute correlation matrix of all numeric columns to locate the strongest pair, then apply a 3\u2011standard\u2011deviation filter on both columns before recalculating the correlation.",
      "n_steps": 5,
      "difficulty": "HARD",
      "template_name": "correlation_after_outlier_removal",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 4 keys: \"columns\" (list of 2 column names, alphabetically sorted), \"original_correlation\" (rounded to 3 decimals), \"outliers_removed\" (integer count), and \"clean_correlation\" (rounded to 3 decimals). Example: {\"columns\": [\"col_a\", \"col_b\"], \"original_correlation\": 0.847, \"outliers_removed\": 12, \"clean_correlation\": 0.891}",
      "ground_truth_hash": "767ff1939e504011",
      "_ground_truth": {
        "columns": [
          "age",
          "bmi"
        ],
        "original_correlation": 0.333,
        "outliers_removed": 259,
        "clean_correlation": 0.366
      },
      "_template": "correlation_after_outlier_removal"
    },
    {
      "question": "Which pair of numeric columns has the strongest correlation? Provide your answer as a JSON object with keys \"columns\" (a list of the two column names, alphabetically sorted) and \"correlation\" (the correlation coefficient rounded to 3 decimal places).",
      "hint": "Compute the absolute correlation matrix for all numeric columns, ignore the diagonal, and identify the off\u2011diagonal pair with the highest value.",
      "n_steps": 4,
      "difficulty": "MEDIUM",
      "template_name": "strongest_correlation",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly two keys: \"columns\" (a list of the two column names, alphabetically sorted) and \"correlation\" (the correlation coefficient rounded to 3 decimal places). Example: {\"columns\": [\"col_a\", \"col_b\"], \"correlation\": 0.847}",
      "ground_truth_hash": "c94c4a61d4f4abdc",
      "_ground_truth": {
        "columns": [
          "age",
          "bmi"
        ],
        "correlation": 0.333
      },
      "_template": "strongest_correlation"
    },
    {
      "question": "Which pair of numeric columns exhibits the weakest non\u2011zero absolute correlation? Provide your answer as a JSON object with keys \"columns\" (a list of the two column names, alphabetically sorted) and \"correlation\" (the absolute correlation value rounded to 3 decimal places).",
      "hint": "Calculate the absolute correlation matrix for all numeric columns, ignore the diagonal (self\u2011correlations), and find the smallest remaining correlation.",
      "n_steps": 4,
      "difficulty": "MEDIUM",
      "template_name": "weakest_correlation",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly two keys: \"columns\" (a list of the two column names, alphabetically sorted) and \"correlation\" (the absolute correlation value rounded to 3 decimal places). Example: {\"columns\": [\"col_a\", \"col_b\"], \"correlation\": 0.012}",
      "ground_truth_hash": "aaba00445de7394e",
      "_ground_truth": {
        "columns": [
          "avg_glucose_level",
          "id"
        ],
        "correlation": 0.001
      },
      "_template": "weakest_correlation"
    },
    {
      "question": "For each numeric column in the dataset, treat a value as an outlier if it differs from the column's mean by more than three times its standard deviation. Determine (1) how many numeric columns contain at least one such outlier, and (2) the total number of outlier values across all numeric columns. Provide your answer as a JSON object with exactly two keys: \"columns_with_outliers\" (an integer) and \"total_outliers\" (an integer).",
      "hint": "Compute the mean and standard deviation for every numeric column, count values whose absolute deviation exceeds 3\u202f\u00d7\u202fstd, then sum the counts and count columns with a non\u2011zero count.",
      "n_steps": 4,
      "difficulty": "MEDIUM",
      "template_name": "count_outlier_columns",
      "template_params": {
        "z_threshold": 3.0
      },
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 2 keys: \"columns_with_outliers\" (integer count of columns containing at least one outlier) and \"total_outliers\" (integer total count of outlier values across all columns). Example: {\"columns_with_outliers\": 3, \"total_outliers\": 47}",
      "ground_truth_hash": "b12f26040aea97a5",
      "_ground_truth": {
        "columns_with_outliers": 5,
        "total_outliers": 1130
      },
      "_template": "count_outlier_columns"
    },
    {
      "question": "What is the count of numeric columns that contain at least one outlier, and the total number of outlier observations across all numeric columns, where an outlier is defined as a value whose absolute deviation from the column mean exceeds 2.5 times the column's standard deviation? Provide your answer as a JSON object with keys 'columns_with_outliers' (integer) and 'total_outliers' (integer).",
      "hint": "For each numeric column compute its mean and standard deviation, then count values that are farther than 2.5\u202f\u00d7\u202fstd from the mean; sum these counts and also count how many columns have a non\u2011zero outlier count.",
      "n_steps": 4,
      "difficulty": "MEDIUM",
      "template_name": "count_outlier_columns",
      "template_params": {
        "z_threshold": 2.5
      },
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 2 keys: \"columns_with_outliers\" (integer count of columns containing at least one outlier) and \"total_outliers\" (integer total count of outlier values across all columns). Example: {\"columns_with_outliers\": 3, \"total_outliers\": 47}",
      "ground_truth_hash": "f3de8c5231d3e06f",
      "_ground_truth": {
        "columns_with_outliers": 5,
        "total_outliers": 1340
      },
      "_template": "count_outlier_columns"
    },
    {
      "question": "What is the mean of the numeric column with the highest variance? Provide your answer as a single number rounded to 3 decimal places.",
      "hint": "Calculate the variance for each numeric column, find the column with the maximum variance, then compute its average.",
      "n_steps": 3,
      "difficulty": "MEDIUM",
      "template_name": "max_variance_mean",
      "template_params": null,
      "output_type": "scalar",
      "output_schema": "A single number (the mean), rounded to 3 decimal places",
      "ground_truth_hash": "2f5da1b29cf9f115",
      "_ground_truth": 36517.829,
      "_template": "max_variance_mean"
    },
    {
      "question": "What is the standard deviation of the numeric column that has the lowest mean? Provide your answer as a single number rounded to 3 decimal places.",
      "hint": "Identify the numeric column with the smallest average value, then calculate its standard deviation.",
      "n_steps": 3,
      "difficulty": "MEDIUM",
      "template_name": "min_mean_column_std",
      "template_params": null,
      "output_type": "scalar",
      "output_schema": "A single number (the standard deviation), rounded to 3 decimal places",
      "ground_truth_hash": "09284d168e7f5c97",
      "_ground_truth": 0.215,
      "_template": "min_mean_column_std"
    },
    {
      "question": "How many columns in the dataset have more than 5% missing values? Provide your answer as a JSON object with keys \"count\" (integer) and \"columns\" (list of column names, alphabetically sorted).",
      "hint": "Calculate the percentage of missing entries for each column and select those exceeding the 5% threshold.",
      "n_steps": 3,
      "difficulty": "EASY",
      "template_name": "count_high_missing_columns",
      "template_params": {
        "missing_threshold": 5.0
      },
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 2 keys: \"count\" (integer) and \"columns\" (list of column names, alphabetically sorted). Example: {\"count\": 3, \"columns\": [\"col_a\", \"col_b\", \"col_c\"]}",
      "ground_truth_hash": "2c42c4348e535666",
      "_ground_truth": {
        "count": 0,
        "columns": []
      },
      "_template": "count_high_missing_columns"
    },
    {
      "question": "How many columns in the dataset have more than 10% missing values, and which columns are they? Provide your answer as a JSON object with keys \"count\" (integer) and \"columns\" (list of column names, alphabetically sorted).",
      "hint": "Compute the missing-value percentage for each column and count those exceeding the 10% threshold.",
      "n_steps": 3,
      "difficulty": "EASY",
      "template_name": "count_high_missing_columns",
      "template_params": {
        "missing_threshold": 10.0
      },
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 2 keys: \"count\" (integer) and \"columns\" (list of column names, alphabetically sorted). Example: {\"count\": 3, \"columns\": [\"col_a\", \"col_b\", \"col_c\"]}",
      "ground_truth_hash": "2c42c4348e535666",
      "_ground_truth": {
        "count": 0,
        "columns": []
      },
      "_template": "count_high_missing_columns"
    }
  ]
}