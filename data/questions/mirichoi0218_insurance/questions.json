{
  "dataset_columns": [
    "age",
    "sex",
    "bmi",
    "children",
    "smoker",
    "region",
    "charges"
  ],
  "questions": [
    {
      "question": "Identify the numeric column that has the highest variance and treat it as the target variable. Then find the three numeric columns that have the largest absolute correlation with this target variable. Using these three columns as predictors, fit an ordinary least squares regression to predict the target. Report the results as a JSON object with the following keys: \"target\" (the name of the target column), \"predictors\" (a list of the three predictor column names), \"r_squared\" (the model R-squared rounded to 4 decimal places), \"adj_r_squared\" (the adjusted R-squared rounded to 4 decimal places), \"n_significant\" (the count of predictors whose p\u2011value is less than 0.05), \"coefficients\" (a dictionary mapping each predictor name to its regression coefficient rounded to 4 decimal places), and \"p_values\" (a dictionary mapping each predictor name to its p\u2011value rounded to 6 decimal places). Provide the answer exactly in this JSON format.",
      "hint": "Compute variance for each numeric column to pick the target, then compute absolute correlations to select the top three predictors before fitting the OLS model.",
      "n_steps": 10,
      "difficulty": "VERY_HARD",
      "template_name": "multiple_regression_top_predictors",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 6 keys: \"target\" (column name), \"predictors\" (list of 3 column names), \"r_squared\" (rounded to 4 decimals), \"adj_r_squared\" (rounded to 4 decimals), \"n_significant\" (integer count of predictors with p < 0.05), \"coefficients\" (dict mapping predictor names to coefficients rounded to 4 decimals), and \"p_values\" (dict mapping predictor names to p-values rounded to 6 decimals). Example: {\"target\": \"price\", \"predictors\": [\"sqft\", \"bedrooms\", \"age\"], \"r_squared\": 0.7234, \"adj_r_squared\": 0.7156, \"n_significant\": 2, \"coefficients\": {\"sqft\": 123.45, \"bedrooms\": 5000.12, \"age\": -200.34}, \"p_values\": {\"sqft\": 0.000001, \"bedrooms\": 0.023456, \"age\": 0.156789}}",
      "ground_truth_hash": "7e1e493db33494cf",
      "_ground_truth": {
        "target": "charges",
        "predictors": [
          "age",
          "bmi",
          "children"
        ],
        "r_squared": 0.1201,
        "adj_r_squared": 0.1181,
        "n_significant": 3,
        "coefficients": {
          "age": 239.9945,
          "bmi": 332.0834,
          "children": 542.8647
        },
        "p_values": {
          "age": 0.0,
          "bmi": 0.0,
          "children": 0.035726
        }
      },
      "_template": "multiple_regression_top_predictors"
    },
    {
      "question": "Identify the numeric column with the highest absolute skewness in the dataset. For that column, calculate the mean, the 95% confidence interval for the mean using 1000 bootstrap resamples, and the bootstrap standard error. Provide your answer as a JSON object with exactly the following keys: \"column\" (the name of the most skewed column), \"skewness\" (absolute skewness rounded to 4 decimal places), \"mean\" (rounded to 4 decimal places), \"ci_lower\" (lower bound of the 95% CI, rounded to 4 decimal places), \"ci_upper\" (upper bound of the 95% CI, rounded to 4 decimal places), \"std_error\" (bootstrap standard error rounded to 4 decimal places), and \"n_bootstrap\" (integer, the number of bootstrap samples).",
      "hint": "Compute the skewness for each numeric column, select the one with the largest absolute value, then bootstrap its non\u2011missing values (1000 samples) to estimate the mean distribution and derive the confidence interval and standard error.",
      "n_steps": 9,
      "difficulty": "VERY_HARD",
      "template_name": "bootstrap_ci_discovered",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 7 keys: \"column\" (name of most skewed column), \"skewness\" (rounded to 4 decimals), \"mean\" (rounded to 4 decimals), \"ci_lower\" (lower bound of 95% CI, rounded to 4 decimals), \"ci_upper\" (upper bound, rounded to 4 decimals), \"std_error\" (bootstrap standard error, rounded to 4 decimals), and \"n_bootstrap\" (integer, the number of bootstrap samples). Example: {\"column\": \"income\", \"skewness\": 2.3456, \"mean\": 50000.1234, \"ci_lower\": 48500.5678, \"ci_upper\": 51500.9012, \"std_error\": 750.3456, \"n_bootstrap\": 1000}",
      "ground_truth_hash": "743abc8c8c17569c",
      "_ground_truth": {
        "column": "charges",
        "skewness": 1.5159,
        "mean": 13270.4223,
        "ci_lower": 12672.5627,
        "ci_upper": 13922.1292,
        "std_error": 324.4055,
        "n_bootstrap": 1000
      },
      "_template": "bootstrap_ci_discovered"
    },
    {
      "question": "Identify the numeric column in the dataset that exhibits the highest variance. Then, find a categorical column that contains between three and ten distinct categories. Using these two columns, conduct a one\u2011way ANOVA to assess whether the mean of the high\u2011variance numeric column differs across the groups defined by the selected categorical column. Report the findings as a JSON object with exactly 11 keys: \"target_column\" (the name of the high\u2011variance numeric column), \"grouping_column\" (the name of the categorical column), \"n_groups\" (the number of distinct groups, integer), \"f_statistic\" (the ANOVA F\u2011statistic rounded to 4 decimal places), \"p_value\" (the ANOVA p\u2011value rounded to 6 decimal places), \"significant\" (true if p\u202f<\u202f0.05, otherwise false), \"best_group\" (the group with the highest mean), \"best_mean\" (that mean rounded to 4 decimal places), \"worst_group\" (the group with the lowest mean), \"worst_mean\" (that mean rounded to 4 decimal places), and \"eta_squared\" (the effect size rounded to 4 decimal places).",
      "hint": "Start by computing variances of all numeric columns to pick the one with the largest value, then examine categorical columns for a moderate number of unique categories before performing the ANOVA.",
      "n_steps": 9,
      "difficulty": "VERY_HARD",
      "template_name": "anova_discovered_groups",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 11 keys: \"target_column\", \"grouping_column\", \"n_groups\" (integer), \"f_statistic\" (rounded to 4 decimals), \"p_value\" (rounded to 6 decimals), \"significant\" (boolean), \"best_group\" (category with highest mean), \"best_mean\" (rounded to 4 decimals), \"worst_group\" (category with lowest mean), \"worst_mean\" (rounded to 4 decimals), and \"eta_squared\" (effect size, rounded to 4 decimals). Example: {\"target_column\": \"sales\", \"grouping_column\": \"region\", \"n_groups\": 4, \"f_statistic\": 15.2345, \"p_value\": 0.000012, \"significant\": true, \"best_group\": \"West\", \"best_mean\": 1234.5678, \"worst_group\": \"East\", \"worst_mean\": 890.1234, \"eta_squared\": 0.1523}",
      "ground_truth_hash": "c948f5d141ff1770",
      "_ground_truth": {
        "target_column": "charges",
        "grouping_column": "region",
        "n_groups": 4,
        "f_statistic": 2.9696,
        "p_value": 0.030893,
        "significant": "True",
        "best_group": "southeast",
        "best_mean": 14735.4114,
        "worst_group": "southwest",
        "worst_mean": 12346.9374,
        "eta_squared": 0.0066
      },
      "_template": "anova_discovered_groups"
    },
    {
      "question": "In the given dataset, first identify the numeric column that has the highest variance and treat it as the target variable. Among the remaining numeric columns, determine which one shows the strongest absolute Pearson correlation with this target column. Using only these two columns (and after removing any rows with missing values), fit a simple ordinary least squares regression of the target on the predictor. Report the name of the target column, the name of the predictor column, the absolute correlation between them (rounded to three decimal places), the R\u2011squared value of the regression (rounded to four decimal places), the regression coefficient for the predictor (rounded to four decimal places), and the p\u2011value for that coefficient (rounded to six decimal places). Provide your answer as a JSON object with exactly the following keys: \"target\", \"best_predictor\", \"correlation\", \"r_squared\", \"coefficient\", \"p_value\".",
      "hint": "Calculate variances of all numeric columns to pick the target, then compute absolute correlations with the other numeric columns to find the most predictive feature before fitting an OLS model.",
      "n_steps": 8,
      "difficulty": "HARD",
      "template_name": "regression_most_predictive",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 6 keys: \"target\" (column name), \"best_predictor\" (column name), \"correlation\" (rounded to 3 decimals), \"r_squared\" (rounded to 4 decimals), \"coefficient\" (rounded to 4 decimals), and \"p_value\" (rounded to 6 decimals). Example: {\"target\": \"price\", \"best_predictor\": \"sqft\", \"correlation\": 0.834, \"r_squared\": 0.6956, \"coefficient\": 135.2847, \"p_value\": 0.000001}",
      "ground_truth_hash": "c2265190a25a187d",
      "_ground_truth": {
        "target": "charges",
        "best_predictor": "age",
        "correlation": 0.299,
        "r_squared": 0.0894,
        "coefficient": 257.7226,
        "p_value": 0.0
      },
      "_template": "regression_most_predictive"
    },
    {
      "question": "Using the given dataset, find the numeric column with the highest variance and treat it as the target column. Then identify a categorical column that contains exactly two distinct categories and use it as the grouping column (the two categories will be group1 and group2). For each group, compute the mean of the target column, perform an independent two\u2011sample t\u2011test between the two groups, and determine if the difference is statistically significant at \u03b1 = 0.05. Provide your answer as a JSON object with exactly the following keys: \"target_column\" (the name of the numeric column with highest variance), \"grouping_column\" (the name of the binary categorical column), \"group1\" (the first category name), \"group2\" (the second category name), \"mean1\" (mean of the target for group1, rounded to 4 decimal places), \"mean2\" (mean of the target for group2, rounded to 4 decimal places), \"t_statistic\" (t\u2011statistic rounded to 4 decimal places), \"p_value\" (p\u2011value rounded to 6 decimal places), and \"significant\" (boolean, true if p < 0.05). Example format: {\"target_column\": \"...\", \"grouping_column\": \"...\", \"group1\": \"...\", \"group2\": \"...\", \"mean1\": 0.0000, \"mean2\": 0.0000, \"t_statistic\": 0.0000, \"p_value\": 0.000000, \"significant\": true}",
      "hint": "Start by calculating the variance of each numeric column to locate the one with the greatest spread, then examine the categorical columns to find one that has exactly two unique values.",
      "n_steps": 8,
      "difficulty": "HARD",
      "template_name": "ttest_discovered_groups",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 9 keys: \"target_column\", \"grouping_column\", \"group1\", \"group2\", \"mean1\" (rounded to 4 decimals), \"mean2\" (rounded to 4 decimals), \"t_statistic\" (rounded to 4 decimals), \"p_value\" (rounded to 6 decimals), and \"significant\" (boolean, true if p < 0.05). Example: {\"target_column\": \"score\", \"grouping_column\": \"gender\", \"group1\": \"M\", \"group2\": \"F\", \"mean1\": 75.4321, \"mean2\": 78.1234, \"t_statistic\": -2.3456, \"p_value\": 0.019234, \"significant\": true}",
      "ground_truth_hash": "df2b327c8f8d8b2d",
      "_ground_truth": {
        "target_column": "charges",
        "grouping_column": "sex",
        "group1": "female",
        "group2": "male",
        "mean1": 12569.5788,
        "mean2": 13956.7512,
        "t_statistic": -2.0975,
        "p_value": 0.036133,
        "significant": "True"
      },
      "_template": "ttest_discovered_groups"
    },
    {
      "question": "Identify the numeric column that has the highest variance in the dataset. Test whether the values in this column are normally distributed. If they are normal, output a JSON object with keys \"distribution\": \"normal\", \"mean\": <number>, and \"std\": <number>. If they are not normal, output a JSON object with keys \"distribution\": \"non-normal\", \"median\": <number>, and \"iqr\": <number>. All numeric values must be rounded to three decimal places. Provide only the JSON object as your answer.",
      "hint": "Compute the variance of each numeric column, pick the one with the maximum variance, then perform a normality test (e.g., Shapiro\u2011Wilk) on its non\u2011missing values (sample if the column has more than 5,000 observations).",
      "n_steps": 5,
      "difficulty": "HARD",
      "template_name": "conditional_normality",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 3 keys. If normal: {\"distribution\": \"normal\", \"mean\": <number>, \"std\": <number>}. If non-normal: {\"distribution\": \"non-normal\", \"median\": <number>, \"iqr\": <number>}. The \"iqr\" value is Q3 minus Q1 as a single number. All numeric values rounded to 3 decimal places.",
      "ground_truth_hash": "ddece8dec237b63c",
      "_ground_truth": {
        "distribution": "non-normal",
        "median": 9382.033,
        "iqr": 11899.625
      },
      "_template": "conditional_normality"
    },
    {
      "question": "Identify the numeric column that exhibits the greatest variance. Then, among the categorical columns that contain between 2 and 20 distinct values, choose one (if several qualify, any will do). For each category of the chosen categorical column, compute the mean of the selected high\u2011variance numeric column, and determine which category yields the highest mean. Provide your answer as a JSON object with exactly four keys: \"category_column\" (the name of the categorical column you used), \"best_category\" (the category value with the highest mean), \"target_column\" (the name of the numeric column with highest variance), and \"mean_value\" (the highest mean rounded to three decimal places). Example format: {\"category_column\": \"...\", \"best_category\": \"...\", \"target_column\": \"...\", \"mean_value\": 1234.567}",
      "hint": "First compute variances for all numeric columns to find the most variable one, then examine the distinct counts of each categorical column to pick one with moderate cardinality before grouping and averaging.",
      "n_steps": 5,
      "difficulty": "HARD",
      "template_name": "category_highest_target_mean",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 4 keys: \"category_column\" (the grouping column name), \"best_category\" (the category value with highest mean), \"target_column\" (the numeric column analyzed), and \"mean_value\" (rounded to 3 decimal places). Example: {\"category_column\": \"region\", \"best_category\": \"West\", \"target_column\": \"sales\", \"mean_value\": 1234.567}",
      "ground_truth_hash": "5c14c0809c87e54e",
      "_ground_truth": {
        "category_column": "sex",
        "best_category": "male",
        "target_column": "charges",
        "mean_value": 13956.751
      },
      "_template": "category_highest_target_mean"
    },
    {
      "question": "Identify the pair of numeric columns that exhibit the strongest absolute correlation in the dataset. Then, for that pair, remove any rows where either column\u2019s value lies more than three standard deviations away from its mean (i.e., treat them as outliers). Report the number of rows removed and recompute the correlation between the two columns using the cleaned data. Provide your answer as a JSON object with exactly four keys: \"columns\" (a list of the two column names, alphabetically sorted), \"original_correlation\" (the correlation before outlier removal, rounded to three decimal places), \"outliers_removed\" (the integer count of rows eliminated), and \"clean_correlation\" (the correlation after cleaning, rounded to three decimal places).",
      "hint": "Start by computing the absolute correlation matrix for all numeric columns to locate the most correlated pair, then apply a 3\u2011sigma rule on each column to filter out extreme values before recalculating the correlation.",
      "n_steps": 5,
      "difficulty": "HARD",
      "template_name": "correlation_after_outlier_removal",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 4 keys: \"columns\" (list of 2 column names, alphabetically sorted), \"original_correlation\" (rounded to 3 decimals), \"outliers_removed\" (integer count), and \"clean_correlation\" (rounded to 3 decimals). Example: {\"columns\": [\"col_a\", \"col_b\"], \"original_correlation\": 0.847, \"outliers_removed\": 12, \"clean_correlation\": 0.891}",
      "ground_truth_hash": "38f6fd4bd97a1197",
      "_ground_truth": {
        "columns": [
          "age",
          "charges"
        ],
        "original_correlation": 0.299,
        "outliers_removed": 7,
        "clean_correlation": 0.305
      },
      "_template": "correlation_after_outlier_removal"
    },
    {
      "question": "Among the numeric columns, which two have the highest absolute correlation? Provide your answer as a JSON object with keys \"columns\" (a list of the two column names, alphabetically sorted) and \"correlation\" (the correlation coefficient rounded to three decimal places).",
      "hint": "Calculate the correlation matrix for all numeric columns and identify the largest off\u2011diagonal correlation value.",
      "n_steps": 4,
      "difficulty": "MEDIUM",
      "template_name": "strongest_correlation",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly two keys: \"columns\" (a list of the two column names, alphabetically sorted) and \"correlation\" (the correlation coefficient rounded to 3 decimal places). Example: {\"columns\": [\"col_a\", \"col_b\"], \"correlation\": 0.847}",
      "ground_truth_hash": "69ed42be73afd36e",
      "_ground_truth": {
        "columns": [
          "age",
          "charges"
        ],
        "correlation": 0.299
      },
      "_template": "strongest_correlation"
    },
    {
      "question": "Among all numeric columns, identify the pair whose absolute correlation is the smallest positive value (i.e., weakest non\u2011zero correlation). Provide your answer as a JSON object with exactly two keys: \"columns\" (a list of the two column names, alphabetically sorted) and \"correlation\" (the absolute correlation rounded to 3 decimal places). Example format: {\"columns\": [\"col_a\", \"col_b\"], \"correlation\": 0.012}",
      "hint": "Compute the absolute correlation matrix for numeric columns, mask the diagonal and any zero entries, then locate the minimum remaining value.",
      "n_steps": 4,
      "difficulty": "MEDIUM",
      "template_name": "weakest_correlation",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly two keys: \"columns\" (a list of the two column names, alphabetically sorted) and \"correlation\" (the absolute correlation value rounded to 3 decimal places). Example: {\"columns\": [\"col_a\", \"col_b\"], \"correlation\": 0.012}",
      "ground_truth_hash": "d27ca4de278e635d",
      "_ground_truth": {
        "columns": [
          "bmi",
          "children"
        ],
        "correlation": 0.013
      },
      "_template": "weakest_correlation"
    },
    {
      "question": "For the numeric columns in the dataset, determine how many of those columns contain at least one outlier (where an outlier is defined as a value whose absolute deviation from the column mean exceeds three times the column standard deviation) and also compute the total number of outlier values across all numeric columns. Provide your answer as a JSON object with exactly two keys: \"columns_with_outliers\" (the integer count of columns that have one or more outliers) and \"total_outliers\" (the integer total count of outlier values). Example format: {\"columns_with_outliers\": 3, \"total_outliers\": 47}",
      "hint": "Calculate the mean and standard deviation for each numeric column, flag values beyond 3\u202f\u00d7\u202fstd, then aggregate counts per column and overall.",
      "n_steps": 4,
      "difficulty": "MEDIUM",
      "template_name": "count_outlier_columns",
      "template_params": {
        "z_threshold": 3.0
      },
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 2 keys: \"columns_with_outliers\" (integer count of columns containing at least one outlier) and \"total_outliers\" (integer total count of outlier values across all columns). Example: {\"columns_with_outliers\": 3, \"total_outliers\": 47}",
      "ground_truth_hash": "f87c2907ca0b0d49",
      "_ground_truth": {
        "columns_with_outliers": 3,
        "total_outliers": 29
      },
      "_template": "count_outlier_columns"
    },
    {
      "question": "Determine how many of the numeric columns in the dataset contain at least one outlier (where an outlier is any value whose absolute deviation from the column mean exceeds 2.5 times the column's standard deviation) and also compute the total number of outlier values across all numeric columns. Provide your answer as a JSON object with the keys \"columns_with_outliers\" (integer) and \"total_outliers\" (integer) exactly in this format: {\"columns_with_outliers\": <int>, \"total_outliers\": <int>}.",
      "hint": "For each numeric column compute its mean and standard deviation, count values farther than 2.5\u202f\u00d7\u202fstd from the mean, then summarize the counts.",
      "n_steps": 4,
      "difficulty": "MEDIUM",
      "template_name": "count_outlier_columns",
      "template_params": {
        "z_threshold": 2.5
      },
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 2 keys: \"columns_with_outliers\" (integer count of columns containing at least one outlier) and \"total_outliers\" (integer total count of outlier values across all columns). Example: {\"columns_with_outliers\": 3, \"total_outliers\": 47}",
      "ground_truth_hash": "17264742db0302f7",
      "_ground_truth": {
        "columns_with_outliers": 3,
        "total_outliers": 85
      },
      "_template": "count_outlier_columns"
    },
    {
      "question": "What is the mean of the numeric column with the highest variance? Provide your answer as a single number rounded to 3 decimal places.",
      "hint": "Identify the numeric column that shows the greatest variance across rows, then calculate its average value.",
      "n_steps": 3,
      "difficulty": "MEDIUM",
      "template_name": "max_variance_mean",
      "template_params": null,
      "output_type": "scalar",
      "output_schema": "A single number (the mean), rounded to 3 decimal places",
      "ground_truth_hash": "9a9101a30ca3b1f0",
      "_ground_truth": 13270.422,
      "_template": "max_variance_mean"
    },
    {
      "question": "What is the standard deviation of the numeric column that has the smallest average value? Provide your answer as a single number rounded to 3 decimal places.",
      "hint": "First calculate the mean of each numeric column, identify the one with the lowest mean, then compute its standard deviation.",
      "n_steps": 3,
      "difficulty": "MEDIUM",
      "template_name": "min_mean_column_std",
      "template_params": null,
      "output_type": "scalar",
      "output_schema": "A single number (the standard deviation), rounded to 3 decimal places",
      "ground_truth_hash": "03a5efde08ad0be9",
      "_ground_truth": 1.205,
      "_template": "min_mean_column_std"
    },
    {
      "question": "How many columns in the dataset have more than 5% missing values, and which columns are they? Provide your answer as a JSON object with exactly two keys: \"count\" (an integer) and \"columns\" (an alphabetically sorted list of column names).",
      "hint": "Compute the missing\u2011value percentage for each column and count those exceeding the 5% threshold.",
      "n_steps": 3,
      "difficulty": "EASY",
      "template_name": "count_high_missing_columns",
      "template_params": {
        "missing_threshold": 5.0
      },
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 2 keys: \"count\" (integer) and \"columns\" (list of column names, alphabetically sorted). Example: {\"count\": 3, \"columns\": [\"col_a\", \"col_b\", \"col_c\"]}",
      "ground_truth_hash": "2c42c4348e535666",
      "_ground_truth": {
        "count": 0,
        "columns": []
      },
      "_template": "count_high_missing_columns"
    },
    {
      "question": "Identify how many columns in the dataset have more than 10% missing values and list those column names. Provide your answer as a JSON object with keys \"count\" (an integer) and \"columns\" (an alphabetically sorted list of column names).",
      "hint": "Calculate the proportion of missing entries for each column and compare it to the 10% threshold.",
      "n_steps": 3,
      "difficulty": "EASY",
      "template_name": "count_high_missing_columns",
      "template_params": {
        "missing_threshold": 10.0
      },
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 2 keys: \"count\" (integer) and \"columns\" (list of column names, alphabetically sorted). Example: {\"count\": 3, \"columns\": [\"col_a\", \"col_b\", \"col_c\"]}",
      "ground_truth_hash": "2c42c4348e535666",
      "_ground_truth": {
        "count": 0,
        "columns": []
      },
      "_template": "count_high_missing_columns"
    }
  ]
}