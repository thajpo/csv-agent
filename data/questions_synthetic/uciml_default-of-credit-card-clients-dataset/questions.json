{
  "dataset_columns": [
    "ID",
    "LIMIT_BAL",
    "SEX",
    "EDUCATION",
    "MARRIAGE",
    "AGE",
    "PAY_0",
    "PAY_2",
    "PAY_3",
    "PAY_4",
    "PAY_5",
    "PAY_6",
    "BILL_AMT1",
    "BILL_AMT2",
    "BILL_AMT3",
    "BILL_AMT4",
    "BILL_AMT5",
    "BILL_AMT6",
    "PAY_AMT1",
    "PAY_AMT2",
    "PAY_AMT3",
    "PAY_AMT4",
    "PAY_AMT5",
    "PAY_AMT6",
    "default.payment.next.month"
  ],
  "questions": [
    {
      "question": "Which numeric variable in this credit\u2011card dataset shows the greatest variability, and can its variation be explained by a few other numeric features? Return as JSON with keys: target, predictors, r_squared, adj_r_squared, n_significant, coefficients, p_values.",
      "hint": "Find the numeric column with the highest variance, compute absolute correlations with the remaining numeric columns, pick the three strongest correlates, fit an OLS regression and report the model fit and significance metrics.",
      "n_steps": 10,
      "difficulty": "VERY_HARD",
      "template_name": "multiple_regression_top_predictors",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 6 keys: \"target\" (column name), \"predictors\" (list of 3 column names), \"r_squared\" (rounded to 4 decimals), \"adj_r_squared\" (rounded to 4 decimals), \"n_significant\" (integer count of predictors with p < 0.05), \"coefficients\" (dict mapping predictor names to coefficients rounded to 4 decimals), and \"p_values\" (dict mapping predictor names to p-values rounded to 6 decimals). Example: {\"target\": \"price\", \"predictors\": [\"sqft\", \"bedrooms\", \"age\"], \"r_squared\": 0.7234, \"adj_r_squared\": 0.7156, \"n_significant\": 2, \"coefficients\": {\"sqft\": 123.45, \"bedrooms\": 5000.12, \"age\": -200.34}, \"p_values\": {\"sqft\": 0.000001, \"bedrooms\": 0.023456, \"age\": 0.156789}}",
      "ground_truth_hash": "cb0c532248b365c4",
      "_ground_truth": {
        "target": "LIMIT_BAL",
        "predictors": [
          "PAY_2",
          "BILL_AMT5",
          "BILL_AMT4"
        ],
        "r_squared": 0.229,
        "adj_r_squared": 0.2289,
        "n_significant": 3,
        "coefficients": {
          "PAY_2": -41530.2737,
          "BILL_AMT5": 0.4397,
          "BILL_AMT4": 0.374
        },
        "p_values": {
          "PAY_2": 0.0,
          "BILL_AMT5": 0.0,
          "BILL_AMT4": 0.0
        }
      },
      "_template": "multiple_regression_top_predictors"
    },
    {
      "question": "Which numeric column in the credit card dataset is the most skewed, and what are its mean and 95% confidence interval using bootstrap? Return as JSON with keys: column, skewness, mean, ci_lower, ci_upper, std_error, n_bootstrap.",
      "hint": "Compute skewness for each numeric column, select the highest, then bootstrap its values to estimate the mean, confidence interval, and standard error.",
      "n_steps": 9,
      "difficulty": "VERY_HARD",
      "template_name": "bootstrap_ci_discovered",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 7 keys: \"column\" (name of most skewed column), \"skewness\" (rounded to 4 decimals), \"mean\" (rounded to 4 decimals), \"ci_lower\" (lower bound of 95% CI, rounded to 4 decimals), \"ci_upper\" (upper bound, rounded to 4 decimals), \"std_error\" (bootstrap standard error, rounded to 4 decimals), and \"n_bootstrap\" (integer, the number of bootstrap samples). Example: {\"column\": \"income\", \"skewness\": 2.3456, \"mean\": 50000.1234, \"ci_lower\": 48500.5678, \"ci_upper\": 51500.9012, \"std_error\": 750.3456, \"n_bootstrap\": 1000}",
      "ground_truth_hash": "ddf21dc51d64ba99",
      "_ground_truth": {
        "column": "PAY_AMT2",
        "skewness": 30.4538,
        "mean": 5921.1635,
        "ci_lower": 5657.8392,
        "ci_upper": 6182.7189,
        "std_error": 132.5815,
        "n_bootstrap": 1000
      },
      "_template": "bootstrap_ci_discovered"
    },
    {
      "question": "Which numeric feature most strongly predicts the column that varies the most in this credit\u2011card dataset? Return as JSON with keys: target, best_predictor, correlation, r_squared, coefficient, p_value.",
      "hint": "First find the numeric column with the highest variance, then identify the numeric feature with the strongest correlation to it and fit a simple OLS regression.",
      "n_steps": 8,
      "difficulty": "HARD",
      "template_name": "regression_most_predictive",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 6 keys: \"target\" (column name), \"best_predictor\" (column name), \"correlation\" (rounded to 3 decimals), \"r_squared\" (rounded to 4 decimals), \"coefficient\" (rounded to 4 decimals), and \"p_value\" (rounded to 6 decimals). Example: {\"target\": \"price\", \"best_predictor\": \"sqft\", \"correlation\": 0.834, \"r_squared\": 0.6956, \"coefficient\": 135.2847, \"p_value\": 0.000001}",
      "ground_truth_hash": "3399b934f6db8c3b",
      "_ground_truth": {
        "target": "LIMIT_BAL",
        "best_predictor": "PAY_2",
        "correlation": 0.296,
        "r_squared": 0.0878,
        "coefficient": -32121.0617,
        "p_value": 0.0
      },
      "_template": "regression_most_predictive"
    },
    {
      "question": "Does the most variable numeric feature differ between two naturally defined groups in the dataset? Return as JSON with keys: target_column, grouping_column, group1, group2, mean1, mean2, t_statistic, p_value, significant.",
      "hint": "Find the numeric column with highest variance, create or locate a binary grouping column, then compare the means of the target column between the two groups using a t\u2011test.",
      "n_steps": 8,
      "difficulty": "HARD",
      "template_name": "ttest_discovered_groups",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 9 keys: \"target_column\", \"grouping_column\", \"group1\", \"group2\", \"mean1\" (rounded to 4 decimals), \"mean2\" (rounded to 4 decimals), \"t_statistic\" (rounded to 4 decimals), \"p_value\" (rounded to 6 decimals), and \"significant\" (boolean, true if p < 0.05). Example: {\"target_column\": \"score\", \"grouping_column\": \"gender\", \"group1\": \"M\", \"group2\": \"F\", \"mean1\": 75.4321, \"mean2\": 78.1234, \"t_statistic\": -2.3456, \"p_value\": 0.019234, \"significant\": true}",
      "ground_truth_hash": "66d26a804666fd93",
      "_ground_truth": {
        "target_column": "LIMIT_BAL",
        "grouping_column": "_binary_group",
        "group1": "low",
        "group2": "high",
        "mean1": 166228.912,
        "mean2": 168739.7333,
        "t_statistic": -1.6759,
        "p_value": 0.093759,
        "significant": "False"
      },
      "_template": "ttest_discovered_groups"
    },
    {
      "question": "Which numeric variable in this credit card dataset most closely follows a normal distribution? Return as JSON with keys: column, ks_statistic, p_value, is_normal, sample_mean, sample_std.",
      "hint": "Select the column with the smallest absolute skewness, standardize its values, and apply a Kolmogorov\u2011Smirnov test against a standard normal distribution.",
      "n_steps": 7,
      "difficulty": "MEDIUM",
      "template_name": "ks_normality_test",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 6 keys: \"column\" (tested column), \"ks_statistic\" (rounded to 4 decimals), \"p_value\" (rounded to 6 decimals), \"is_normal\" (boolean, true if p >= 0.05), \"sample_mean\" (rounded to 4 decimals), and \"sample_std\" (rounded to 4 decimals). Example: {\"column\": \"height\", \"ks_statistic\": 0.0456, \"p_value\": 0.234567, \"is_normal\": true, \"sample_mean\": 170.1234, \"sample_std\": 10.5678}",
      "ground_truth_hash": "0163a4a5e4643cd3",
      "_ground_truth": {
        "column": "ID",
        "ks_statistic": 0.0572,
        "p_value": 0.0,
        "is_normal": "False",
        "sample_mean": 15000.5,
        "sample_std": 8660.3984
      },
      "_template": "ks_normality_test"
    },
    {
      "question": "Is the most skewed numeric feature distributed differently between two groups defined by a binary split of another numeric variable? Return as JSON with keys: target_column, grouping_column, group1, group2, median1, median2, u_statistic, p_value.",
      "hint": "Find the column with highest absolute skew, create a high/low binary group using the median of another numeric column, then compare medians with a Mann\u2011Whitney U test.",
      "n_steps": 6,
      "difficulty": "MEDIUM",
      "template_name": "mann_whitney_u_test",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 8 keys: \"target_column\", \"grouping_column\", \"group1\", \"group2\", \"median1\" (rounded to 4 decimals), \"median2\" (rounded to 4 decimals), \"u_statistic\" (rounded to 2 decimals), and \"p_value\" (rounded to 6 decimals). Example: {\"target_column\": \"score\", \"grouping_column\": \"treatment\", \"group1\": \"control\", \"group2\": \"experimental\", \"median1\": 72.5000, \"median2\": 78.0000, \"u_statistic\": 1234.50, \"p_value\": 0.034567}",
      "ground_truth_hash": "0f73264ed2ac9319",
      "_ground_truth": {
        "target_column": "PAY_AMT2",
        "grouping_column": "_binary_group",
        "group1": "low",
        "group2": "high",
        "median1": 2000.0,
        "median2": 2235.5,
        "u_statistic": 105186411.0,
        "p_value": 0.0
      },
      "_template": "mann_whitney_u_test"
    },
    {
      "question": "Which two numeric variables in the credit\u2011card dataset have the strongest monotonic relationship? Return as JSON with keys: columns, spearman_rho, p_value, interpretation.",
      "hint": "Compute the absolute Spearman correlation for every pair of numeric columns and pick the pair with the highest value.",
      "n_steps": 6,
      "difficulty": "MEDIUM",
      "template_name": "spearman_rank_correlation",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 4 keys: \"columns\" (list of 2 column names, alphabetically sorted), \"spearman_rho\" (correlation coefficient rounded to 4 decimals), \"p_value\" (rounded to 6 decimals), and \"interpretation\" (string: \"strong\", \"moderate\", \"weak\", or \"negligible\"). Example: {\"columns\": [\"age\", \"income\"], \"spearman_rho\": 0.7234, \"p_value\": 0.000001, \"interpretation\": \"strong\"}",
      "ground_truth_hash": "21264b3e7f194807",
      "_ground_truth": {
        "columns": [
          "BILL_AMT1",
          "BILL_AMT2"
        ],
        "spearman_rho": 0.9111,
        "p_value": 0.0,
        "interpretation": "strong"
      },
      "_template": "spearman_rank_correlation"
    },
    {
      "question": "Do the two most skewed numeric columns show a stronger relationship after a log transformation? Return as JSON with keys: columns, original_correlation, log_correlation, improvement, transformation_helpful.",
      "hint": "Identify the numeric columns with highest absolute skew, compute Pearson correlation before and after a log1p transform, then compare the absolute values.",
      "n_steps": 6,
      "difficulty": "HARD",
      "template_name": "correlation_change_analysis",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 5 keys: \"columns\" (list of 2 column names, alphabetically sorted), \"original_correlation\" (Pearson, rounded to 4 decimals), \"log_correlation\" (after log transform, rounded to 4 decimals), \"improvement\" (absolute difference, rounded to 4 decimals), and \"transformation_helpful\" (boolean, true if |log_corr| > |orig_corr|). Example: {\"columns\": [\"income\", \"spending\"], \"original_correlation\": 0.4567, \"log_correlation\": 0.7234, \"improvement\": 0.2667, \"transformation_helpful\": true}",
      "ground_truth_hash": "cc55550603495644",
      "_ground_truth": {
        "columns": [
          "AGE",
          "LIMIT_BAL"
        ],
        "original_correlation": 0.1447,
        "log_correlation": 0.19,
        "improvement": 0.0453,
        "transformation_helpful": "True"
      },
      "_template": "correlation_change_analysis"
    },
    {
      "question": "Which numeric column in this credit dataset has the greatest variability, and how many extreme outliers does it contain? Return as JSON with keys: column, q1, q3, iqr, lower_fence, upper_fence, n_outliers.",
      "hint": "Identify the column with the highest variance, then compute its Q1, Q3, IQR and the 1.5*IQR fences to count outliers.",
      "n_steps": 5,
      "difficulty": "EASY",
      "template_name": "iqr_outlier_analysis",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 7 keys: \"column\" (analyzed column), \"q1\" (25th percentile rounded to 4 decimals), \"q3\" (75th percentile rounded to 4 decimals), \"iqr\" (rounded to 4 decimals), \"lower_fence\" (rounded to 4 decimals), \"upper_fence\" (rounded to 4 decimals), and \"n_outliers\" (integer count). Example: {\"column\": \"salary\", \"q1\": 45000.0000, \"q3\": 75000.0000, \"iqr\": 30000.0000, \"lower_fence\": 0.0000, \"upper_fence\": 120000.0000, \"n_outliers\": 23}",
      "ground_truth_hash": "8c35e27d6717cb65",
      "_ground_truth": {
        "column": "LIMIT_BAL",
        "q1": 50000.0,
        "q3": 240000.0,
        "iqr": 190000.0,
        "lower_fence": -235000.0,
        "upper_fence": 525000.0,
        "n_outliers": 167
      },
      "_template": "iqr_outlier_analysis"
    },
    {
      "question": "Which numeric column shows the greatest variability and does its distribution deviate from normality? Return as JSON with keys: distribution, median, iqr.",
      "hint": "Find the column with the highest variance, test its normality (e.g., Shapiro-Wilk), then report median and IQR if non\u2011normal.",
      "n_steps": 5,
      "difficulty": "HARD",
      "template_name": "conditional_normality",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 3 keys. If normal: {\"distribution\": \"normal\", \"mean\": <number>, \"std\": <number>}. If non-normal: {\"distribution\": \"non-normal\", \"median\": <number>, \"iqr\": <number>}. The \"iqr\" value is Q3 minus Q1 as a single number. All numeric values rounded to 3 decimal places.",
      "ground_truth_hash": "40c7975c1ba65937",
      "_ground_truth": {
        "distribution": "non-normal",
        "median": 140000.0,
        "iqr": 190000.0
      },
      "_template": "conditional_normality"
    },
    {
      "question": "How many numeric columns contain any extreme values and what is the total number of such outlier observations? Return as JSON with keys: columns_with_outliers, total_outliers.",
      "hint": "Identify outliers as points more than 3 standard deviations from the mean for each numeric column.",
      "n_steps": 4,
      "difficulty": "MEDIUM",
      "template_name": "count_outlier_columns",
      "template_params": {
        "z_threshold": 3.0
      },
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 2 keys: \"columns_with_outliers\" (integer count of columns containing at least one outlier) and \"total_outliers\" (integer total count of outlier values across all columns). Example: {\"columns_with_outliers\": 3, \"total_outliers\": 47}",
      "ground_truth_hash": "94cd2ea279f36e64",
      "_ground_truth": {
        "columns_with_outliers": 21,
        "total_outliers": 7819
      },
      "_template": "count_outlier_columns"
    },
    {
      "question": "How many numeric columns contain outliers and what is the total number of outlier values? Return as JSON with keys: columns_with_outliers, total_outliers.",
      "hint": "For each numeric column, flag values farther than 2.5 standard deviations from the mean, then count columns with any flags and sum all flagged values.",
      "n_steps": 4,
      "difficulty": "MEDIUM",
      "template_name": "count_outlier_columns",
      "template_params": {
        "z_threshold": 2.5
      },
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 2 keys: \"columns_with_outliers\" (integer count of columns containing at least one outlier) and \"total_outliers\" (integer total count of outlier values across all columns). Example: {\"columns_with_outliers\": 3, \"total_outliers\": 47}",
      "ground_truth_hash": "6a4124b3cb636da3",
      "_ground_truth": {
        "columns_with_outliers": 22,
        "total_outliers": 13458
      },
      "_template": "count_outlier_columns"
    },
    {
      "question": "Which numeric feature shows the greatest relative variability across customers? Return as JSON with keys: column, cv, mean, std.",
      "hint": "Calculate mean and standard deviation for each numeric column, compute CV = (std/mean)*100, and identify the column with the highest CV.",
      "n_steps": 4,
      "difficulty": "EASY",
      "template_name": "coefficient_of_variation",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 4 keys: \"column\" (name of column with highest CV), \"cv\" (coefficient of variation as percentage rounded to 2 decimals), \"mean\" (rounded to 4 decimals), and \"std\" (rounded to 4 decimals). Example: {\"column\": \"price\", \"cv\": 45.23, \"mean\": 1234.5678, \"std\": 558.4567}",
      "ground_truth_hash": "67e0ef801d02b67f",
      "_ground_truth": {
        "column": "PAY_AMT2",
        "cv": 389.13,
        "mean": 5921.1635,
        "std": 23040.8704
      },
      "_template": "coefficient_of_variation"
    },
    {
      "question": "Which two numeric columns in the credit dataset have the strongest correlation? Return as JSON with keys: columns, correlation.",
      "hint": "Calculate the absolute correlation matrix for all numeric features and identify the pair with the highest off\u2011diagonal value.",
      "n_steps": 4,
      "difficulty": "MEDIUM",
      "template_name": "strongest_correlation",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly two keys: \"columns\" (a list of the two column names, alphabetically sorted) and \"correlation\" (the correlation coefficient rounded to 3 decimal places). Example: {\"columns\": [\"col_a\", \"col_b\"], \"correlation\": 0.847}",
      "ground_truth_hash": "126afbbc0c95df30",
      "_ground_truth": {
        "columns": [
          "BILL_AMT1",
          "BILL_AMT2"
        ],
        "correlation": 0.951
      },
      "_template": "strongest_correlation"
    },
    {
      "question": "Which two numeric variables in the credit card dataset are the least correlated with each other? Return as JSON with keys: columns, correlation.",
      "hint": "Compute the absolute correlation matrix for all numeric columns, ignore the diagonal, and find the pair with the smallest non\u2011zero value.",
      "n_steps": 4,
      "difficulty": "MEDIUM",
      "template_name": "weakest_correlation",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly two keys: \"columns\" (a list of the two column names, alphabetically sorted) and \"correlation\" (the absolute correlation value rounded to 3 decimal places). Example: {\"columns\": [\"col_a\", \"col_b\"], \"correlation\": 0.012}",
      "ground_truth_hash": "c37b19052ecb1234",
      "_ground_truth": {
        "columns": [
          "PAY_AMT1",
          "SEX"
        ],
        "correlation": 0.0
      },
      "_template": "weakest_correlation"
    },
    {
      "question": "Which numeric feature in the dataset shows the greatest variability, and what is its average value? Return as JSON with keys: result.",
      "hint": "Identify the numeric column with the highest variance, then compute its mean.",
      "n_steps": 3,
      "difficulty": "MEDIUM",
      "template_name": "max_variance_mean",
      "template_params": null,
      "output_type": "scalar",
      "output_schema": "A single number (the mean), rounded to 3 decimal places",
      "ground_truth_hash": "352fa723b08cb741",
      "_ground_truth": 167484.323,
      "_template": "max_variance_mean"
    },
    {
      "question": "Which numeric variable in the dataset has the smallest average value, and how spread out are its observations? Return as JSON with keys: std.",
      "hint": "Identify the column with the minimum mean, then compute its standard deviation.",
      "n_steps": 3,
      "difficulty": "MEDIUM",
      "template_name": "min_mean_column_std",
      "template_params": null,
      "output_type": "scalar",
      "output_schema": "A single number (the standard deviation), rounded to 3 decimal places",
      "ground_truth_hash": "9f0e787f95cbd2f6",
      "_ground_truth": 1.15,
      "_template": "min_mean_column_std"
    },
    {
      "question": "Are there any features in the dataset that have a substantial proportion of missing values? Return as JSON with keys: count, columns.",
      "hint": "Compute the missing percentage for each column, count those exceeding 5%, and list their names alphabetically.",
      "n_steps": 3,
      "difficulty": "EASY",
      "template_name": "count_high_missing_columns",
      "template_params": {
        "missing_threshold": 5.0
      },
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 2 keys: \"count\" (integer) and \"columns\" (list of column names, alphabetically sorted). Example: {\"count\": 3, \"columns\": [\"col_a\", \"col_b\", \"col_c\"]}",
      "ground_truth_hash": "2c42c4348e535666",
      "_ground_truth": {
        "count": 0,
        "columns": []
      },
      "_template": "count_high_missing_columns"
    },
    {
      "question": "Are there any features in this credit card dataset that have a substantial amount of missing data (more than 10% missing values)? Return as JSON with keys: count, columns.",
      "hint": "Compute the percentage of missing values for each column, then count and list those columns where the missing percentage exceeds 10%.",
      "n_steps": 3,
      "difficulty": "EASY",
      "template_name": "count_high_missing_columns",
      "template_params": {
        "missing_threshold": 10.0
      },
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 2 keys: \"count\" (integer) and \"columns\" (list of column names, alphabetically sorted). Example: {\"count\": 3, \"columns\": [\"col_a\", \"col_b\", \"col_c\"]}",
      "ground_truth_hash": "2c42c4348e535666",
      "_ground_truth": {
        "count": 0,
        "columns": []
      },
      "_template": "count_high_missing_columns"
    },
    {
      "question": "Which numeric column in this credit card dataset spans the widest range, and what are its key percentiles? Return as JSON with keys: column, p10, p25, p50, p75, p90.",
      "hint": "Find the numeric feature with the largest max\u2011min difference, then calculate its 10th, 25th, 50th, 75th, and 90th percentiles.",
      "n_steps": 3,
      "difficulty": "EASY",
      "template_name": "percentile_ranking",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 6 keys: \"column\" (analyzed column), \"p10\" (10th percentile rounded to 4 decimals), \"p25\" (25th percentile), \"p50\" (median), \"p75\" (75th percentile), and \"p90\" (90th percentile). Example: {\"column\": \"income\", \"p10\": 25000.0000, \"p25\": 40000.0000, \"p50\": 55000.0000, \"p75\": 75000.0000, \"p90\": 100000.0000}",
      "ground_truth_hash": "b845ddc360969b2d",
      "_ground_truth": {
        "column": "BILL_AMT3",
        "p10": 0.0,
        "p25": 2666.25,
        "p50": 20088.5,
        "p75": 60164.75,
        "p90": 132051.3
      },
      "_template": "percentile_ranking"
    },
    {
      "question": "Which numeric variable in this credit\u2011card dataset shows the greatest variability? Return as JSON with keys: column, count, mean, std, min, max, median, skewness, kurtosis.",
      "hint": "Find the column with the highest variance and then calculate its descriptive statistics.",
      "n_steps": 3,
      "difficulty": "EASY",
      "template_name": "descriptive_summary",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 9 keys: \"column\", \"count\" (integer), \"mean\" (rounded to 4 decimals), \"std\", \"min\", \"max\", \"median\", \"skewness\", and \"kurtosis\" (all rounded to 4 decimals). Example: {\"column\": \"age\", \"count\": 1000, \"mean\": 35.4567, \"std\": 12.3456, \"min\": 18.0000, \"max\": 85.0000, \"median\": 34.0000, \"skewness\": 0.5678, \"kurtosis\": -0.2345}",
      "ground_truth_hash": "65eb62ffad7a1cc5",
      "_ground_truth": {
        "column": "LIMIT_BAL",
        "count": 30000,
        "mean": 167484.3227,
        "std": 129747.6616,
        "min": 10000.0,
        "max": 1000000.0,
        "median": 140000.0,
        "skewness": 0.9929,
        "kurtosis": 0.5363
      },
      "_template": "descriptive_summary"
    }
  ]
}