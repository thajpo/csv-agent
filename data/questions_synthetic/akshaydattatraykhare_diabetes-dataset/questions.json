{
  "dataset_columns": [
    "Pregnancies",
    "Glucose",
    "BloodPressure",
    "SkinThickness",
    "Insulin",
    "BMI",
    "DiabetesPedigreeFunction",
    "Age",
    "Outcome"
  ],
  "questions": [
    {
      "question": "Which numeric measurement shows the most variability and can be explained by three other clinical features, and how well does that linear model perform? Return as JSON with keys: target, predictors, r_squared, adj_r_squared, n_significant, coefficients, p_values.",
      "hint": "Pick the numeric column with the highest variance as the target, select its three strongest correlated numeric predictors, fit an OLS regression, and report the model statistics.",
      "n_steps": 10,
      "difficulty": "VERY_HARD",
      "template_name": "multiple_regression_top_predictors",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 6 keys: \"target\" (column name), \"predictors\" (list of 3 column names), \"r_squared\" (rounded to 4 decimals), \"adj_r_squared\" (rounded to 4 decimals), \"n_significant\" (integer count of predictors with p < 0.05), \"coefficients\" (dict mapping predictor names to coefficients rounded to 4 decimals), and \"p_values\" (dict mapping predictor names to p-values rounded to 6 decimals). Example: {\"target\": \"price\", \"predictors\": [\"sqft\", \"bedrooms\", \"age\"], \"r_squared\": 0.7234, \"adj_r_squared\": 0.7156, \"n_significant\": 2, \"coefficients\": {\"sqft\": 123.45, \"bedrooms\": 5000.12, \"age\": -200.34}, \"p_values\": {\"sqft\": 0.000001, \"bedrooms\": 0.023456, \"age\": 0.156789}}",
      "ground_truth_hash": "f8ab79a505283348",
      "_ground_truth": {
        "target": "Insulin",
        "predictors": [
          "SkinThickness",
          "Glucose",
          "BMI"
        ],
        "r_squared": 0.2864,
        "adj_r_squared": 0.2836,
        "n_significant": 2,
        "coefficients": {
          "SkinThickness": 3.1465,
          "Glucose": 1.1386,
          "BMI": -0.6279
        },
        "p_values": {
          "SkinThickness": 0.0,
          "Glucose": 0.0,
          "BMI": 0.207315
        }
      },
      "_template": "multiple_regression_top_predictors"
    },
    {
      "question": "Which numeric measurement in the diabetes dataset shows the greatest skewness, and what are its mean and 95% confidence interval?",
      "hint": "Calculate absolute skewness for all numeric columns, select the most skewed one, then bootstrap its mean to obtain the confidence interval and standard error. Return as JSON with keys: column, skewness, mean, ci_lower, ci_upper, std_error, n_bootstrap.",
      "n_steps": 9,
      "difficulty": "VERY_HARD",
      "template_name": "bootstrap_ci_discovered",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 7 keys: \"column\" (name of most skewed column), \"skewness\" (rounded to 4 decimals), \"mean\" (rounded to 4 decimals), \"ci_lower\" (lower bound of 95% CI, rounded to 4 decimals), \"ci_upper\" (upper bound, rounded to 4 decimals), \"std_error\" (bootstrap standard error, rounded to 4 decimals), and \"n_bootstrap\" (integer, the number of bootstrap samples). Example: {\"column\": \"income\", \"skewness\": 2.3456, \"mean\": 50000.1234, \"ci_lower\": 48500.5678, \"ci_upper\": 51500.9012, \"std_error\": 750.3456, \"n_bootstrap\": 1000}",
      "ground_truth_hash": "dde48557f10b5b2c",
      "_ground_truth": {
        "column": "Insulin",
        "skewness": 2.2723,
        "mean": 79.7995,
        "ci_lower": 72.1633,
        "ci_upper": 87.6147,
        "std_error": 4.0649,
        "n_bootstrap": 1000
      },
      "_template": "bootstrap_ci_discovered"
    },
    {
      "question": "Which measurement in the diabetes dataset shows the highest variability and which other feature most strongly predicts it? Return as JSON with keys: target, best_predictor, correlation, r_squared, coefficient, p_value.",
      "hint": "Find the numeric column with the greatest variance, compute absolute correlations with it, select the strongest correlated feature, and fit a simple linear regression.",
      "n_steps": 8,
      "difficulty": "HARD",
      "template_name": "regression_most_predictive",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 6 keys: \"target\" (column name), \"best_predictor\" (column name), \"correlation\" (rounded to 3 decimals), \"r_squared\" (rounded to 4 decimals), \"coefficient\" (rounded to 4 decimals), and \"p_value\" (rounded to 6 decimals). Example: {\"target\": \"price\", \"best_predictor\": \"sqft\", \"correlation\": 0.834, \"r_squared\": 0.6956, \"coefficient\": 135.2847, \"p_value\": 0.000001}",
      "ground_truth_hash": "c3361d9b35ad44ff",
      "_ground_truth": {
        "target": "Insulin",
        "best_predictor": "SkinThickness",
        "correlation": 0.437,
        "r_squared": 0.1908,
        "coefficient": 3.1555,
        "p_value": 0.0
      },
      "_template": "regression_most_predictive"
    },
    {
      "question": "Does the most variable measurement differ significantly between high and low groups of another feature? Return as JSON with keys: target_column, grouping_column, group1, group2, mean1, mean2, t_statistic, p_value, significant.",
      "hint": "Identify the numeric column with the highest variance, split another numeric column at its median into high/low groups, then compare the two groups with a t\u2011test.",
      "n_steps": 8,
      "difficulty": "HARD",
      "template_name": "ttest_discovered_groups",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 9 keys: \"target_column\", \"grouping_column\", \"group1\", \"group2\", \"mean1\" (rounded to 4 decimals), \"mean2\" (rounded to 4 decimals), \"t_statistic\" (rounded to 4 decimals), \"p_value\" (rounded to 6 decimals), and \"significant\" (boolean, true if p < 0.05). Example: {\"target_column\": \"score\", \"grouping_column\": \"gender\", \"group1\": \"M\", \"group2\": \"F\", \"mean1\": 75.4321, \"mean2\": 78.1234, \"t_statistic\": -2.3456, \"p_value\": 0.019234, \"significant\": true}",
      "ground_truth_hash": "377f80d84a99b8a0",
      "_ground_truth": {
        "target_column": "Insulin",
        "grouping_column": "_binary_group",
        "group1": "high",
        "group2": "low",
        "mean1": 68.3081,
        "mean2": 89.1226,
        "t_statistic": -2.4975,
        "p_value": 0.012716,
        "significant": "True"
      },
      "_template": "ttest_discovered_groups"
    },
    {
      "question": "Is there a numeric measurement in the diabetes dataset that appears to follow a normal distribution? Return as JSON with keys: column, ks_statistic, p_value, is_normal, sample_mean, sample_std.",
      "hint": "Identify the numeric column with the smallest absolute skewness, compute its mean and std, standardize the data, and run a one\u2011sample Kolmogorov\u2013Smirnov test against the standard normal.",
      "n_steps": 7,
      "difficulty": "MEDIUM",
      "template_name": "ks_normality_test",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 6 keys: \"column\" (tested column), \"ks_statistic\" (rounded to 4 decimals), \"p_value\" (rounded to 6 decimals), \"is_normal\" (boolean, true if p >= 0.05), \"sample_mean\" (rounded to 4 decimals), and \"sample_std\" (rounded to 4 decimals). Example: {\"column\": \"height\", \"ks_statistic\": 0.0456, \"p_value\": 0.234567, \"is_normal\": true, \"sample_mean\": 170.1234, \"sample_std\": 10.5678}",
      "ground_truth_hash": "9fc2378a5a3ba655",
      "_ground_truth": {
        "column": "SkinThickness",
        "ks_statistic": 0.1966,
        "p_value": 0.0,
        "is_normal": "False",
        "sample_mean": 20.5365,
        "sample_std": 15.9522
      },
      "_template": "ks_normality_test"
    },
    {
      "question": "Is the most skewed numeric measurement different between patients with high versus low values of another feature? Return as JSON with keys: target_column, grouping_column, group1, group2, median1, median2, u_statistic, p_value.",
      "hint": "Identify the numeric column with the greatest absolute skewness, create a binary group by median\u2011splitting another numeric variable, then compare the groups' medians using a Mann\u2011Whitney U test.",
      "n_steps": 6,
      "difficulty": "MEDIUM",
      "template_name": "mann_whitney_u_test",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 8 keys: \"target_column\", \"grouping_column\", \"group1\", \"group2\", \"median1\" (rounded to 4 decimals), \"median2\" (rounded to 4 decimals), \"u_statistic\" (rounded to 2 decimals), and \"p_value\" (rounded to 6 decimals). Example: {\"target_column\": \"score\", \"grouping_column\": \"treatment\", \"group1\": \"control\", \"group2\": \"experimental\", \"median1\": 72.5000, \"median2\": 78.0000, \"u_statistic\": 1234.50, \"p_value\": 0.034567}",
      "ground_truth_hash": "a2b15f45ab9b7ea5",
      "_ground_truth": {
        "target_column": "Insulin",
        "grouping_column": "_binary_group",
        "group1": "high",
        "group2": "low",
        "median1": 0.0,
        "median2": 63.0,
        "u_statistic": 60181.0,
        "p_value": 9e-06
      },
      "_template": "mann_whitney_u_test"
    },
    {
      "question": "Do the two most skewed positive measurements become more correlated after applying a log transformation? Return as JSON with keys: columns, original_correlation, log_correlation, improvement, transformation_helpful.",
      "hint": "Identify the two numeric columns with the highest absolute skewness (ensuring positivity), compute their Pearson correlation, log\u2011transform both columns (e.g., log1p after shifting if needed), recompute the correlation, and compare the absolute values.",
      "n_steps": 6,
      "difficulty": "HARD",
      "template_name": "correlation_change_analysis",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 5 keys: \"columns\" (list of 2 column names, alphabetically sorted), \"original_correlation\" (Pearson, rounded to 4 decimals), \"log_correlation\" (after log transform, rounded to 4 decimals), \"improvement\" (absolute difference, rounded to 4 decimals), and \"transformation_helpful\" (boolean, true if |log_corr| > |orig_corr|). Example: {\"columns\": [\"income\", \"spending\"], \"original_correlation\": 0.4567, \"log_correlation\": 0.7234, \"improvement\": 0.2667, \"transformation_helpful\": true}",
      "ground_truth_hash": "807cf6b21cc03265",
      "_ground_truth": {
        "columns": [
          "Age",
          "DiabetesPedigreeFunction"
        ],
        "original_correlation": 0.0336,
        "log_correlation": 0.0542,
        "improvement": 0.0206,
        "transformation_helpful": "True"
      },
      "_template": "correlation_change_analysis"
    },
    {
      "question": "Which numeric feature shows the highest variance, and what are its Q1, Q3, IQR, fence values, and outlier count? Return as JSON with keys: column, q1, q3, iqr, lower_fence, upper_fence, n_outliers.",
      "hint": "Identify the column with the largest variance, then compute its 25th and 75th percentiles, IQR, lower/upper fences (1.5*IQR), and count points outside the fences.",
      "n_steps": 5,
      "difficulty": "EASY",
      "template_name": "iqr_outlier_analysis",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 7 keys: \"column\" (analyzed column), \"q1\" (25th percentile rounded to 4 decimals), \"q3\" (75th percentile rounded to 4 decimals), \"iqr\" (rounded to 4 decimals), \"lower_fence\" (rounded to 4 decimals), \"upper_fence\" (rounded to 4 decimals), and \"n_outliers\" (integer count). Example: {\"column\": \"salary\", \"q1\": 45000.0000, \"q3\": 75000.0000, \"iqr\": 30000.0000, \"lower_fence\": 0.0000, \"upper_fence\": 120000.0000, \"n_outliers\": 23}",
      "ground_truth_hash": "7f5e88d827a332ef",
      "_ground_truth": {
        "column": "Insulin",
        "q1": 0.0,
        "q3": 127.25,
        "iqr": 127.25,
        "lower_fence": -190.875,
        "upper_fence": 318.125,
        "n_outliers": 34
      },
      "_template": "iqr_outlier_analysis"
    },
    {
      "question": "Which numeric measurement has the highest variance and does it follow a normal distribution? Return as JSON with keys: distribution, median, iqr.",
      "hint": "Identify the numeric column with the greatest variance, perform a normality test (e.g., Shapiro-Wilk), then output median and IQR if non\u2011normal or mean and std if normal.",
      "n_steps": 5,
      "difficulty": "HARD",
      "template_name": "conditional_normality",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 3 keys. If normal: {\"distribution\": \"normal\", \"mean\": <number>, \"std\": <number>}. If non-normal: {\"distribution\": \"non-normal\", \"median\": <number>, \"iqr\": <number>}. The \"iqr\" value is Q3 minus Q1 as a single number. All numeric values rounded to 3 decimal places.",
      "ground_truth_hash": "a6c31c572df75bf6",
      "_ground_truth": {
        "distribution": "non-normal",
        "median": 30.5,
        "iqr": 127.25
      },
      "_template": "conditional_normality"
    },
    {
      "question": "Which two numeric variables in the diabetes dataset show the strongest correlation, and how does that correlation change after removing outliers? Return as JSON with keys: columns, original_correlation, outliers_removed, clean_correlation.",
      "hint": "Find the pair with the highest absolute Pearson correlation, filter out rows beyond 3\u202f\u00d7\u202fstandard deviation for both columns, then recompute the correlation on the cleaned data.",
      "n_steps": 5,
      "difficulty": "HARD",
      "template_name": "correlation_after_outlier_removal",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 4 keys: \"columns\" (list of 2 column names, alphabetically sorted), \"original_correlation\" (rounded to 3 decimals), \"outliers_removed\" (integer count), and \"clean_correlation\" (rounded to 3 decimals). Example: {\"columns\": [\"col_a\", \"col_b\"], \"original_correlation\": 0.847, \"outliers_removed\": 12, \"clean_correlation\": 0.891}",
      "ground_truth_hash": "75580e090332aa3c",
      "_ground_truth": {
        "columns": [
          "Age",
          "Pregnancies"
        ],
        "original_correlation": 0.544,
        "outliers_removed": 9,
        "clean_correlation": 0.559
      },
      "_template": "correlation_after_outlier_removal"
    },
    {
      "question": "How many numeric variables contain outliers and what is the total number of outlier values in the dataset? Return as JSON with keys: columns_with_outliers, total_outliers.",
      "hint": "Flag values that lie more than 3 standard deviations away from the mean for each numeric column.",
      "n_steps": 4,
      "difficulty": "MEDIUM",
      "template_name": "count_outlier_columns",
      "template_params": {
        "z_threshold": 3.0
      },
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 2 keys: \"columns_with_outliers\" (integer count of columns containing at least one outlier) and \"total_outliers\" (integer total count of outlier values across all columns). Example: {\"columns_with_outliers\": 3, \"total_outliers\": 47}",
      "ground_truth_hash": "9f53cb44274d8cec",
      "_ground_truth": {
        "columns_with_outliers": 8,
        "total_outliers": 93
      },
      "_template": "count_outlier_columns"
    },
    {
      "question": "How many of the clinical measurements contain extreme values, and what is the total number of such outliers? Return as JSON with keys: columns_with_outliers, total_outliers.",
      "hint": "Flag values beyond 2.5\u202f\u00d7\u202fstandard deviation from the mean in each numeric column, then count columns with any flagged values and sum all flagged instances.",
      "n_steps": 4,
      "difficulty": "MEDIUM",
      "template_name": "count_outlier_columns",
      "template_params": {
        "z_threshold": 2.5
      },
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 2 keys: \"columns_with_outliers\" (integer count of columns containing at least one outlier) and \"total_outliers\" (integer total count of outlier values across all columns). Example: {\"columns_with_outliers\": 3, \"total_outliers\": 47}",
      "ground_truth_hash": "7c170ea49c43d633",
      "_ground_truth": {
        "columns_with_outliers": 8,
        "total_outliers": 141
      },
      "_template": "count_outlier_columns"
    },
    {
      "question": "Which numeric measurement in the diabetes dataset shows the greatest relative variability?",
      "hint": "Calculate the coefficient of variation (std/mean*100) for each numeric column and identify the highest; then report its mean and std. Return as JSON with keys: column, cv, mean, std.",
      "n_steps": 4,
      "difficulty": "EASY",
      "template_name": "coefficient_of_variation",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 4 keys: \"column\" (name of column with highest CV), \"cv\" (coefficient of variation as percentage rounded to 2 decimals), \"mean\" (rounded to 4 decimals), and \"std\" (rounded to 4 decimals). Example: {\"column\": \"price\", \"cv\": 45.23, \"mean\": 1234.5678, \"std\": 558.4567}",
      "ground_truth_hash": "3d6cb0c3dcf2ff72",
      "_ground_truth": {
        "column": "Insulin",
        "cv": 144.42,
        "mean": 79.7995,
        "std": 115.244
      },
      "_template": "coefficient_of_variation"
    },
    {
      "question": "Which two numeric variables in the dataset show the strongest correlation? Return as JSON with keys: columns, correlation.",
      "hint": "Calculate the absolute correlation matrix, set the diagonal to zero, and identify the pair with the highest off\u2011diagonal value.",
      "n_steps": 4,
      "difficulty": "MEDIUM",
      "template_name": "strongest_correlation",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly two keys: \"columns\" (a list of the two column names, alphabetically sorted) and \"correlation\" (the correlation coefficient rounded to 3 decimal places). Example: {\"columns\": [\"col_a\", \"col_b\"], \"correlation\": 0.847}",
      "ground_truth_hash": "5effc0aac9988557",
      "_ground_truth": {
        "columns": [
          "Age",
          "Pregnancies"
        ],
        "correlation": 0.544
      },
      "_template": "strongest_correlation"
    },
    {
      "question": "Which pair of numeric measurements in the diabetes dataset are the least correlated? Return as JSON with keys: columns, correlation.",
      "hint": "Compute the absolute correlation matrix, ignore the diagonal, and identify the smallest non\u2011zero correlation.",
      "n_steps": 4,
      "difficulty": "MEDIUM",
      "template_name": "weakest_correlation",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly two keys: \"columns\" (a list of the two column names, alphabetically sorted) and \"correlation\" (the absolute correlation value rounded to 3 decimal places). Example: {\"columns\": [\"col_a\", \"col_b\"], \"correlation\": 0.012}",
      "ground_truth_hash": "50c6a02cd29b17cf",
      "_ground_truth": {
        "columns": [
          "BMI",
          "Pregnancies"
        ],
        "correlation": 0.018
      },
      "_template": "weakest_correlation"
    },
    {
      "question": "Which measurement in the dataset varies the most, and what is its average value? Return as JSON with keys: question, hint.",
      "hint": "Identify the numeric column with the highest variance, then compute its mean.",
      "n_steps": 3,
      "difficulty": "MEDIUM",
      "template_name": "max_variance_mean",
      "template_params": null,
      "output_type": "scalar",
      "output_schema": "A single number (the mean), rounded to 3 decimal places",
      "ground_truth_hash": "6314c4ac2d1c3757",
      "_ground_truth": 79.799,
      "_template": "max_variance_mean"
    },
    {
      "question": "Which measurement in the dataset tends to have the lowest average value, and how much does it vary?",
      "hint": "Identify the numeric column with the smallest mean, then calculate its standard deviation. Return as JSON with keys: question, hint.",
      "n_steps": 3,
      "difficulty": "MEDIUM",
      "template_name": "min_mean_column_std",
      "template_params": null,
      "output_type": "scalar",
      "output_schema": "A single number (the standard deviation), rounded to 3 decimal places",
      "ground_truth_hash": "646c5c23791310cd",
      "_ground_truth": 0.477,
      "_template": "min_mean_column_std"
    },
    {
      "question": "I wonder if any of the variables have a substantial amount of missing data. Return as JSON with keys: count, columns.",
      "hint": "Calculate the missing percentage for each column and identify those above a 5% threshold.",
      "n_steps": 3,
      "difficulty": "EASY",
      "template_name": "count_high_missing_columns",
      "template_params": {
        "missing_threshold": 5.0
      },
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 2 keys: \"count\" (integer) and \"columns\" (list of column names, alphabetically sorted). Example: {\"count\": 3, \"columns\": [\"col_a\", \"col_b\", \"col_c\"]}",
      "ground_truth_hash": "2c42c4348e535666",
      "_ground_truth": {
        "count": 0,
        "columns": []
      },
      "_template": "count_high_missing_columns"
    },
    {
      "question": "Are there any features in this dataset that have a high proportion of missing values? Return as JSON with keys: count, columns.",
      "hint": "Calculate the missing percentage for each column and count those above a 10% threshold.",
      "n_steps": 3,
      "difficulty": "EASY",
      "template_name": "count_high_missing_columns",
      "template_params": {
        "missing_threshold": 10.0
      },
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 2 keys: \"count\" (integer) and \"columns\" (list of column names, alphabetically sorted). Example: {\"count\": 3, \"columns\": [\"col_a\", \"col_b\", \"col_c\"]}",
      "ground_truth_hash": "2c42c4348e535666",
      "_ground_truth": {
        "count": 0,
        "columns": []
      },
      "_template": "count_high_missing_columns"
    },
    {
      "question": "Which numeric measurement in the diabetes dataset has the largest range, and what are its 10th, 25th, 50th, 75th, and 90th percentiles? Return as JSON with keys: column, p10, p25, p50, p75, p90.",
      "hint": "Find the column with the biggest max\u2011min difference, then compute the specified percentiles for that column.",
      "n_steps": 3,
      "difficulty": "EASY",
      "template_name": "percentile_ranking",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 6 keys: \"column\" (analyzed column), \"p10\" (10th percentile rounded to 4 decimals), \"p25\" (25th percentile), \"p50\" (median), \"p75\" (75th percentile), and \"p90\" (90th percentile). Example: {\"column\": \"income\", \"p10\": 25000.0000, \"p25\": 40000.0000, \"p50\": 55000.0000, \"p75\": 75000.0000, \"p90\": 100000.0000}",
      "ground_truth_hash": "52523373cfda0e6f",
      "_ground_truth": {
        "column": "Insulin",
        "p10": 0.0,
        "p25": 0.0,
        "p50": 30.5,
        "p75": 127.25,
        "p90": 210.0
      },
      "_template": "percentile_ranking"
    },
    {
      "question": "Which numeric measurement in the diabetes dataset exhibits the highest variability? Return as JSON with keys: column, count, mean, std, min, max, median, skewness, kurtosis.",
      "hint": "Identify the numeric column with the largest variance, then compute its descriptive statistics.",
      "n_steps": 3,
      "difficulty": "EASY",
      "template_name": "descriptive_summary",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 9 keys: \"column\", \"count\" (integer), \"mean\" (rounded to 4 decimals), \"std\", \"min\", \"max\", \"median\", \"skewness\", and \"kurtosis\" (all rounded to 4 decimals). Example: {\"column\": \"age\", \"count\": 1000, \"mean\": 35.4567, \"std\": 12.3456, \"min\": 18.0000, \"max\": 85.0000, \"median\": 34.0000, \"skewness\": 0.5678, \"kurtosis\": -0.2345}",
      "ground_truth_hash": "7ba0029e52bec2d2",
      "_ground_truth": {
        "column": "Insulin",
        "count": 768,
        "mean": 79.7995,
        "std": 115.244,
        "min": 0.0,
        "max": 846.0,
        "median": 30.5,
        "skewness": 2.2723,
        "kurtosis": 7.2143
      },
      "_template": "descriptive_summary"
    }
  ]
}