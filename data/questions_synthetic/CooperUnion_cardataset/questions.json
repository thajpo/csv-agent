{
  "dataset_columns": [
    "Make",
    "Model",
    "Year",
    "Engine Fuel Type",
    "Engine HP",
    "Engine Cylinders",
    "Transmission Type",
    "Driven_Wheels",
    "Number of Doors",
    "Market Category",
    "Vehicle Size",
    "Vehicle Style",
    "highway MPG",
    "city mpg",
    "Popularity",
    "MSRP"
  ],
  "questions": [
    {
      "question": "Which numeric variable in this car dataset varies the most and can be explained by a few other measurements?",
      "hint": "Find the numeric column with highest variance, compute its absolute correlations with the other numeric columns, select the three strongest predictors, fit an OLS regression and report the model statistics. Return as JSON with keys: target, predictors, r_squared, adj_r_squared, n_significant, coefficients, p_values.",
      "n_steps": 10,
      "difficulty": "VERY_HARD",
      "template_name": "multiple_regression_top_predictors",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 6 keys: \"target\" (column name), \"predictors\" (list of 3 column names), \"r_squared\" (rounded to 4 decimals), \"adj_r_squared\" (rounded to 4 decimals), \"n_significant\" (integer count of predictors with p < 0.05), \"coefficients\" (dict mapping predictor names to coefficients rounded to 4 decimals), and \"p_values\" (dict mapping predictor names to p-values rounded to 6 decimals). Example: {\"target\": \"price\", \"predictors\": [\"sqft\", \"bedrooms\", \"age\"], \"r_squared\": 0.7234, \"adj_r_squared\": 0.7156, \"n_significant\": 2, \"coefficients\": {\"sqft\": 123.45, \"bedrooms\": 5000.12, \"age\": -200.34}, \"p_values\": {\"sqft\": 0.000001, \"bedrooms\": 0.023456, \"age\": 0.156789}}",
      "ground_truth_hash": "e05ac5b010c8c0d6",
      "_ground_truth": {
        "target": "MSRP",
        "predictors": [
          "Engine HP",
          "Engine Cylinders",
          "Year"
        ],
        "r_squared": 0.441,
        "adj_r_squared": 0.4409,
        "n_significant": 3,
        "coefficients": {
          "Engine HP": 321.4695,
          "Engine Cylinders": 3140.3893,
          "Year": 198.458
        },
        "p_values": {
          "Engine HP": 0.0,
          "Engine Cylinders": 0.0,
          "Year": 0.00393
        }
      },
      "_template": "multiple_regression_top_predictors"
    },
    {
      "question": "Which numeric feature in the car dataset is the most skewed, and what are its mean and 95% confidence interval? Return as JSON with keys: column, skewness, mean, ci_lower, ci_upper, std_error, n_bootstrap.",
      "hint": "Calculate absolute skewness for each numeric column, select the highest, then use bootstrap resampling to estimate its mean, confidence interval, and standard error.",
      "n_steps": 9,
      "difficulty": "VERY_HARD",
      "template_name": "bootstrap_ci_discovered",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 7 keys: \"column\" (name of most skewed column), \"skewness\" (rounded to 4 decimals), \"mean\" (rounded to 4 decimals), \"ci_lower\" (lower bound of 95% CI, rounded to 4 decimals), \"ci_upper\" (upper bound, rounded to 4 decimals), \"std_error\" (bootstrap standard error, rounded to 4 decimals), and \"n_bootstrap\" (integer, the number of bootstrap samples). Example: {\"column\": \"income\", \"skewness\": 2.3456, \"mean\": 50000.1234, \"ci_lower\": 48500.5678, \"ci_upper\": 51500.9012, \"std_error\": 750.3456, \"n_bootstrap\": 1000}",
      "ground_truth_hash": "24b39fb826072f53",
      "_ground_truth": {
        "column": "MSRP",
        "skewness": 11.772,
        "mean": 40594.737,
        "ci_lower": 39546.751,
        "ci_upper": 41709.8884,
        "std_error": 558.5736,
        "n_bootstrap": 1000
      },
      "_template": "bootstrap_ci_discovered"
    },
    {
      "question": "Does the numeric feature with the highest variability differ significantly across a categorical variable that has a moderate number of groups? Return as JSON with keys: target_column, grouping_column, n_groups, f_statistic, p_value, significant, best_group, best_mean, worst_group, worst_mean, eta_squared.",
      "hint": "Find the numeric column with the largest variance, select a categorical column with 3\u201110 unique values, compute group means and perform a one\u2011way ANOVA.",
      "n_steps": 9,
      "difficulty": "VERY_HARD",
      "template_name": "anova_discovered_groups",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 11 keys: \"target_column\", \"grouping_column\", \"n_groups\" (integer), \"f_statistic\" (rounded to 4 decimals), \"p_value\" (rounded to 6 decimals), \"significant\" (boolean), \"best_group\" (category with highest mean), \"best_mean\" (rounded to 4 decimals), \"worst_group\" (category with lowest mean), \"worst_mean\" (rounded to 4 decimals), and \"eta_squared\" (effect size, rounded to 4 decimals). Example: {\"target_column\": \"sales\", \"grouping_column\": \"region\", \"n_groups\": 4, \"f_statistic\": 15.2345, \"p_value\": 0.000012, \"significant\": true, \"best_group\": \"West\", \"best_mean\": 1234.5678, \"worst_group\": \"East\", \"worst_mean\": 890.1234, \"eta_squared\": 0.1523}",
      "ground_truth_hash": "d27822de03b00bd5",
      "_ground_truth": {
        "target_column": "MSRP",
        "grouping_column": "Engine Fuel Type",
        "n_groups": 10,
        "f_statistic": 425.8813,
        "p_value": 0.0,
        "significant": "True",
        "best_group": "flex-fuel (premium unleaded required/E85)",
        "best_mean": 159429.3519,
        "worst_group": "regular unleaded",
        "worst_mean": 23013.9555,
        "eta_squared": 0.2436
      },
      "_template": "anova_discovered_groups"
    },
    {
      "question": "Which numeric feature most strongly predicts the vehicle price? Return as JSON with keys: target, best_predictor, correlation, r_squared, coefficient, p_value.",
      "hint": "Find the numeric column with the greatest variance, compute absolute correlations with it, pick the highest, and fit a simple OLS regression.",
      "n_steps": 8,
      "difficulty": "HARD",
      "template_name": "regression_most_predictive",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 6 keys: \"target\" (column name), \"best_predictor\" (column name), \"correlation\" (rounded to 3 decimals), \"r_squared\" (rounded to 4 decimals), \"coefficient\" (rounded to 4 decimals), and \"p_value\" (rounded to 6 decimals). Example: {\"target\": \"price\", \"best_predictor\": \"sqft\", \"correlation\": 0.834, \"r_squared\": 0.6956, \"coefficient\": 135.2847, \"p_value\": 0.000001}",
      "ground_truth_hash": "6d3ba176d18f6611",
      "_ground_truth": {
        "target": "MSRP",
        "best_predictor": "Engine HP",
        "correlation": 0.662,
        "r_squared": 0.4383,
        "coefficient": 365.2884,
        "p_value": 0.0
      },
      "_template": "regression_most_predictive"
    },
    {
      "question": "Does the most variable numeric measurement differ significantly between two groups formed by a binary split of another feature? Return as JSON with keys: target_column, grouping_column, group1, group2, mean1, mean2, t_statistic, p_value, significant.",
      "hint": "Find the numeric column with highest variance, create a binary grouping (e.g., median split of another column), then compare group means with a t-test.",
      "n_steps": 8,
      "difficulty": "HARD",
      "template_name": "ttest_discovered_groups",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 9 keys: \"target_column\", \"grouping_column\", \"group1\", \"group2\", \"mean1\" (rounded to 4 decimals), \"mean2\" (rounded to 4 decimals), \"t_statistic\" (rounded to 4 decimals), \"p_value\" (rounded to 6 decimals), and \"significant\" (boolean, true if p < 0.05). Example: {\"target_column\": \"score\", \"grouping_column\": \"gender\", \"group1\": \"M\", \"group2\": \"F\", \"mean1\": 75.4321, \"mean2\": 78.1234, \"t_statistic\": -2.3456, \"p_value\": 0.019234, \"significant\": true}",
      "ground_truth_hash": "f54634d305651282",
      "_ground_truth": {
        "target_column": "MSRP",
        "grouping_column": "_binary_group",
        "group1": "low",
        "group2": "high",
        "mean1": 38498.5876,
        "mean2": 45027.6136,
        "t_statistic": -5.5422,
        "p_value": 0.0,
        "significant": "True"
      },
      "_template": "ttest_discovered_groups"
    },
    {
      "question": "I wonder which numeric feature in the vehicle dataset is closest to a normal distribution. Return as JSON with keys: column, ks_statistic, p_value, is_normal, sample_mean, sample_std.",
      "hint": "Identify the numeric column with the smallest absolute skewness, compute its mean and std, standardize the data, perform a K\u2011S test against a standard normal, and report the results.",
      "n_steps": 7,
      "difficulty": "MEDIUM",
      "template_name": "ks_normality_test",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 6 keys: \"column\" (tested column), \"ks_statistic\" (rounded to 4 decimals), \"p_value\" (rounded to 6 decimals), \"is_normal\" (boolean, true if p >= 0.05), \"sample_mean\" (rounded to 4 decimals), and \"sample_std\" (rounded to 4 decimals). Example: {\"column\": \"height\", \"ks_statistic\": 0.0456, \"p_value\": 0.234567, \"is_normal\": true, \"sample_mean\": 170.1234, \"sample_std\": 10.5678}",
      "ground_truth_hash": "7029168c953c6120",
      "_ground_truth": {
        "column": "Engine Cylinders",
        "ks_statistic": 0.2269,
        "p_value": 0.0,
        "is_normal": "False",
        "sample_mean": 5.6288,
        "sample_std": 1.7806
      },
      "_template": "ks_normality_test"
    },
    {
      "question": "Is the numeric feature with the greatest variability distributed equally across the groups of a low\u2011cardinality categorical attribute? Return as JSON with keys: target_column, grouping_column, n_groups, levene_statistic, p_value, variances_equal, group_variances.",
      "hint": "Identify the numeric column with the highest variance, choose a categorical column with 2\u20116 distinct values, then assess variance equality across its groups using Levene\u2019s test.",
      "n_steps": 7,
      "difficulty": "HARD",
      "template_name": "levene_variance_test",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 7 keys: \"target_column\", \"grouping_column\", \"n_groups\" (integer), \"levene_statistic\" (rounded to 4 decimals), \"p_value\" (rounded to 6 decimals), \"variances_equal\" (boolean, true if p >= 0.05), and \"group_variances\" (dict mapping group names to variance rounded to 4 decimals). Example: {\"target_column\": \"score\", \"grouping_column\": \"class\", \"n_groups\": 3, \"levene_statistic\": 2.3456, \"p_value\": 0.098765, \"variances_equal\": true, \"group_variances\": {\"A\": 123.4567, \"B\": 145.6789, \"C\": 112.3456}}",
      "ground_truth_hash": "a7876ccc1f22befe",
      "_ground_truth": {
        "target_column": "MSRP",
        "grouping_column": "Transmission Type",
        "n_groups": 5,
        "levene_statistic": 124.1131,
        "p_value": 0.0,
        "variances_equal": "False",
        "group_variances": {
          "AUTOMATED_MANUAL": 26402197015.2896,
          "AUTOMATIC": 2292347266.1864,
          "DIRECT_DRIVE": 644438787.5933,
          "MANUAL": 1628348381.5783,
          "UNKNOWN": 5423346.3158
        }
      },
      "_template": "levene_variance_test"
    },
    {
      "question": "Does the most skewed numeric feature differ between two opposite groups? Return as JSON with keys: target_column, grouping_column, group1, group2, median1, median2, u_statistic, p_value.",
      "hint": "Find the numeric column with the highest absolute skew, create a binary grouping column (e.g., median split on another numeric variable), then compare the groups using medians and a Mann\u2011Whitney U test.",
      "n_steps": 6,
      "difficulty": "MEDIUM",
      "template_name": "mann_whitney_u_test",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 8 keys: \"target_column\", \"grouping_column\", \"group1\", \"group2\", \"median1\" (rounded to 4 decimals), \"median2\" (rounded to 4 decimals), \"u_statistic\" (rounded to 2 decimals), and \"p_value\" (rounded to 6 decimals). Example: {\"target_column\": \"score\", \"grouping_column\": \"treatment\", \"group1\": \"control\", \"group2\": \"experimental\", \"median1\": 72.5000, \"median2\": 78.0000, \"u_statistic\": 1234.50, \"p_value\": 0.034567}",
      "ground_truth_hash": "29bad52dc1240156",
      "_ground_truth": {
        "target_column": "MSRP",
        "grouping_column": "_binary_group",
        "group1": "low",
        "group2": "high",
        "median1": 26985.0,
        "median2": 36320.0,
        "u_statistic": 10057082.0,
        "p_value": 0.0
      },
      "_template": "mann_whitney_u_test"
    },
    {
      "question": "Which pair of numeric vehicle attributes shows the strongest monotonic relationship? Return as JSON with keys: columns, spearman_rho, p_value, interpretation.",
      "hint": "Calculate the Spearman correlation matrix for all numeric columns, identify the pair with the highest absolute correlation, then compute its rho and p\u2011value.",
      "n_steps": 6,
      "difficulty": "MEDIUM",
      "template_name": "spearman_rank_correlation",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 4 keys: \"columns\" (list of 2 column names, alphabetically sorted), \"spearman_rho\" (correlation coefficient rounded to 4 decimals), \"p_value\" (rounded to 6 decimals), and \"interpretation\" (string: \"strong\", \"moderate\", \"weak\", or \"negligible\"). Example: {\"columns\": [\"age\", \"income\"], \"spearman_rho\": 0.7234, \"p_value\": 0.000001, \"interpretation\": \"strong\"}",
      "ground_truth_hash": "88fb4e0b10ea270e",
      "_ground_truth": {
        "columns": [
          "city mpg",
          "highway MPG"
        ],
        "spearman_rho": 0.9513,
        "p_value": 0.0,
        "interpretation": "strong"
      },
      "_template": "spearman_rank_correlation"
    },
    {
      "question": "I wonder if any two numeric features are weakly correlated originally but become more strongly related after applying a log transformation. Return as JSON with keys: columns, original_correlation, log_correlation, improvement, transformation_helpful.",
      "hint": "Identify the two most skewed positive numeric columns, compute their Pearson correlation, then log\u2011transform both columns and recompute the correlation to compare the absolute values.",
      "n_steps": 6,
      "difficulty": "HARD",
      "template_name": "correlation_change_analysis",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 5 keys: \"columns\" (list of 2 column names, alphabetically sorted), \"original_correlation\" (Pearson, rounded to 4 decimals), \"log_correlation\" (after log transform, rounded to 4 decimals), \"improvement\" (absolute difference, rounded to 4 decimals), and \"transformation_helpful\" (boolean, true if |log_corr| > |orig_corr|). Example: {\"columns\": [\"income\", \"spending\"], \"original_correlation\": 0.4567, \"log_correlation\": 0.7234, \"improvement\": 0.2667, \"transformation_helpful\": true}",
      "ground_truth_hash": "ceb9a9da6a8d6fea",
      "_ground_truth": {
        "columns": [
          "MSRP",
          "highway MPG"
        ],
        "original_correlation": -0.16,
        "log_correlation": 0.0595,
        "improvement": 0.1006,
        "transformation_helpful": "False"
      },
      "_template": "correlation_change_analysis"
    },
    {
      "question": "Which numeric attribute in the dataset has the highest variance and what are its Q1, Q3, IQR, lower and upper fences, and outlier count? Return as JSON with keys: column, q1, q3, iqr, lower_fence, upper_fence, n_outliers.",
      "hint": "Find the numeric column with the greatest spread, then compute its quartiles and apply the 1.5*IQR rule for fences.",
      "n_steps": 5,
      "difficulty": "EASY",
      "template_name": "iqr_outlier_analysis",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 7 keys: \"column\" (analyzed column), \"q1\" (25th percentile rounded to 4 decimals), \"q3\" (75th percentile rounded to 4 decimals), \"iqr\" (rounded to 4 decimals), \"lower_fence\" (rounded to 4 decimals), \"upper_fence\" (rounded to 4 decimals), and \"n_outliers\" (integer count). Example: {\"column\": \"salary\", \"q1\": 45000.0000, \"q3\": 75000.0000, \"iqr\": 30000.0000, \"lower_fence\": 0.0000, \"upper_fence\": 120000.0000, \"n_outliers\": 23}",
      "ground_truth_hash": "655cc356b77193cc",
      "_ground_truth": {
        "column": "MSRP",
        "q1": 21000.0,
        "q3": 42231.25,
        "iqr": 21231.25,
        "lower_fence": -10846.875,
        "upper_fence": 74078.125,
        "n_outliers": 996
      },
      "_template": "iqr_outlier_analysis"
    },
    {
      "question": "What is the distribution of the most variable numeric measurement in this vehicle dataset? Return as JSON with keys: distribution, median, iqr.",
      "hint": "Find the numeric column with the highest variance, test its normality (e.g., Shapiro-Wilk), and report median and IQR if non\u2011normal or mean and std if normal.",
      "n_steps": 5,
      "difficulty": "HARD",
      "template_name": "conditional_normality",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 3 keys. If normal: {\"distribution\": \"normal\", \"mean\": <number>, \"std\": <number>}. If non-normal: {\"distribution\": \"non-normal\", \"median\": <number>, \"iqr\": <number>}. The \"iqr\" value is Q3 minus Q1 as a single number. All numeric values rounded to 3 decimal places.",
      "ground_truth_hash": "44fb1e6579e22a02",
      "_ground_truth": {
        "distribution": "non-normal",
        "median": 29995.0,
        "iqr": 21231.25
      },
      "_template": "conditional_normality"
    },
    {
      "question": "Which car attribute category shows the highest average price? Return as JSON with keys: category_column, best_category, target_column, mean_value.",
      "hint": "Identify the numeric column with the greatest variance, select a categorical column with moderate cardinality, then compare the mean values of the target across its categories.",
      "n_steps": 5,
      "difficulty": "HARD",
      "template_name": "category_highest_target_mean",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 4 keys: \"category_column\" (the grouping column name), \"best_category\" (the category value with highest mean), \"target_column\" (the numeric column analyzed), and \"mean_value\" (rounded to 3 decimal places). Example: {\"category_column\": \"region\", \"best_category\": \"West\", \"target_column\": \"sales\", \"mean_value\": 1234.567}",
      "ground_truth_hash": "0e932edc2679b890",
      "_ground_truth": {
        "category_column": "Engine Fuel Type",
        "best_category": "flex-fuel (premium unleaded required/E85)",
        "target_column": "MSRP",
        "mean_value": 159429.352
      },
      "_template": "category_highest_target_mean"
    },
    {
      "question": "Which two numeric attributes in the vehicle dataset have the strongest correlation, and how does that relationship shift after discarding extreme outliers? Return as JSON with keys: columns, original_correlation, outliers_removed, clean_correlation.",
      "hint": "Identify the highest absolute Pearson correlation among numeric columns, filter rows that lie beyond three standard deviations for both columns, then recompute the correlation on the cleaned data.",
      "n_steps": 5,
      "difficulty": "HARD",
      "template_name": "correlation_after_outlier_removal",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 4 keys: \"columns\" (list of 2 column names, alphabetically sorted), \"original_correlation\" (rounded to 3 decimals), \"outliers_removed\" (integer count), and \"clean_correlation\" (rounded to 3 decimals). Example: {\"columns\": [\"col_a\", \"col_b\"], \"original_correlation\": 0.847, \"outliers_removed\": 12, \"clean_correlation\": 0.891}",
      "ground_truth_hash": "cb2d1a4c5a2380b9",
      "_ground_truth": {
        "columns": [
          "city mpg",
          "highway MPG"
        ],
        "original_correlation": 0.887,
        "outliers_removed": 113,
        "clean_correlation": 0.926
      },
      "_template": "correlation_after_outlier_removal"
    },
    {
      "question": "How many numeric features contain outliers and what is the total number of outlier values in the dataset? Return as JSON with keys: columns_with_outliers, total_outliers.",
      "hint": "Use a 3\u2011standard\u2011deviation rule on each numeric column to flag outliers, then count columns with any and sum all outlier occurrences.",
      "n_steps": 4,
      "difficulty": "MEDIUM",
      "template_name": "count_outlier_columns",
      "template_params": {
        "z_threshold": 3.0
      },
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 2 keys: \"columns_with_outliers\" (integer count of columns containing at least one outlier) and \"total_outliers\" (integer total count of outlier values across all columns). Example: {\"columns_with_outliers\": 3, \"total_outliers\": 47}",
      "ground_truth_hash": "1452922e58c3f941",
      "_ground_truth": {
        "columns_with_outliers": 5,
        "total_outliers": 877
      },
      "_template": "count_outlier_columns"
    },
    {
      "question": "I wonder how many extreme values are present across the numeric features in this car dataset. Return as JSON with keys: columns_with_outliers, total_outliers.",
      "hint": "Flag values beyond 2.5 standard deviations from the mean for each numeric column, then count columns with any outliers and sum all outlier instances.",
      "n_steps": 4,
      "difficulty": "MEDIUM",
      "template_name": "count_outlier_columns",
      "template_params": {
        "z_threshold": 2.5
      },
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 2 keys: \"columns_with_outliers\" (integer count of columns containing at least one outlier) and \"total_outliers\" (integer total count of outlier values across all columns). Example: {\"columns_with_outliers\": 3, \"total_outliers\": 47}",
      "ground_truth_hash": "d4e111322b5f2c76",
      "_ground_truth": {
        "columns_with_outliers": 7,
        "total_outliers": 2370
      },
      "_template": "count_outlier_columns"
    },
    {
      "question": "Which numeric attribute in the vehicle dataset exhibits the greatest relative variability? Return as JSON with keys: column, cv, mean, std.",
      "hint": "Calculate the coefficient of variation (std/mean * 100) for each numeric column and identify the one with the highest value, then report its mean and standard deviation.",
      "n_steps": 4,
      "difficulty": "EASY",
      "template_name": "coefficient_of_variation",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 4 keys: \"column\" (name of column with highest CV), \"cv\" (coefficient of variation as percentage rounded to 2 decimals), \"mean\" (rounded to 4 decimals), and \"std\" (rounded to 4 decimals). Example: {\"column\": \"price\", \"cv\": 45.23, \"mean\": 1234.5678, \"std\": 558.4567}",
      "ground_truth_hash": "5ac456a40a8bc3d5",
      "_ground_truth": {
        "column": "MSRP",
        "cv": 148.07,
        "mean": 40594.737,
        "std": 60109.1036
      },
      "_template": "coefficient_of_variation"
    },
    {
      "question": "Which pair of numeric features in this vehicle dataset have the strongest linear relationship? Return as JSON with keys: columns, correlation.",
      "hint": "Calculate the absolute correlation matrix for all numeric columns, set the diagonal to zero, and identify the pair with the highest value.",
      "n_steps": 4,
      "difficulty": "MEDIUM",
      "template_name": "strongest_correlation",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly two keys: \"columns\" (a list of the two column names, alphabetically sorted) and \"correlation\" (the correlation coefficient rounded to 3 decimal places). Example: {\"columns\": [\"col_a\", \"col_b\"], \"correlation\": 0.847}",
      "ground_truth_hash": "5b9cd0a118b8179f",
      "_ground_truth": {
        "columns": [
          "city mpg",
          "highway MPG"
        ],
        "correlation": 0.887
      },
      "_template": "strongest_correlation"
    },
    {
      "question": "Which two numeric attributes in this vehicle dataset are the least correlated with each other? Return as JSON with keys: columns, correlation.",
      "hint": "Calculate the absolute correlation matrix for all numeric columns, ignore the diagonal, and identify the pair with the smallest non\u2011zero correlation.",
      "n_steps": 4,
      "difficulty": "MEDIUM",
      "template_name": "weakest_correlation",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly two keys: \"columns\" (a list of the two column names, alphabetically sorted) and \"correlation\" (the absolute correlation value rounded to 3 decimal places). Example: {\"columns\": [\"col_a\", \"col_b\"], \"correlation\": 0.012}",
      "ground_truth_hash": "599bf04e4cbcff5f",
      "_ground_truth": {
        "columns": [
          "Popularity",
          "city mpg"
        ],
        "correlation": 0.003
      },
      "_template": "weakest_correlation"
    },
    {
      "question": "Which numeric feature shows the greatest variability among the cars, and what is its average? Return as JSON with keys: mean.",
      "hint": "Identify the numeric column with the highest variance, then compute its mean.",
      "n_steps": 3,
      "difficulty": "MEDIUM",
      "template_name": "max_variance_mean",
      "template_params": null,
      "output_type": "scalar",
      "output_schema": "A single number (the mean), rounded to 3 decimal places",
      "ground_truth_hash": "adb75493ad6e4261",
      "_ground_truth": 40594.737,
      "_template": "max_variance_mean"
    },
    {
      "question": "Which numeric attribute has the smallest average value, and what is its standard deviation? Return as JSON with key: std.",
      "hint": "Identify the numeric column with the lowest mean, then calculate its standard deviation.",
      "n_steps": 3,
      "difficulty": "MEDIUM",
      "template_name": "min_mean_column_std",
      "template_params": null,
      "output_type": "scalar",
      "output_schema": "A single number (the standard deviation), rounded to 3 decimal places",
      "ground_truth_hash": "88c31da5d6f5989f",
      "_ground_truth": 0.881,
      "_template": "min_mean_column_std"
    },
    {
      "question": "Which columns in the dataset have a substantial amount of missing data? Return as JSON with keys: count, columns.",
      "hint": "Compute the percentage of missing values for each column and list those exceeding a 5% threshold.",
      "n_steps": 3,
      "difficulty": "EASY",
      "template_name": "count_high_missing_columns",
      "template_params": {
        "missing_threshold": 5.0
      },
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 2 keys: \"count\" (integer) and \"columns\" (list of column names, alphabetically sorted). Example: {\"count\": 3, \"columns\": [\"col_a\", \"col_b\", \"col_c\"]}",
      "ground_truth_hash": "94bbd4ccc69daf14",
      "_ground_truth": {
        "count": 1,
        "columns": [
          "Market Category"
        ]
      },
      "_template": "count_high_missing_columns"
    },
    {
      "question": "Which features in the dataset have a large amount of missing data? Return as JSON with keys: count, columns.",
      "hint": "Compute the percentage of missing values for each column and list those exceeding 10%.",
      "n_steps": 3,
      "difficulty": "EASY",
      "template_name": "count_high_missing_columns",
      "template_params": {
        "missing_threshold": 10.0
      },
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 2 keys: \"count\" (integer) and \"columns\" (list of column names, alphabetically sorted). Example: {\"count\": 3, \"columns\": [\"col_a\", \"col_b\", \"col_c\"]}",
      "ground_truth_hash": "94bbd4ccc69daf14",
      "_ground_truth": {
        "count": 1,
        "columns": [
          "Market Category"
        ]
      },
      "_template": "count_high_missing_columns"
    },
    {
      "question": "Which numeric attribute in the vehicle dataset has the largest range, and what are its 10th, 25th, 50th, 75th, and 90th percentiles? Return as JSON with keys: column, p10, p25, p50, p75, p90.",
      "hint": "Identify the numeric column with the biggest max\u2011min difference, then compute its specified percentiles.",
      "n_steps": 3,
      "difficulty": "EASY",
      "template_name": "percentile_ranking",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 6 keys: \"column\" (analyzed column), \"p10\" (10th percentile rounded to 4 decimals), \"p25\" (25th percentile), \"p50\" (median), \"p75\" (75th percentile), and \"p90\" (90th percentile). Example: {\"column\": \"income\", \"p10\": 25000.0000, \"p25\": 40000.0000, \"p50\": 55000.0000, \"p75\": 75000.0000, \"p90\": 100000.0000}",
      "ground_truth_hash": "f65096ac17e2fc61",
      "_ground_truth": {
        "column": "MSRP",
        "p10": 2254.6,
        "p25": 21000.0,
        "p50": 29995.0,
        "p75": 42231.25,
        "p90": 65080.0
      },
      "_template": "percentile_ranking"
    },
    {
      "question": "Which numeric attribute in the vehicle dataset shows the greatest variability, and what are its core descriptive statistics? Return as JSON with keys: column, count, mean, std, min, max, median, skewness, kurtosis.",
      "hint": "Identify the numeric column with the highest variance, then compute its count, mean, standard deviation, min, max, median, skewness, and kurtosis.",
      "n_steps": 3,
      "difficulty": "EASY",
      "template_name": "descriptive_summary",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 9 keys: \"column\", \"count\" (integer), \"mean\" (rounded to 4 decimals), \"std\", \"min\", \"max\", \"median\", \"skewness\", and \"kurtosis\" (all rounded to 4 decimals). Example: {\"column\": \"age\", \"count\": 1000, \"mean\": 35.4567, \"std\": 12.3456, \"min\": 18.0000, \"max\": 85.0000, \"median\": 34.0000, \"skewness\": 0.5678, \"kurtosis\": -0.2345}",
      "ground_truth_hash": "41713cb30172c5a5",
      "_ground_truth": {
        "column": "MSRP",
        "count": 11914,
        "mean": 40594.737,
        "std": 60109.1036,
        "min": 2000.0,
        "max": 2065902.0,
        "median": 29995.0,
        "skewness": 11.772,
        "kurtosis": 268.9263
      },
      "_template": "descriptive_summary"
    }
  ]
}