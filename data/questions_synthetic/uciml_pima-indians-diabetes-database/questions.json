{
  "dataset_columns": [
    "Pregnancies",
    "Glucose",
    "BloodPressure",
    "SkinThickness",
    "Insulin",
    "BMI",
    "DiabetesPedigreeFunction",
    "Age",
    "Outcome"
  ],
  "questions": [
    {
      "question": "Which numeric variable that varies the most can be explained by other clinical measurements? Return as JSON with keys: target, predictors, r_squared, adj_r_squared, n_significant, coefficients, p_values.",
      "hint": "Pick the column with highest variance, select its three strongest numeric correlates, fit an OLS regression, and report the model fit and significance.",
      "n_steps": 10,
      "difficulty": "VERY_HARD",
      "template_name": "multiple_regression_top_predictors",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 6 keys: \"target\" (column name), \"predictors\" (list of 3 column names), \"r_squared\" (rounded to 4 decimals), \"adj_r_squared\" (rounded to 4 decimals), \"n_significant\" (integer count of predictors with p < 0.05), \"coefficients\" (dict mapping predictor names to coefficients rounded to 4 decimals), and \"p_values\" (dict mapping predictor names to p-values rounded to 6 decimals). Example: {\"target\": \"price\", \"predictors\": [\"sqft\", \"bedrooms\", \"age\"], \"r_squared\": 0.7234, \"adj_r_squared\": 0.7156, \"n_significant\": 2, \"coefficients\": {\"sqft\": 123.45, \"bedrooms\": 5000.12, \"age\": -200.34}, \"p_values\": {\"sqft\": 0.000001, \"bedrooms\": 0.023456, \"age\": 0.156789}}",
      "ground_truth_hash": "f8ab79a505283348",
      "_ground_truth": {
        "target": "Insulin",
        "predictors": [
          "SkinThickness",
          "Glucose",
          "BMI"
        ],
        "r_squared": 0.2864,
        "adj_r_squared": 0.2836,
        "n_significant": 2,
        "coefficients": {
          "SkinThickness": 3.1465,
          "Glucose": 1.1386,
          "BMI": -0.6279
        },
        "p_values": {
          "SkinThickness": 0.0,
          "Glucose": 0.0,
          "BMI": 0.207315
        }
      },
      "_template": "multiple_regression_top_predictors"
    },
    {
      "question": "Which numeric measurement in the diabetes dataset is most skewed, and what is its average value with a 95% confidence interval? Return as JSON with keys: column, skewness, mean, ci_lower, ci_upper, std_error, n_bootstrap.",
      "hint": "Compute absolute skewness for all numeric columns, pick the one with the highest value, then perform bootstrap resampling (e.g., 1000 iterations) on that column to estimate the mean, its 95% CI, and the standard error.",
      "n_steps": 9,
      "difficulty": "VERY_HARD",
      "template_name": "bootstrap_ci_discovered",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 7 keys: \"column\" (name of most skewed column), \"skewness\" (rounded to 4 decimals), \"mean\" (rounded to 4 decimals), \"ci_lower\" (lower bound of 95% CI, rounded to 4 decimals), \"ci_upper\" (upper bound, rounded to 4 decimals), \"std_error\" (bootstrap standard error, rounded to 4 decimals), and \"n_bootstrap\" (integer, the number of bootstrap samples). Example: {\"column\": \"income\", \"skewness\": 2.3456, \"mean\": 50000.1234, \"ci_lower\": 48500.5678, \"ci_upper\": 51500.9012, \"std_error\": 750.3456, \"n_bootstrap\": 1000}",
      "ground_truth_hash": "dde48557f10b5b2c",
      "_ground_truth": {
        "column": "Insulin",
        "skewness": 2.2723,
        "mean": 79.7995,
        "ci_lower": 72.1633,
        "ci_upper": 87.6147,
        "std_error": 4.0649,
        "n_bootstrap": 1000
      },
      "_template": "bootstrap_ci_discovered"
    },
    {
      "question": "Which numeric measurement in the diabetes dataset is most closely approximated by a normal distribution? Return as JSON with keys: column, ks_statistic, p_value, is_normal, sample_mean, sample_std.",
      "hint": "Identify the column with the smallest absolute skewness, compute its mean and standard deviation, standardize the data, and run a Kolmogorov\u2011Smirnov test against a standard normal distribution.",
      "n_steps": 7,
      "difficulty": "MEDIUM",
      "template_name": "ks_normality_test",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 6 keys: \"column\" (tested column), \"ks_statistic\" (rounded to 4 decimals), \"p_value\" (rounded to 6 decimals), \"is_normal\" (boolean, true if p >= 0.05), \"sample_mean\" (rounded to 4 decimals), and \"sample_std\" (rounded to 4 decimals). Example: {\"column\": \"height\", \"ks_statistic\": 0.0456, \"p_value\": 0.234567, \"is_normal\": true, \"sample_mean\": 170.1234, \"sample_std\": 10.5678}",
      "ground_truth_hash": "9fc2378a5a3ba655",
      "_ground_truth": {
        "column": "SkinThickness",
        "ks_statistic": 0.1966,
        "p_value": 0.0,
        "is_normal": "False",
        "sample_mean": 20.5365,
        "sample_std": 15.9522
      },
      "_template": "ks_normality_test"
    },
    {
      "question": "Is the most skewed numeric measurement different between two groups defined by a median split of another variable? Return as JSON with keys: target_column, grouping_column, group1, group2, median1, median2, u_statistic, p_value.",
      "hint": "Find the numeric column with the highest absolute skewness, create a binary group by splitting another numeric column at its median, then compare the groups' medians using a Mann\u2011Whitney U test.",
      "n_steps": 6,
      "difficulty": "MEDIUM",
      "template_name": "mann_whitney_u_test",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 8 keys: \"target_column\", \"grouping_column\", \"group1\", \"group2\", \"median1\" (rounded to 4 decimals), \"median2\" (rounded to 4 decimals), \"u_statistic\" (rounded to 2 decimals), and \"p_value\" (rounded to 6 decimals). Example: {\"target_column\": \"score\", \"grouping_column\": \"treatment\", \"group1\": \"control\", \"group2\": \"experimental\", \"median1\": 72.5000, \"median2\": 78.0000, \"u_statistic\": 1234.50, \"p_value\": 0.034567}",
      "ground_truth_hash": "a2b15f45ab9b7ea5",
      "_ground_truth": {
        "target_column": "Insulin",
        "grouping_column": "_binary_group",
        "group1": "high",
        "group2": "low",
        "median1": 0.0,
        "median2": 63.0,
        "u_statistic": 60181.0,
        "p_value": 9e-06
      },
      "_template": "mann_whitney_u_test"
    },
    {
      "question": "Which two numeric measurements show the strongest relationship, and does applying a log transformation strengthen it? Return as JSON with keys: columns, original_correlation, log_correlation, improvement, transformation_helpful.",
      "hint": "Identify the most skewed positive columns, compute Pearson correlation on the original and log\u2011transformed data, then compare the absolute correlations.",
      "n_steps": 6,
      "difficulty": "HARD",
      "template_name": "correlation_change_analysis",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 5 keys: \"columns\" (list of 2 column names, alphabetically sorted), \"original_correlation\" (Pearson, rounded to 4 decimals), \"log_correlation\" (after log transform, rounded to 4 decimals), \"improvement\" (absolute difference, rounded to 4 decimals), and \"transformation_helpful\" (boolean, true if |log_corr| > |orig_corr|). Example: {\"columns\": [\"income\", \"spending\"], \"original_correlation\": 0.4567, \"log_correlation\": 0.7234, \"improvement\": 0.2667, \"transformation_helpful\": true}",
      "ground_truth_hash": "807cf6b21cc03265",
      "_ground_truth": {
        "columns": [
          "Age",
          "DiabetesPedigreeFunction"
        ],
        "original_correlation": 0.0336,
        "log_correlation": 0.0542,
        "improvement": 0.0206,
        "transformation_helpful": "True"
      },
      "_template": "correlation_change_analysis"
    },
    {
      "question": "Which numeric measurement in the diabetes dataset shows the greatest variability, and what are its quartiles and outlier thresholds? Return as JSON with keys: column, q1, q3, iqr, lower_fence, upper_fence, n_outliers.",
      "hint": "Find the column with the highest variance, then compute its 25th and 75th percentiles, IQR, fences, and count outliers.",
      "n_steps": 5,
      "difficulty": "EASY",
      "template_name": "iqr_outlier_analysis",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 7 keys: \"column\" (analyzed column), \"q1\" (25th percentile rounded to 4 decimals), \"q3\" (75th percentile rounded to 4 decimals), \"iqr\" (rounded to 4 decimals), \"lower_fence\" (rounded to 4 decimals), \"upper_fence\" (rounded to 4 decimals), and \"n_outliers\" (integer count). Example: {\"column\": \"salary\", \"q1\": 45000.0000, \"q3\": 75000.0000, \"iqr\": 30000.0000, \"lower_fence\": 0.0000, \"upper_fence\": 120000.0000, \"n_outliers\": 23}",
      "ground_truth_hash": "7f5e88d827a332ef",
      "_ground_truth": {
        "column": "Insulin",
        "q1": 0.0,
        "q3": 127.25,
        "iqr": 127.25,
        "lower_fence": -190.875,
        "upper_fence": 318.125,
        "n_outliers": 34
      },
      "_template": "iqr_outlier_analysis"
    },
    {
      "question": "Which numeric feature has the highest variance and does its distribution appear normal? Return as JSON with keys: distribution, median, iqr.",
      "hint": "Find the column with the greatest variance, run a Shapiro\u2011Wilk test, and if non\u2011normal report its median and inter\u2011quartile range.",
      "n_steps": 5,
      "difficulty": "HARD",
      "template_name": "conditional_normality",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 3 keys. If normal: {\"distribution\": \"normal\", \"mean\": <number>, \"std\": <number>}. If non-normal: {\"distribution\": \"non-normal\", \"median\": <number>, \"iqr\": <number>}. The \"iqr\" value is Q3 minus Q1 as a single number. All numeric values rounded to 3 decimal places.",
      "ground_truth_hash": "a6c31c572df75bf6",
      "_ground_truth": {
        "distribution": "non-normal",
        "median": 30.5,
        "iqr": 127.25
      },
      "_template": "conditional_normality"
    },
    {
      "question": "Which two numeric features show the strongest correlation, and how does removing extreme outliers change that relationship? Return as JSON with keys: columns, original_correlation, outliers_removed, clean_correlation.",
      "hint": "Find the highest absolute correlation pair, drop rows where either feature is more than 3\u202f\u03c3 from its mean, then recompute the correlation.",
      "n_steps": 5,
      "difficulty": "HARD",
      "template_name": "correlation_after_outlier_removal",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 4 keys: \"columns\" (list of 2 column names, alphabetically sorted), \"original_correlation\" (rounded to 3 decimals), \"outliers_removed\" (integer count), and \"clean_correlation\" (rounded to 3 decimals). Example: {\"columns\": [\"col_a\", \"col_b\"], \"original_correlation\": 0.847, \"outliers_removed\": 12, \"clean_correlation\": 0.891}",
      "ground_truth_hash": "75580e090332aa3c",
      "_ground_truth": {
        "columns": [
          "Age",
          "Pregnancies"
        ],
        "original_correlation": 0.544,
        "outliers_removed": 9,
        "clean_correlation": 0.559
      },
      "_template": "correlation_after_outlier_removal"
    },
    {
      "question": "I\u2019m curious how many outlier values exist in this health dataset and in how many features they occur. Return as JSON with keys: columns_with_outliers, total_outliers.",
      "hint": "Check each numeric column for values farther than 3\u202f\u00d7\u202fstandard deviation from the mean.",
      "n_steps": 4,
      "difficulty": "MEDIUM",
      "template_name": "count_outlier_columns",
      "template_params": {
        "z_threshold": 3.0
      },
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 2 keys: \"columns_with_outliers\" (integer count of columns containing at least one outlier) and \"total_outliers\" (integer total count of outlier values across all columns). Example: {\"columns_with_outliers\": 3, \"total_outliers\": 47}",
      "ground_truth_hash": "9f53cb44274d8cec",
      "_ground_truth": {
        "columns_with_outliers": 8,
        "total_outliers": 93
      },
      "_template": "count_outlier_columns"
    },
    {
      "question": "How many numeric features have any outlier values and what is the total count of outliers across all features? Return as JSON with keys: columns_with_outliers, total_outliers.",
      "hint": "For each numeric column, compute mean and standard deviation, flag values beyond 2.5\u202f\u00d7\u202fstd as outliers, then count columns with at least one outlier and sum all outlier occurrences.",
      "n_steps": 4,
      "difficulty": "MEDIUM",
      "template_name": "count_outlier_columns",
      "template_params": {
        "z_threshold": 2.5
      },
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 2 keys: \"columns_with_outliers\" (integer count of columns containing at least one outlier) and \"total_outliers\" (integer total count of outlier values across all columns). Example: {\"columns_with_outliers\": 3, \"total_outliers\": 47}",
      "ground_truth_hash": "7c170ea49c43d633",
      "_ground_truth": {
        "columns_with_outliers": 8,
        "total_outliers": 141
      },
      "_template": "count_outlier_columns"
    },
    {
      "question": "Which numeric measurement shows the greatest relative variability across patients? Return as JSON with keys: column, cv, mean, std.",
      "hint": "Calculate the coefficient of variation (std/mean*100) for each numeric column and identify the one with the highest value.",
      "n_steps": 4,
      "difficulty": "EASY",
      "template_name": "coefficient_of_variation",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 4 keys: \"column\" (name of column with highest CV), \"cv\" (coefficient of variation as percentage rounded to 2 decimals), \"mean\" (rounded to 4 decimals), and \"std\" (rounded to 4 decimals). Example: {\"column\": \"price\", \"cv\": 45.23, \"mean\": 1234.5678, \"std\": 558.4567}",
      "ground_truth_hash": "3d6cb0c3dcf2ff72",
      "_ground_truth": {
        "column": "Insulin",
        "cv": 144.42,
        "mean": 79.7995,
        "std": 115.244
      },
      "_template": "coefficient_of_variation"
    },
    {
      "question": "Which two numeric variables in this diabetes dataset show the strongest linear relationship? Return as JSON with keys: columns, correlation.",
      "hint": "Compute the absolute correlation matrix of all numeric features and identify the pair with the highest off\u2011diagonal value.",
      "n_steps": 4,
      "difficulty": "MEDIUM",
      "template_name": "strongest_correlation",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly two keys: \"columns\" (a list of the two column names, alphabetically sorted) and \"correlation\" (the correlation coefficient rounded to 3 decimal places). Example: {\"columns\": [\"col_a\", \"col_b\"], \"correlation\": 0.847}",
      "ground_truth_hash": "5effc0aac9988557",
      "_ground_truth": {
        "columns": [
          "Age",
          "Pregnancies"
        ],
        "correlation": 0.544
      },
      "_template": "strongest_correlation"
    },
    {
      "question": "Which pair of numeric measurements in the diabetes dataset have the weakest linear relationship? Return as JSON with keys: columns, correlation.",
      "hint": "Compute the absolute correlation matrix for all numeric columns and identify the smallest non\u2011zero correlation pair.",
      "n_steps": 4,
      "difficulty": "MEDIUM",
      "template_name": "weakest_correlation",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly two keys: \"columns\" (a list of the two column names, alphabetically sorted) and \"correlation\" (the absolute correlation value rounded to 3 decimal places). Example: {\"columns\": [\"col_a\", \"col_b\"], \"correlation\": 0.012}",
      "ground_truth_hash": "50c6a02cd29b17cf",
      "_ground_truth": {
        "columns": [
          "BMI",
          "Pregnancies"
        ],
        "correlation": 0.018
      },
      "_template": "weakest_correlation"
    },
    {
      "question": "Which measurement in the diabetes dataset shows the greatest variability, and what is its average value? Return as JSON with keys: question, hint.",
      "hint": "Identify the numeric column with the highest variance, then compute its mean.",
      "n_steps": 3,
      "difficulty": "MEDIUM",
      "template_name": "max_variance_mean",
      "template_params": null,
      "output_type": "scalar",
      "output_schema": "A single number (the mean), rounded to 3 decimal places",
      "ground_truth_hash": "6314c4ac2d1c3757",
      "_ground_truth": 79.799,
      "_template": "max_variance_mean"
    },
    {
      "question": "Which numeric measurement has the lowest average value and what is its standard deviation? Return as JSON with keys: result.",
      "hint": "Compute the mean of each numeric column, pick the column with the smallest mean, then calculate its standard deviation.",
      "n_steps": 3,
      "difficulty": "MEDIUM",
      "template_name": "min_mean_column_std",
      "template_params": null,
      "output_type": "scalar",
      "output_schema": "A single number (the standard deviation), rounded to 3 decimal places",
      "ground_truth_hash": "646c5c23791310cd",
      "_ground_truth": 0.477,
      "_template": "min_mean_column_std"
    },
    {
      "question": "I wonder whether any of the measurements have a substantial amount of missing data. Return as JSON with keys: count, columns.",
      "hint": "Calculate the missing percentage for each column and count those above a 5% threshold.",
      "n_steps": 3,
      "difficulty": "EASY",
      "template_name": "count_high_missing_columns",
      "template_params": {
        "missing_threshold": 5.0
      },
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 2 keys: \"count\" (integer) and \"columns\" (list of column names, alphabetically sorted). Example: {\"count\": 3, \"columns\": [\"col_a\", \"col_b\", \"col_c\"]}",
      "ground_truth_hash": "2c42c4348e535666",
      "_ground_truth": {
        "count": 0,
        "columns": []
      },
      "_template": "count_high_missing_columns"
    },
    {
      "question": "Do any of the measurements have a large fraction of missing values? Return as JSON with keys: count, columns.",
      "hint": "Compute the missing percentage for each column and count those above a 10% threshold.",
      "n_steps": 3,
      "difficulty": "EASY",
      "template_name": "count_high_missing_columns",
      "template_params": {
        "missing_threshold": 10.0
      },
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 2 keys: \"count\" (integer) and \"columns\" (list of column names, alphabetically sorted). Example: {\"count\": 3, \"columns\": [\"col_a\", \"col_b\", \"col_c\"]}",
      "ground_truth_hash": "2c42c4348e535666",
      "_ground_truth": {
        "count": 0,
        "columns": []
      },
      "_template": "count_high_missing_columns"
    },
    {
      "question": "Which clinical measurement shows the greatest variation among patients, and what are its 10th, 25th, 50th, 75th, and 90th percentiles? Return as JSON with keys: column, p10, p25, p50, p75, p90.",
      "hint": "Find the numeric column with the largest range, then compute its specified percentiles.",
      "n_steps": 3,
      "difficulty": "EASY",
      "template_name": "percentile_ranking",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 6 keys: \"column\" (analyzed column), \"p10\" (10th percentile rounded to 4 decimals), \"p25\" (25th percentile), \"p50\" (median), \"p75\" (75th percentile), and \"p90\" (90th percentile). Example: {\"column\": \"income\", \"p10\": 25000.0000, \"p25\": 40000.0000, \"p50\": 55000.0000, \"p75\": 75000.0000, \"p90\": 100000.0000}",
      "ground_truth_hash": "52523373cfda0e6f",
      "_ground_truth": {
        "column": "Insulin",
        "p10": 0.0,
        "p25": 0.0,
        "p50": 30.5,
        "p75": 127.25,
        "p90": 210.0
      },
      "_template": "percentile_ranking"
    },
    {
      "question": "Which numeric measurement shows the greatest variability across patients? Return as JSON with keys: column, count, mean, std, min, max, median, skewness, kurtosis.",
      "hint": "Find the column with the highest variance and then compute its descriptive statistics.",
      "n_steps": 3,
      "difficulty": "EASY",
      "template_name": "descriptive_summary",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 9 keys: \"column\", \"count\" (integer), \"mean\" (rounded to 4 decimals), \"std\", \"min\", \"max\", \"median\", \"skewness\", and \"kurtosis\" (all rounded to 4 decimals). Example: {\"column\": \"age\", \"count\": 1000, \"mean\": 35.4567, \"std\": 12.3456, \"min\": 18.0000, \"max\": 85.0000, \"median\": 34.0000, \"skewness\": 0.5678, \"kurtosis\": -0.2345}",
      "ground_truth_hash": "7ba0029e52bec2d2",
      "_ground_truth": {
        "column": "Insulin",
        "count": 768,
        "mean": 79.7995,
        "std": 115.244,
        "min": 0.0,
        "max": 846.0,
        "median": 30.5,
        "skewness": 2.2723,
        "kurtosis": 7.2143
      },
      "_template": "descriptive_summary"
    }
  ]
}