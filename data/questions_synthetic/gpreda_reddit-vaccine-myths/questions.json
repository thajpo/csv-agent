{
  "dataset_columns": [
    "title",
    "score",
    "id",
    "url",
    "comms_num",
    "created",
    "body",
    "timestamp"
  ],
  "questions": [
    {
      "question": "Which numeric column in the dataset is the most skewed and what is its average score with a 95% confidence interval? Return as JSON with keys: column, skewness, mean, ci_lower, ci_upper, std_error, n_bootstrap.",
      "hint": "Identify numeric columns, compute absolute skewness, pick the highest, then bootstrap the mean to get CI and standard error.",
      "n_steps": 9,
      "difficulty": "VERY_HARD",
      "template_name": "bootstrap_ci_discovered",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 7 keys: \"column\" (name of most skewed column), \"skewness\" (rounded to 4 decimals), \"mean\" (rounded to 4 decimals), \"ci_lower\" (lower bound of 95% CI, rounded to 4 decimals), \"ci_upper\" (upper bound, rounded to 4 decimals), \"std_error\" (bootstrap standard error, rounded to 4 decimals), and \"n_bootstrap\" (integer, the number of bootstrap samples). Example: {\"column\": \"income\", \"skewness\": 2.3456, \"mean\": 50000.1234, \"ci_lower\": 48500.5678, \"ci_upper\": 51500.9012, \"std_error\": 750.3456, \"n_bootstrap\": 1000}",
      "ground_truth_hash": "62cda498796bfc7f",
      "_ground_truth": {
        "column": "score",
        "skewness": 38.7127,
        "mean": 3.6866,
        "ci_lower": 2.7802,
        "ci_upper": 5.2573,
        "std_error": 0.7413,
        "n_bootstrap": 1000
      },
      "_template": "bootstrap_ci_discovered"
    },
    {
      "question": "Which numeric variable that shows the greatest variability can be best predicted by another numeric feature? Return as JSON with keys: target, best_predictor, correlation, r_squared, coefficient, p_value.",
      "hint": "Find the numeric column with the highest variance, compute absolute correlations with the other numeric columns, pick the strongest, and fit a simple OLS regression.",
      "n_steps": 8,
      "difficulty": "HARD",
      "template_name": "regression_most_predictive",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 6 keys: \"target\" (column name), \"best_predictor\" (column name), \"correlation\" (rounded to 3 decimals), \"r_squared\" (rounded to 4 decimals), \"coefficient\" (rounded to 4 decimals), and \"p_value\" (rounded to 6 decimals). Example: {\"target\": \"price\", \"best_predictor\": \"sqft\", \"correlation\": 0.834, \"r_squared\": 0.6956, \"coefficient\": 135.2847, \"p_value\": 0.000001}",
      "ground_truth_hash": "500929b1924b5fa6",
      "_ground_truth": {
        "target": "created",
        "best_predictor": "comms_num",
        "correlation": 0.103,
        "r_squared": 0.0106,
        "coefficient": -454374.5793,
        "p_value": 3.5e-05
      },
      "_template": "regression_most_predictive"
    },
    {
      "question": "Do the values of the most variable numeric feature differ significantly between two groups formed by splitting another numeric feature at its median? Return as JSON with keys: target_column, grouping_column, group1, group2, mean1, mean2, t_statistic, p_value, significant.",
      "hint": "Find the numeric column with the highest variance, create a binary grouping column by median\u2011splitting another numeric column, then compare the group means with a t\u2011test.",
      "n_steps": 8,
      "difficulty": "HARD",
      "template_name": "ttest_discovered_groups",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 9 keys: \"target_column\", \"grouping_column\", \"group1\", \"group2\", \"mean1\" (rounded to 4 decimals), \"mean2\" (rounded to 4 decimals), \"t_statistic\" (rounded to 4 decimals), \"p_value\" (rounded to 6 decimals), and \"significant\" (boolean, true if p < 0.05). Example: {\"target_column\": \"score\", \"grouping_column\": \"gender\", \"group1\": \"M\", \"group2\": \"F\", \"mean1\": 75.4321, \"mean2\": 78.1234, \"t_statistic\": -2.3456, \"p_value\": 0.019234, \"significant\": true}",
      "ground_truth_hash": "7b54bec45ac16d73",
      "_ground_truth": {
        "target_column": "created",
        "grouping_column": "_binary_group",
        "group1": "high",
        "group2": "low",
        "mean1": 1525713855.933,
        "mean2": 1565918766.5245,
        "t_statistic": -11.7831,
        "p_value": 0.0,
        "significant": "True"
      },
      "_template": "ttest_discovered_groups"
    },
    {
      "question": "Is there a numeric column in the data that appears to be normally distributed? Return as JSON with keys: column, ks_statistic, p_value, is_normal, sample_mean, sample_std.",
      "hint": "Identify the numeric column with the lowest absolute skewness, compute its mean and standard deviation, standardize the data, and perform a Kolmogorov\u2011Smirnov test against a standard normal distribution.",
      "n_steps": 7,
      "difficulty": "MEDIUM",
      "template_name": "ks_normality_test",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 6 keys: \"column\" (tested column), \"ks_statistic\" (rounded to 4 decimals), \"p_value\" (rounded to 6 decimals), \"is_normal\" (boolean, true if p >= 0.05), \"sample_mean\" (rounded to 4 decimals), and \"sample_std\" (rounded to 4 decimals). Example: {\"column\": \"height\", \"ks_statistic\": 0.0456, \"p_value\": 0.234567, \"is_normal\": true, \"sample_mean\": 170.1234, \"sample_std\": 10.5678}",
      "ground_truth_hash": "2d4c89487df08bd5",
      "_ground_truth": {
        "column": "created",
        "ks_statistic": 0.3224,
        "p_value": 0.0,
        "is_normal": "False",
        "sample_mean": 1547196629.6323,
        "sample_std": 70995110.2043
      },
      "_template": "ks_normality_test"
    },
    {
      "question": "Does the most skewed numeric variable show a significant difference between two opposite groups in the dataset? Return as JSON with keys: target_column, grouping_column, group1, group2, median1, median2, u_statistic, p_value.",
      "hint": "Find the numeric column with highest absolute skewness, define a binary grouping (use an existing binary column or split another numeric column at its median), then compare the groups' medians with a Mann\u2011Whitney U test.",
      "n_steps": 6,
      "difficulty": "MEDIUM",
      "template_name": "mann_whitney_u_test",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 8 keys: \"target_column\", \"grouping_column\", \"group1\", \"group2\", \"median1\" (rounded to 4 decimals), \"median2\" (rounded to 4 decimals), \"u_statistic\" (rounded to 2 decimals), and \"p_value\" (rounded to 6 decimals). Example: {\"target_column\": \"score\", \"grouping_column\": \"treatment\", \"group1\": \"control\", \"group2\": \"experimental\", \"median1\": 72.5000, \"median2\": 78.0000, \"u_statistic\": 1234.50, \"p_value\": 0.034567}",
      "ground_truth_hash": "32a41f686138ebae",
      "_ground_truth": {
        "target_column": "score",
        "grouping_column": "_binary_group",
        "group1": "low",
        "group2": "high",
        "median1": 1.0,
        "median2": 5.0,
        "u_statistic": 108172.5,
        "p_value": 0.0
      },
      "_template": "mann_whitney_u_test"
    },
    {
      "question": "Which two numeric variables in the dataset show the strongest monotonic relationship? Return as JSON with keys: columns, spearman_rho, p_value, interpretation.",
      "hint": "Compute Spearman correlations among all numeric columns and pick the pair with the highest absolute correlation.",
      "n_steps": 6,
      "difficulty": "MEDIUM",
      "template_name": "spearman_rank_correlation",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 4 keys: \"columns\" (list of 2 column names, alphabetically sorted), \"spearman_rho\" (correlation coefficient rounded to 4 decimals), \"p_value\" (rounded to 6 decimals), and \"interpretation\" (string: \"strong\", \"moderate\", \"weak\", or \"negligible\"). Example: {\"columns\": [\"age\", \"income\"], \"spearman_rho\": 0.7234, \"p_value\": 0.000001, \"interpretation\": \"strong\"}",
      "ground_truth_hash": "85dd513512405eaa",
      "_ground_truth": {
        "columns": [
          "comms_num",
          "created"
        ],
        "spearman_rho": -0.492,
        "p_value": 0.0,
        "interpretation": "moderate"
      },
      "_template": "spearman_rank_correlation"
    },
    {
      "question": "Do the two most skewed numeric columns in the dataset show a different relationship after applying a log transformation? Return as JSON with keys: columns, original_correlation, log_correlation, improvement, transformation_helpful.",
      "hint": "Find the two numeric columns with the highest absolute skewness, compute their Pearson correlation, log\u2011transform the values, recompute the correlation, and compare the absolute values.",
      "n_steps": 6,
      "difficulty": "HARD",
      "template_name": "correlation_change_analysis",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 5 keys: \"columns\" (list of 2 column names, alphabetically sorted), \"original_correlation\" (Pearson, rounded to 4 decimals), \"log_correlation\" (after log transform, rounded to 4 decimals), \"improvement\" (absolute difference, rounded to 4 decimals), and \"transformation_helpful\" (boolean, true if |log_corr| > |orig_corr|). Example: {\"columns\": [\"income\", \"spending\"], \"original_correlation\": 0.4567, \"log_correlation\": 0.7234, \"improvement\": 0.2667, \"transformation_helpful\": true}",
      "ground_truth_hash": "b654b0bc52de6125",
      "_ground_truth": {
        "columns": [
          "comms_num",
          "score"
        ],
        "original_correlation": 0.9231,
        "log_correlation": 0.4999,
        "improvement": 0.4232,
        "transformation_helpful": "False"
      },
      "_template": "correlation_change_analysis"
    },
    {
      "question": "Which numeric attribute has the largest variability, and what are its Q1, Q3, IQR, fence values, and outlier count? Return as JSON with keys: column, q1, q3, iqr, lower_fence, upper_fence, n_outliers.",
      "hint": "Identify the numeric column with the highest variance, then compute its 25th and 75th percentiles, derive the IQR, calculate the lower and upper fences (1.5\u202f\u00d7\u202fIQR), and count observations outside these fences.",
      "n_steps": 5,
      "difficulty": "EASY",
      "template_name": "iqr_outlier_analysis",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 7 keys: \"column\" (analyzed column), \"q1\" (25th percentile rounded to 4 decimals), \"q3\" (75th percentile rounded to 4 decimals), \"iqr\" (rounded to 4 decimals), \"lower_fence\" (rounded to 4 decimals), \"upper_fence\" (rounded to 4 decimals), and \"n_outliers\" (integer count). Example: {\"column\": \"salary\", \"q1\": 45000.0000, \"q3\": 75000.0000, \"iqr\": 30000.0000, \"lower_fence\": 0.0000, \"upper_fence\": 120000.0000, \"n_outliers\": 23}",
      "ground_truth_hash": "ce2ab1806b72c617",
      "_ground_truth": {
        "column": "created",
        "q1": 1554367455.75,
        "q3": 1584900970.5,
        "iqr": 30533514.75,
        "lower_fence": 1508567183.625,
        "upper_fence": 1630701242.625,
        "n_outliers": 352
      },
      "_template": "iqr_outlier_analysis"
    },
    {
      "question": "Is the numeric column with the greatest variance in this dataset normally distributed? Return as JSON with keys: distribution, median, iqr.",
      "hint": "Identify the numeric column with the highest variance, test its normality (e.g., Shapiro\u2011Wilk), and if non\u2011normal report the median and interquartile range.",
      "n_steps": 5,
      "difficulty": "HARD",
      "template_name": "conditional_normality",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 3 keys. If normal: {\"distribution\": \"normal\", \"mean\": <number>, \"std\": <number>}. If non-normal: {\"distribution\": \"non-normal\", \"median\": <number>, \"iqr\": <number>}. The \"iqr\" value is Q3 minus Q1 as a single number. All numeric values rounded to 3 decimal places.",
      "ground_truth_hash": "0680021ffc10c10d",
      "_ground_truth": {
        "distribution": "non-normal",
        "median": 1569226482.0,
        "iqr": 30533514.75
      },
      "_template": "conditional_normality"
    },
    {
      "question": "Which group of posts (based on their headings) has the highest average creation time? Return as JSON with keys: category_column, best_category, target_column, mean_value.",
      "hint": "Identify the numeric column with the largest variance, compute its mean for each categorical group, and select the group with the highest mean.",
      "n_steps": 5,
      "difficulty": "HARD",
      "template_name": "category_highest_target_mean",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 4 keys: \"category_column\" (the grouping column name), \"best_category\" (the category value with highest mean), \"target_column\" (the numeric column analyzed), and \"mean_value\" (rounded to 3 decimal places). Example: {\"category_column\": \"region\", \"best_category\": \"West\", \"target_column\": \"sales\", \"mean_value\": 1234.567}",
      "ground_truth_hash": "595d9088c20d55fe",
      "_ground_truth": {
        "category_column": "title",
        "best_category": "Vaccines leading to heart conditions?",
        "target_column": "created",
        "mean_value": 1640822084.0
      },
      "_template": "category_highest_target_mean"
    },
    {
      "question": "Which numeric columns show the strongest correlation, and how does that relationship change after removing extreme outliers? Return as JSON with keys: columns, original_correlation, outliers_removed, clean_correlation.",
      "hint": "Find the pair with the highest absolute correlation, drop rows where either value is more than 3\u202f\u03c3 from its mean, then recompute the correlation.",
      "n_steps": 5,
      "difficulty": "HARD",
      "template_name": "correlation_after_outlier_removal",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 4 keys: \"columns\" (list of 2 column names, alphabetically sorted), \"original_correlation\" (rounded to 3 decimals), \"outliers_removed\" (integer count), and \"clean_correlation\" (rounded to 3 decimals). Example: {\"columns\": [\"col_a\", \"col_b\"], \"original_correlation\": 0.847, \"outliers_removed\": 12, \"clean_correlation\": 0.891}",
      "ground_truth_hash": "d0eb31c4f8ac7a26",
      "_ground_truth": {
        "columns": [
          "comms_num",
          "score"
        ],
        "original_correlation": 0.923,
        "outliers_removed": 4,
        "clean_correlation": 0.307
      },
      "_template": "correlation_after_outlier_removal"
    },
    {
      "question": "How many numeric columns have outliers and what is the total count of outlier values? Return as JSON with keys: columns_with_outliers, total_outliers.",
      "hint": "Identify values >3 standard deviations from the mean for each numeric column and tally them.",
      "n_steps": 4,
      "difficulty": "MEDIUM",
      "template_name": "count_outlier_columns",
      "template_params": {
        "z_threshold": 3.0
      },
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 2 keys: \"columns_with_outliers\" (integer count of columns containing at least one outlier) and \"total_outliers\" (integer total count of outlier values across all columns). Example: {\"columns_with_outliers\": 3, \"total_outliers\": 47}",
      "ground_truth_hash": "4b0e149798dceea1",
      "_ground_truth": {
        "columns_with_outliers": 2,
        "total_outliers": 5
      },
      "_template": "count_outlier_columns"
    },
    {
      "question": "How many numeric columns contain outliers and what is the total number of outlier values? Return as JSON with keys: columns_with_outliers, total_outliers.",
      "hint": "Identify numeric columns, compute mean and standard deviation, flag values beyond 2.5\u202f\u00d7\u202fstd, then count affected columns and total outliers.",
      "n_steps": 4,
      "difficulty": "MEDIUM",
      "template_name": "count_outlier_columns",
      "template_params": {
        "z_threshold": 2.5
      },
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 2 keys: \"columns_with_outliers\" (integer count of columns containing at least one outlier) and \"total_outliers\" (integer total count of outlier values across all columns). Example: {\"columns_with_outliers\": 3, \"total_outliers\": 47}",
      "ground_truth_hash": "56dc985aa79f2e2c",
      "_ground_truth": {
        "columns_with_outliers": 2,
        "total_outliers": 8
      },
      "_template": "count_outlier_columns"
    },
    {
      "question": "Which numeric field shows the greatest relative variability? Return as JSON with keys: column, cv, mean, std.",
      "hint": "Calculate the coefficient of variation (std/mean*100) for each numeric column and identify the one with the highest value.",
      "n_steps": 4,
      "difficulty": "EASY",
      "template_name": "coefficient_of_variation",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 4 keys: \"column\" (name of column with highest CV), \"cv\" (coefficient of variation as percentage rounded to 2 decimals), \"mean\" (rounded to 4 decimals), and \"std\" (rounded to 4 decimals). Example: {\"column\": \"price\", \"cv\": 45.23, \"mean\": 1234.5678, \"std\": 558.4567}",
      "ground_truth_hash": "fda2267fb23b384d",
      "_ground_truth": {
        "column": "comms_num",
        "cv": 876.32,
        "mean": 1.839,
        "std": 16.1151
      },
      "_template": "coefficient_of_variation"
    },
    {
      "question": "Which two numeric fields in this dataset are most strongly linearly related? Return as JSON with keys: columns, correlation.",
      "hint": "Calculate the absolute Pearson correlation matrix for all numeric columns, zero out the diagonal, and identify the pair with the highest correlation.",
      "n_steps": 4,
      "difficulty": "MEDIUM",
      "template_name": "strongest_correlation",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly two keys: \"columns\" (a list of the two column names, alphabetically sorted) and \"correlation\" (the correlation coefficient rounded to 3 decimal places). Example: {\"columns\": [\"col_a\", \"col_b\"], \"correlation\": 0.847}",
      "ground_truth_hash": "f10bd1b639cda112",
      "_ground_truth": {
        "columns": [
          "comms_num",
          "score"
        ],
        "correlation": 0.923
      },
      "_template": "strongest_correlation"
    },
    {
      "question": "Which pair of numeric fields in the dataset shows the weakest relationship? Return as JSON with keys: columns, correlation.",
      "hint": "Compute the absolute correlation matrix for numeric columns, mask the diagonal, and locate the minimum non\u2011zero correlation.",
      "n_steps": 4,
      "difficulty": "MEDIUM",
      "template_name": "weakest_correlation",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly two keys: \"columns\" (a list of the two column names, alphabetically sorted) and \"correlation\" (the absolute correlation value rounded to 3 decimal places). Example: {\"columns\": [\"col_a\", \"col_b\"], \"correlation\": 0.012}",
      "ground_truth_hash": "41a94b6bc46a11e4",
      "_ground_truth": {
        "columns": [
          "created",
          "score"
        ],
        "correlation": 0.097
      },
      "_template": "weakest_correlation"
    },
    {
      "question": "Which numeric column in the dataset shows the greatest variability, and what is the average value of that column? Return as JSON with keys: result.",
      "hint": "Find the numeric column with the highest variance, then calculate its mean.",
      "n_steps": 3,
      "difficulty": "MEDIUM",
      "template_name": "max_variance_mean",
      "template_params": null,
      "output_type": "scalar",
      "output_schema": "A single number (the mean), rounded to 3 decimal places",
      "ground_truth_hash": "37e586b5b81086af",
      "_ground_truth": 1547196629.632,
      "_template": "max_variance_mean"
    },
    {
      "question": "Which numeric column has the lowest average value, and what is its standard deviation? Return as JSON with keys: std.",
      "hint": "Identify the numeric column with the smallest mean, then compute its standard deviation.",
      "n_steps": 3,
      "difficulty": "MEDIUM",
      "template_name": "min_mean_column_std",
      "template_params": null,
      "output_type": "scalar",
      "output_schema": "A single number (the standard deviation), rounded to 3 decimal places",
      "ground_truth_hash": "3f394f4f7a4f8849",
      "_ground_truth": 16.115,
      "_template": "min_mean_column_std"
    },
    {
      "question": "Which columns in the dataset have a substantial amount of missing data? Return as JSON with keys: count, columns.",
      "hint": "Calculate missing percentages for each column and list those above a 5% threshold.",
      "n_steps": 3,
      "difficulty": "EASY",
      "template_name": "count_high_missing_columns",
      "template_params": {
        "missing_threshold": 5.0
      },
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 2 keys: \"count\" (integer) and \"columns\" (list of column names, alphabetically sorted). Example: {\"count\": 3, \"columns\": [\"col_a\", \"col_b\", \"col_c\"]}",
      "ground_truth_hash": "cedd9df85ff8ec75",
      "_ground_truth": {
        "count": 2,
        "columns": [
          "body",
          "url"
        ]
      },
      "_template": "count_high_missing_columns"
    },
    {
      "question": "Which columns in the dataset have a high proportion of missing values? Return as JSON with keys: count, columns.",
      "hint": "Calculate missing percentages for each column and list those exceeding 10%.",
      "n_steps": 3,
      "difficulty": "EASY",
      "template_name": "count_high_missing_columns",
      "template_params": {
        "missing_threshold": 10.0
      },
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 2 keys: \"count\" (integer) and \"columns\" (list of column names, alphabetically sorted). Example: {\"count\": 3, \"columns\": [\"col_a\", \"col_b\", \"col_c\"]}",
      "ground_truth_hash": "cedd9df85ff8ec75",
      "_ground_truth": {
        "count": 2,
        "columns": [
          "body",
          "url"
        ]
      },
      "_template": "count_high_missing_columns"
    },
    {
      "question": "Which numeric variable in the dataset shows the greatest spread, and what are its key percentile values? Return as JSON with keys: column, p10, p25, p50, p75, p90.",
      "hint": "Find the numeric column with the largest range, then compute its 10th, 25th, 50th, 75th, and 90th percentiles.",
      "n_steps": 3,
      "difficulty": "EASY",
      "template_name": "percentile_ranking",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 6 keys: \"column\" (analyzed column), \"p10\" (10th percentile rounded to 4 decimals), \"p25\" (25th percentile), \"p50\" (median), \"p75\" (75th percentile), and \"p90\" (90th percentile). Example: {\"column\": \"income\", \"p10\": 25000.0000, \"p25\": 40000.0000, \"p50\": 55000.0000, \"p75\": 75000.0000, \"p90\": 100000.0000}",
      "ground_truth_hash": "1933e92aef70f6a4",
      "_ground_truth": {
        "column": "created",
        "p10": 1398977188.2,
        "p25": 1554367455.75,
        "p50": 1569226482.0,
        "p75": 1584900970.5,
        "p90": 1616613026.9
      },
      "_template": "percentile_ranking"
    },
    {
      "question": "Which numeric column shows the greatest variability, and what are its basic descriptive statistics? Return as JSON with keys: column, count, mean, std, min, max, median, skewness, kurtosis.",
      "hint": "Find the numeric column with the highest variance, then compute its count, mean, standard deviation, min, max, median, skewness, and kurtosis.",
      "n_steps": 3,
      "difficulty": "EASY",
      "template_name": "descriptive_summary",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 9 keys: \"column\", \"count\" (integer), \"mean\" (rounded to 4 decimals), \"std\", \"min\", \"max\", \"median\", \"skewness\", and \"kurtosis\" (all rounded to 4 decimals). Example: {\"column\": \"age\", \"count\": 1000, \"mean\": 35.4567, \"std\": 12.3456, \"min\": 18.0000, \"max\": 85.0000, \"median\": 34.0000, \"skewness\": 0.5678, \"kurtosis\": -0.2345}",
      "ground_truth_hash": "2d4fc95e14c3f2fb",
      "_ground_truth": {
        "column": "created",
        "count": 1602,
        "mean": 1547196629.6323,
        "std": 70995110.2043,
        "min": 1389595375.0,
        "max": 1640822169.0,
        "median": 1569226482.0,
        "skewness": -1.2819,
        "kurtosis": 0.3191
      },
      "_template": "descriptive_summary"
    }
  ]
}