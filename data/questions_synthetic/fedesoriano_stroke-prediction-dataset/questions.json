{
  "dataset_columns": [
    "id",
    "gender",
    "age",
    "hypertension",
    "heart_disease",
    "ever_married",
    "work_type",
    "Residence_type",
    "avg_glucose_level",
    "bmi",
    "smoking_status",
    "stroke"
  ],
  "questions": [
    {
      "question": "Which numeric feature shows the greatest variance and can be explained by the three most correlated numeric variables? Return as JSON with keys: target, predictors, r_squared, adj_r_squared, n_significant, coefficients, p_values.",
      "hint": "Identify numeric columns, select the one with highest variance as target, compute absolute correlations, pick the top three predictors, fit an OLS regression, and report R\u00b2, adjusted R\u00b2, number of significant predictors (p<0.05), coefficients and p-values.",
      "n_steps": 10,
      "difficulty": "VERY_HARD",
      "template_name": "multiple_regression_top_predictors",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 6 keys: \"target\" (column name), \"predictors\" (list of 3 column names), \"r_squared\" (rounded to 4 decimals), \"adj_r_squared\" (rounded to 4 decimals), \"n_significant\" (integer count of predictors with p < 0.05), \"coefficients\" (dict mapping predictor names to coefficients rounded to 4 decimals), and \"p_values\" (dict mapping predictor names to p-values rounded to 6 decimals). Example: {\"target\": \"price\", \"predictors\": [\"sqft\", \"bedrooms\", \"age\"], \"r_squared\": 0.7234, \"adj_r_squared\": 0.7156, \"n_significant\": 2, \"coefficients\": {\"sqft\": 123.45, \"bedrooms\": 5000.12, \"age\": -200.34}, \"p_values\": {\"sqft\": 0.000001, \"bedrooms\": 0.023456, \"age\": 0.156789}}",
      "ground_truth_hash": "2644c421c8d26c14",
      "_ground_truth": {
        "target": "id",
        "predictors": [
          "stroke",
          "hypertension",
          "age"
        ],
        "r_squared": 0.0001,
        "adj_r_squared": -0.0005,
        "n_significant": 0,
        "coefficients": {
          "stroke": 562.1107,
          "hypertension": 172.0977,
          "age": 1.3744
        },
        "p_values": {
          "stroke": 0.692569,
          "hypertension": 0.868708,
          "age": 0.921634
        }
      },
      "_template": "multiple_regression_top_predictors"
    },
    {
      "question": "Which numeric column in the dataset is the most skewed, and what are its mean, 95% confidence interval, and bootstrap standard error? Return as JSON with keys: column, skewness, mean, ci_lower, ci_upper, std_error, n_bootstrap.",
      "hint": "Calculate absolute skewness for each numeric column, select the one with the highest value, then use bootstrap resampling to estimate its mean, confidence interval, and standard error.",
      "n_steps": 9,
      "difficulty": "VERY_HARD",
      "template_name": "bootstrap_ci_discovered",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 7 keys: \"column\" (name of most skewed column), \"skewness\" (rounded to 4 decimals), \"mean\" (rounded to 4 decimals), \"ci_lower\" (lower bound of 95% CI, rounded to 4 decimals), \"ci_upper\" (upper bound, rounded to 4 decimals), \"std_error\" (bootstrap standard error, rounded to 4 decimals), and \"n_bootstrap\" (integer, the number of bootstrap samples). Example: {\"column\": \"income\", \"skewness\": 2.3456, \"mean\": 50000.1234, \"ci_lower\": 48500.5678, \"ci_upper\": 51500.9012, \"std_error\": 750.3456, \"n_bootstrap\": 1000}",
      "ground_truth_hash": "fd98c265be7e120a",
      "_ground_truth": {
        "column": "stroke",
        "skewness": 4.1933,
        "mean": 0.0487,
        "ci_lower": 0.0429,
        "ci_upper": 0.0546,
        "std_error": 0.0031,
        "n_bootstrap": 1000
      },
      "_template": "bootstrap_ci_discovered"
    },
    {
      "question": "Which numeric variable shows the strongest linear relationship with the most variable numeric column in this clinical dataset? Return as JSON with keys: target, best_predictor, correlation, r_squared, coefficient, p_value.",
      "hint": "Identify the numeric column with highest variance, compute absolute correlations with other numeric columns, pick the strongest, fit a simple OLS regression and report the stats.",
      "n_steps": 8,
      "difficulty": "HARD",
      "template_name": "regression_most_predictive",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 6 keys: \"target\" (column name), \"best_predictor\" (column name), \"correlation\" (rounded to 3 decimals), \"r_squared\" (rounded to 4 decimals), \"coefficient\" (rounded to 4 decimals), and \"p_value\" (rounded to 6 decimals). Example: {\"target\": \"price\", \"best_predictor\": \"sqft\", \"correlation\": 0.834, \"r_squared\": 0.6956, \"coefficient\": 135.2847, \"p_value\": 0.000001}",
      "ground_truth_hash": "7145709584395521",
      "_ground_truth": {
        "target": "id",
        "best_predictor": "stroke",
        "correlation": 0.006,
        "r_squared": 0.0,
        "coefficient": 627.8319,
        "p_value": 0.647997
      },
      "_template": "regression_most_predictive"
    },
    {
      "question": "Which numeric feature in the clinical dataset is closest to a normal distribution? Return as JSON with keys: column, ks_statistic, p_value, is_normal, sample_mean, sample_std.",
      "hint": "Calculate absolute skewness for each numeric column, select the one with the lowest value, then standardize its values and run a Kolmogorov\u2011Smirnov test against a standard normal distribution.",
      "n_steps": 7,
      "difficulty": "MEDIUM",
      "template_name": "ks_normality_test",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 6 keys: \"column\" (tested column), \"ks_statistic\" (rounded to 4 decimals), \"p_value\" (rounded to 6 decimals), \"is_normal\" (boolean, true if p >= 0.05), \"sample_mean\" (rounded to 4 decimals), and \"sample_std\" (rounded to 4 decimals). Example: {\"column\": \"height\", \"ks_statistic\": 0.0456, \"p_value\": 0.234567, \"is_normal\": true, \"sample_mean\": 170.1234, \"sample_std\": 10.5678}",
      "ground_truth_hash": "b9fd0ab425bf5101",
      "_ground_truth": {
        "column": "id",
        "ks_statistic": 0.0634,
        "p_value": 0.0,
        "is_normal": "False",
        "sample_mean": 36517.8294,
        "sample_std": 21161.7216
      },
      "_template": "ks_normality_test"
    },
    {
      "question": "Do any of the demographic categorical variables appear to be related to each other? Return as JSON with keys: column1, column2, chi_squared, p_value, degrees_of_freedom, expected_min, independent.",
      "hint": "Build a cross\u2011tabulation of two suitable categorical columns and run a chi\u2011squared test of independence.",
      "n_steps": 6,
      "difficulty": "MEDIUM",
      "template_name": "chi_squared_independence",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 7 keys: \"column1\" (first categorical column), \"column2\" (second categorical column), \"chi_squared\" (test statistic rounded to 4 decimals), \"p_value\" (rounded to 6 decimals), \"degrees_of_freedom\" (integer), \"expected_min\" (minimum expected frequency rounded to 2 decimals), and \"independent\" (boolean, true if p >= 0.05). Example: {\"column1\": \"gender\", \"column2\": \"product\", \"chi_squared\": 15.2345, \"p_value\": 0.004321, \"degrees_of_freedom\": 4, \"expected_min\": 5.23, \"independent\": false}",
      "ground_truth_hash": "3b8f324f80699a24",
      "_ground_truth": {
        "column1": "gender",
        "column2": "ever_married",
        "chi_squared": 6.5587,
        "p_value": 0.037654,
        "degrees_of_freedom": 2,
        "expected_min": 0.34,
        "independent": "False"
      },
      "_template": "chi_squared_independence"
    },
    {
      "question": "Which numeric feature shows the greatest skew in this stroke dataset, and does its distribution differ between two groups defined by a binary categorical variable? Return as JSON with keys: target_column, grouping_column, group1, group2, median1, median2, u_statistic, p_value.",
      "hint": "Identify the most skewed numeric column, pick a binary categorical column (or create one via median split), then compare the two groups with a Mann\u2011Whitney U test.",
      "n_steps": 6,
      "difficulty": "MEDIUM",
      "template_name": "mann_whitney_u_test",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 8 keys: \"target_column\", \"grouping_column\", \"group1\", \"group2\", \"median1\" (rounded to 4 decimals), \"median2\" (rounded to 4 decimals), \"u_statistic\" (rounded to 2 decimals), and \"p_value\" (rounded to 6 decimals). Example: {\"target_column\": \"score\", \"grouping_column\": \"treatment\", \"group1\": \"control\", \"group2\": \"experimental\", \"median1\": 72.5000, \"median2\": 78.0000, \"u_statistic\": 1234.50, \"p_value\": 0.034567}",
      "ground_truth_hash": "a0c31c98d278fdb1",
      "_ground_truth": {
        "target_column": "stroke",
        "grouping_column": "ever_married",
        "group1": "Yes",
        "group2": "No",
        "median1": 0.0,
        "median2": 0.0,
        "u_statistic": 3090262.0,
        "p_value": 0.0
      },
      "_template": "mann_whitney_u_test"
    },
    {
      "question": "Do the two most skewed numeric clinical measurements show a stronger relationship after applying a log transformation? Return as JSON with keys: columns, original_correlation, log_correlation, improvement, transformation_helpful.",
      "hint": "Find the numeric columns with the highest absolute skewness, compute their Pearson correlation, log\u2011transform both columns, recompute the correlation, and compare the absolute values.",
      "n_steps": 6,
      "difficulty": "HARD",
      "template_name": "correlation_change_analysis",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 5 keys: \"columns\" (list of 2 column names, alphabetically sorted), \"original_correlation\" (Pearson, rounded to 4 decimals), \"log_correlation\" (after log transform, rounded to 4 decimals), \"improvement\" (absolute difference, rounded to 4 decimals), and \"transformation_helpful\" (boolean, true if |log_corr| > |orig_corr|). Example: {\"columns\": [\"income\", \"spending\"], \"original_correlation\": 0.4567, \"log_correlation\": 0.7234, \"improvement\": 0.2667, \"transformation_helpful\": true}",
      "ground_truth_hash": "b11c733ea42a5d6b",
      "_ground_truth": {
        "columns": [
          "age",
          "avg_glucose_level"
        ],
        "original_correlation": 0.2382,
        "log_correlation": 0.1312,
        "improvement": 0.107,
        "transformation_helpful": "False"
      },
      "_template": "correlation_change_analysis"
    },
    {
      "question": "Which numeric variable in the stroke dataset exhibits the greatest variability? Return as JSON with keys: column, q1, q3, iqr, lower_fence, upper_fence, n_outliers.",
      "hint": "Identify the numeric column with the highest variance, then calculate its quartiles, IQR, fences, and count outliers.",
      "n_steps": 5,
      "difficulty": "EASY",
      "template_name": "iqr_outlier_analysis",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 7 keys: \"column\" (analyzed column), \"q1\" (25th percentile rounded to 4 decimals), \"q3\" (75th percentile rounded to 4 decimals), \"iqr\" (rounded to 4 decimals), \"lower_fence\" (rounded to 4 decimals), \"upper_fence\" (rounded to 4 decimals), and \"n_outliers\" (integer count). Example: {\"column\": \"salary\", \"q1\": 45000.0000, \"q3\": 75000.0000, \"iqr\": 30000.0000, \"lower_fence\": 0.0000, \"upper_fence\": 120000.0000, \"n_outliers\": 23}",
      "ground_truth_hash": "302abe34f80d1058",
      "_ground_truth": {
        "column": "id",
        "q1": 17741.25,
        "q3": 54682.0,
        "iqr": 36940.75,
        "lower_fence": -37669.875,
        "upper_fence": 110093.125,
        "n_outliers": 0
      },
      "_template": "iqr_outlier_analysis"
    },
    {
      "question": "Which numeric feature has the highest variance and does its distribution follow a normal shape? Return as JSON with keys: distribution, median, iqr.",
      "hint": "Identify the most variable numeric column, test normality (e.g., Shapiro-Wilk), and if non\u2011normal report its median and IQR; otherwise report mean and std.",
      "n_steps": 5,
      "difficulty": "HARD",
      "template_name": "conditional_normality",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 3 keys. If normal: {\"distribution\": \"normal\", \"mean\": <number>, \"std\": <number>}. If non-normal: {\"distribution\": \"non-normal\", \"median\": <number>, \"iqr\": <number>}. The \"iqr\" value is Q3 minus Q1 as a single number. All numeric values rounded to 3 decimal places.",
      "ground_truth_hash": "e2eb8057dfcf6740",
      "_ground_truth": {
        "distribution": "non-normal",
        "median": 36932.0,
        "iqr": 36940.75
      },
      "_template": "conditional_normality"
    },
    {
      "question": "Which categorical group has the highest average of the most variable numeric feature? Return as JSON with keys: category_column, best_category, target_column, mean_value.",
      "hint": "Identify the numeric column with the greatest variance, select a categorical column with 2\u201320 unique values, compute the mean of that numeric column for each category, and report the category with the highest mean.",
      "n_steps": 5,
      "difficulty": "HARD",
      "template_name": "category_highest_target_mean",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 4 keys: \"category_column\" (the grouping column name), \"best_category\" (the category value with highest mean), \"target_column\" (the numeric column analyzed), and \"mean_value\" (rounded to 3 decimal places). Example: {\"category_column\": \"region\", \"best_category\": \"West\", \"target_column\": \"sales\", \"mean_value\": 1234.567}",
      "ground_truth_hash": "04fcf361411400c3",
      "_ground_truth": {
        "category_column": "gender",
        "best_category": "Other",
        "target_column": "id",
        "mean_value": 56156.0
      },
      "_template": "category_highest_target_mean"
    },
    {
      "question": "I wonder how many numeric variables contain extreme values and what the overall count of such outliers is. Return as JSON with keys: columns_with_outliers, total_outliers.",
      "hint": "Flag values more than 3 standard deviations from the mean in each numeric column, then count columns with any outliers and sum all outlier occurrences.",
      "n_steps": 4,
      "difficulty": "MEDIUM",
      "template_name": "count_outlier_columns",
      "template_params": {
        "z_threshold": 3.0
      },
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 2 keys: \"columns_with_outliers\" (integer count of columns containing at least one outlier) and \"total_outliers\" (integer total count of outlier values across all columns). Example: {\"columns_with_outliers\": 3, \"total_outliers\": 47}",
      "ground_truth_hash": "b12f26040aea97a5",
      "_ground_truth": {
        "columns_with_outliers": 5,
        "total_outliers": 1130
      },
      "_template": "count_outlier_columns"
    },
    {
      "question": "How many numeric clinical features have extreme values and what is the total number of such outliers? Return as JSON with keys: columns_with_outliers, total_outliers.",
      "hint": "Identify values that lie more than 2.5 standard deviations away from the mean for each numeric column, then count columns with any outliers and sum all outlier instances.",
      "n_steps": 4,
      "difficulty": "MEDIUM",
      "template_name": "count_outlier_columns",
      "template_params": {
        "z_threshold": 2.5
      },
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 2 keys: \"columns_with_outliers\" (integer count of columns containing at least one outlier) and \"total_outliers\" (integer total count of outlier values across all columns). Example: {\"columns_with_outliers\": 3, \"total_outliers\": 47}",
      "ground_truth_hash": "f3de8c5231d3e06f",
      "_ground_truth": {
        "columns_with_outliers": 5,
        "total_outliers": 1340
      },
      "_template": "count_outlier_columns"
    },
    {
      "question": "Which numeric clinical measurement shows the greatest relative variability across the patients? Return as JSON with keys: column, cv, mean, std.",
      "hint": "Compute the coefficient of variation (std/mean*100) for each numeric column and identify the column with the highest CV.",
      "n_steps": 4,
      "difficulty": "EASY",
      "template_name": "coefficient_of_variation",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 4 keys: \"column\" (name of column with highest CV), \"cv\" (coefficient of variation as percentage rounded to 2 decimals), \"mean\" (rounded to 4 decimals), and \"std\" (rounded to 4 decimals). Example: {\"column\": \"price\", \"cv\": 45.23, \"mean\": 1234.5678, \"std\": 558.4567}",
      "ground_truth_hash": "c3fd44ad57dc5028",
      "_ground_truth": {
        "column": "stroke",
        "cv": 441.88,
        "mean": 0.0487,
        "std": 0.2153
      },
      "_template": "coefficient_of_variation"
    },
    {
      "question": "Which pair of numeric clinical features shows the strongest linear relationship? Return as JSON with keys: columns, correlation.",
      "hint": "Compute the absolute correlation matrix for numeric columns, zero out the diagonal, and find the maximum off\u2011diagonal value.",
      "n_steps": 4,
      "difficulty": "MEDIUM",
      "template_name": "strongest_correlation",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly two keys: \"columns\" (a list of the two column names, alphabetically sorted) and \"correlation\" (the correlation coefficient rounded to 3 decimal places). Example: {\"columns\": [\"col_a\", \"col_b\"], \"correlation\": 0.847}",
      "ground_truth_hash": "c94c4a61d4f4abdc",
      "_ground_truth": {
        "columns": [
          "age",
          "bmi"
        ],
        "correlation": 0.333
      },
      "_template": "strongest_correlation"
    },
    {
      "question": "Which two numeric features in this stroke dataset show the weakest linear correlation? Return as JSON with keys: columns, correlation.",
      "hint": "Calculate the absolute correlation matrix for all numeric columns, ignore the diagonal and zero values, then locate the smallest remaining correlation.",
      "n_steps": 4,
      "difficulty": "MEDIUM",
      "template_name": "weakest_correlation",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly two keys: \"columns\" (a list of the two column names, alphabetically sorted) and \"correlation\" (the absolute correlation value rounded to 3 decimal places). Example: {\"columns\": [\"col_a\", \"col_b\"], \"correlation\": 0.012}",
      "ground_truth_hash": "aaba00445de7394e",
      "_ground_truth": {
        "columns": [
          "avg_glucose_level",
          "id"
        ],
        "correlation": 0.001
      },
      "_template": "weakest_correlation"
    },
    {
      "question": "Which numeric feature shows the greatest variability, and what is its average value?",
      "hint": "Identify the numeric column with the highest variance, then compute its mean.",
      "n_steps": 3,
      "difficulty": "MEDIUM",
      "template_name": "max_variance_mean",
      "template_params": null,
      "output_type": "scalar",
      "output_schema": "A single number (the mean), rounded to 3 decimal places",
      "ground_truth_hash": "2f5da1b29cf9f115",
      "_ground_truth": 36517.829,
      "_template": "max_variance_mean"
    },
    {
      "question": "Which numeric clinical feature has the lowest average value, and what is its variability? Return as JSON with keys: std.",
      "hint": "Calculate the mean of each numeric column, identify the smallest, then compute its standard deviation and round to three decimal places.",
      "n_steps": 3,
      "difficulty": "MEDIUM",
      "template_name": "min_mean_column_std",
      "template_params": null,
      "output_type": "scalar",
      "output_schema": "A single number (the standard deviation), rounded to 3 decimal places",
      "ground_truth_hash": "09284d168e7f5c97",
      "_ground_truth": 0.215,
      "_template": "min_mean_column_std"
    },
    {
      "question": "Are there any features in the dataset that have a substantial amount of missing data? Return as JSON with keys: count, columns.",
      "hint": "Calculate the percentage of missing values for each column, count how many exceed a 5% threshold, and list their names alphabetically.",
      "n_steps": 3,
      "difficulty": "EASY",
      "template_name": "count_high_missing_columns",
      "template_params": {
        "missing_threshold": 5.0
      },
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 2 keys: \"count\" (integer) and \"columns\" (list of column names, alphabetically sorted). Example: {\"count\": 3, \"columns\": [\"col_a\", \"col_b\", \"col_c\"]}",
      "ground_truth_hash": "2c42c4348e535666",
      "_ground_truth": {
        "count": 0,
        "columns": []
      },
      "_template": "count_high_missing_columns"
    },
    {
      "question": "Are any of the dataset's features missing more than 10% of their values? Return as JSON with keys: count, columns.",
      "hint": "Compute the percentage of missing values for each column and identify those above a 10% threshold.",
      "n_steps": 3,
      "difficulty": "EASY",
      "template_name": "count_high_missing_columns",
      "template_params": {
        "missing_threshold": 10.0
      },
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 2 keys: \"count\" (integer) and \"columns\" (list of column names, alphabetically sorted). Example: {\"count\": 3, \"columns\": [\"col_a\", \"col_b\", \"col_c\"]}",
      "ground_truth_hash": "2c42c4348e535666",
      "_ground_truth": {
        "count": 0,
        "columns": []
      },
      "_template": "count_high_missing_columns"
    },
    {
      "question": "Which numeric column in the dataset has the widest spread, and what are its key percentile values? Return as JSON with keys: column, p10, p25, p50, p75, p90.",
      "hint": "Find the numeric column with the largest range, then compute its 10th, 25th, 50th, 75th, and 90th percentiles.",
      "n_steps": 3,
      "difficulty": "EASY",
      "template_name": "percentile_ranking",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 6 keys: \"column\" (analyzed column), \"p10\" (10th percentile rounded to 4 decimals), \"p25\" (25th percentile), \"p50\" (median), \"p75\" (75th percentile), and \"p90\" (90th percentile). Example: {\"column\": \"income\", \"p10\": 25000.0000, \"p25\": 40000.0000, \"p50\": 55000.0000, \"p75\": 75000.0000, \"p90\": 100000.0000}",
      "ground_truth_hash": "32feec9751b290bd",
      "_ground_truth": {
        "column": "id",
        "p10": 6972.5,
        "p25": 17741.25,
        "p50": 36932.0,
        "p75": 54682.0,
        "p90": 65667.6
      },
      "_template": "percentile_ranking"
    },
    {
      "question": "Which numeric column varies the most across patients, and what are its key descriptive statistics? Return as JSON with keys: column, count, mean, std, min, max, median, skewness, kurtosis.",
      "hint": "Identify the numeric feature with the highest variance, then compute its count, mean, standard deviation, min, max, median, skewness, and kurtosis.",
      "n_steps": 3,
      "difficulty": "EASY",
      "template_name": "descriptive_summary",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 9 keys: \"column\", \"count\" (integer), \"mean\" (rounded to 4 decimals), \"std\", \"min\", \"max\", \"median\", \"skewness\", and \"kurtosis\" (all rounded to 4 decimals). Example: {\"column\": \"age\", \"count\": 1000, \"mean\": 35.4567, \"std\": 12.3456, \"min\": 18.0000, \"max\": 85.0000, \"median\": 34.0000, \"skewness\": 0.5678, \"kurtosis\": -0.2345}",
      "ground_truth_hash": "2bb8c55a9e11e478",
      "_ground_truth": {
        "column": "id",
        "count": 5110,
        "mean": 36517.8294,
        "std": 21161.7216,
        "min": 67.0,
        "max": 72940.0,
        "median": 36932.0,
        "skewness": -0.0199,
        "kurtosis": -1.2124
      },
      "_template": "descriptive_summary"
    }
  ]
}