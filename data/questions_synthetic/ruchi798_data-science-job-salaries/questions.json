{
  "dataset_columns": [
    "Unnamed: 0",
    "work_year",
    "experience_level",
    "employment_type",
    "job_title",
    "salary",
    "salary_currency",
    "salary_in_usd",
    "employee_residence",
    "remote_ratio",
    "company_location",
    "company_size"
  ],
  "questions": [
    {
      "question": "Can the numeric column with the greatest variance be explained by a few other numeric features? Return as JSON with keys: target, predictors, r_squared, adj_r_squared, n_significant, coefficients, p_values.",
      "hint": "Pick the numeric column with highest variance, select its three most correlated numeric columns, fit an OLS regression, and report the model fit and significance.",
      "n_steps": 10,
      "difficulty": "VERY_HARD",
      "template_name": "multiple_regression_top_predictors",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 6 keys: \"target\" (column name), \"predictors\" (list of 3 column names), \"r_squared\" (rounded to 4 decimals), \"adj_r_squared\" (rounded to 4 decimals), \"n_significant\" (integer count of predictors with p < 0.05), \"coefficients\" (dict mapping predictor names to coefficients rounded to 4 decimals), and \"p_values\" (dict mapping predictor names to p-values rounded to 6 decimals). Example: {\"target\": \"price\", \"predictors\": [\"sqft\", \"bedrooms\", \"age\"], \"r_squared\": 0.7234, \"adj_r_squared\": 0.7156, \"n_significant\": 2, \"coefficients\": {\"sqft\": 123.45, \"bedrooms\": 5000.12, \"age\": -200.34}, \"p_values\": {\"sqft\": 0.000001, \"bedrooms\": 0.023456, \"age\": 0.156789}}",
      "ground_truth_hash": "0f75bd6020418cb7",
      "_ground_truth": {
        "target": "salary",
        "predictors": [
          "Unnamed: 0",
          "work_year",
          "salary_in_usd"
        ],
        "r_squared": 0.014,
        "adj_r_squared": 0.0091,
        "n_significant": 0,
        "coefficients": {
          "Unnamed: 0": -720.099,
          "work_year": -7138.8658,
          "salary_in_usd": -1.517
        },
        "p_values": {
          "Unnamed: 0": 0.350183,
          "work_year": 0.970848,
          "salary_in_usd": 0.090126
        }
      },
      "_template": "multiple_regression_top_predictors"
    },
    {
      "question": "Does the most variable numeric measurement differ significantly across experience groups? Return as JSON with keys: target_column, grouping_column, n_groups, f_statistic, p_value, significant, best_group, best_mean, worst_group, worst_mean, eta_squared.",
      "hint": "Identify the numeric column with highest variance, choose a categorical column having 3\u201110 distinct values, then perform a one\u2011way ANOVA to compare group means.",
      "n_steps": 9,
      "difficulty": "VERY_HARD",
      "template_name": "anova_discovered_groups",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 11 keys: \"target_column\", \"grouping_column\", \"n_groups\" (integer), \"f_statistic\" (rounded to 4 decimals), \"p_value\" (rounded to 6 decimals), \"significant\" (boolean), \"best_group\" (category with highest mean), \"best_mean\" (rounded to 4 decimals), \"worst_group\" (category with lowest mean), \"worst_mean\" (rounded to 4 decimals), and \"eta_squared\" (effect size, rounded to 4 decimals). Example: {\"target_column\": \"sales\", \"grouping_column\": \"region\", \"n_groups\": 4, \"f_statistic\": 15.2345, \"p_value\": 0.000012, \"significant\": true, \"best_group\": \"West\", \"best_mean\": 1234.5678, \"worst_group\": \"East\", \"worst_mean\": 890.1234, \"eta_squared\": 0.1523}",
      "ground_truth_hash": "d5216f6303cb6898",
      "_ground_truth": {
        "target_column": "salary",
        "grouping_column": "experience_level",
        "n_groups": 4,
        "f_statistic": 1.2879,
        "p_value": 0.277587,
        "significant": "False",
        "best_group": "MI",
        "best_mean": 480617.6901,
        "worst_group": "SE",
        "worst_mean": 213949.3536,
        "eta_squared": 0.0064
      },
      "_template": "anova_discovered_groups"
    },
    {
      "question": "Which numeric feature best predicts the most variable measurement in the dataset? Return as JSON with keys: target, best_predictor, correlation, r_squared, coefficient, p_value.",
      "hint": "Identify the numeric column with highest variance, compute absolute correlations with it, pick the strongest, then fit a simple OLS regression to report the stats.",
      "n_steps": 8,
      "difficulty": "HARD",
      "template_name": "regression_most_predictive",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 6 keys: \"target\" (column name), \"best_predictor\" (column name), \"correlation\" (rounded to 3 decimals), \"r_squared\" (rounded to 4 decimals), \"coefficient\" (rounded to 4 decimals), and \"p_value\" (rounded to 6 decimals). Example: {\"target\": \"price\", \"best_predictor\": \"sqft\", \"correlation\": 0.834, \"r_squared\": 0.6956, \"coefficient\": 135.2847, \"p_value\": 0.000001}",
      "ground_truth_hash": "94248172ee410ed3",
      "_ground_truth": {
        "target": "salary",
        "best_predictor": "Unnamed: 0",
        "correlation": 0.096,
        "r_squared": 0.0093,
        "coefficient": -847.6004,
        "p_value": 0.017694
      },
      "_template": "regression_most_predictive"
    },
    {
      "question": "Does the numeric column with the highest variance show a significant difference between two groups defined by a binary characteristic? Return as JSON with keys: target_column, grouping_column, group1, group2, mean1, mean2, t_statistic, p_value, significant.",
      "hint": "Identify the most variable numeric column, use or create a binary grouping column, then compare group means with a t\u2011test.",
      "n_steps": 8,
      "difficulty": "HARD",
      "template_name": "ttest_discovered_groups",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 9 keys: \"target_column\", \"grouping_column\", \"group1\", \"group2\", \"mean1\" (rounded to 4 decimals), \"mean2\" (rounded to 4 decimals), \"t_statistic\" (rounded to 4 decimals), \"p_value\" (rounded to 6 decimals), and \"significant\" (boolean, true if p < 0.05). Example: {\"target_column\": \"score\", \"grouping_column\": \"gender\", \"group1\": \"M\", \"group2\": \"F\", \"mean1\": 75.4321, \"mean2\": 78.1234, \"t_statistic\": -2.3456, \"p_value\": 0.019234, \"significant\": true}",
      "ground_truth_hash": "6eb1dfecd57710f0",
      "_ground_truth": {
        "target_column": "salary",
        "grouping_column": "_binary_group",
        "group1": "low",
        "group2": "high",
        "mean1": 486754.5461,
        "mean2": 160708.4356,
        "t_statistic": 2.6132,
        "p_value": 0.009193,
        "significant": "True"
      },
      "_template": "ttest_discovered_groups"
    },
    {
      "question": "Is there any numeric column in the dataset that appears to follow a normal distribution? Return as JSON with keys: column, ks_statistic, p_value, is_normal, sample_mean, sample_std.",
      "hint": "Identify the numeric column with the smallest absolute skewness, standardize its values, and run a Kolmogorov\u2011Smirnov test against a standard normal distribution.",
      "n_steps": 7,
      "difficulty": "MEDIUM",
      "template_name": "ks_normality_test",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 6 keys: \"column\" (tested column), \"ks_statistic\" (rounded to 4 decimals), \"p_value\" (rounded to 6 decimals), \"is_normal\" (boolean, true if p >= 0.05), \"sample_mean\" (rounded to 4 decimals), and \"sample_std\" (rounded to 4 decimals). Example: {\"column\": \"height\", \"ks_statistic\": 0.0456, \"p_value\": 0.234567, \"is_normal\": true, \"sample_mean\": 170.1234, \"sample_std\": 10.5678}",
      "ground_truth_hash": "3e2dce04be488350",
      "_ground_truth": {
        "column": "Unnamed: 0",
        "ks_statistic": 0.0578,
        "p_value": 0.033098,
        "is_normal": "False",
        "sample_mean": 303.0,
        "sample_std": 175.3701
      },
      "_template": "ks_normality_test"
    },
    {
      "question": "Is the variability of the most spread-out numeric measurement consistent across different experience levels? Return as JSON with keys: target_column, grouping_column, n_groups, levene_statistic, p_value, variances_equal, group_variances.",
      "hint": "Find the numeric column with the highest variance, select a categorical column with 2-6 groups, and use Levene's test to assess variance equality across those groups.",
      "n_steps": 7,
      "difficulty": "HARD",
      "template_name": "levene_variance_test",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 7 keys: \"target_column\", \"grouping_column\", \"n_groups\" (integer), \"levene_statistic\" (rounded to 4 decimals), \"p_value\" (rounded to 6 decimals), \"variances_equal\" (boolean, true if p >= 0.05), and \"group_variances\" (dict mapping group names to variance rounded to 4 decimals). Example: {\"target_column\": \"score\", \"grouping_column\": \"class\", \"n_groups\": 3, \"levene_statistic\": 2.3456, \"p_value\": 0.098765, \"variances_equal\": true, \"group_variances\": {\"A\": 123.4567, \"B\": 145.6789, \"C\": 112.3456}}",
      "ground_truth_hash": "aefdb52be6ac9c6c",
      "_ground_truth": {
        "target_column": "salary",
        "grouping_column": "experience_level",
        "n_groups": 4,
        "levene_statistic": 1.6768,
        "p_value": 0.170807,
        "variances_equal": "True",
        "group_variances": {
          "EN": 423782395797.1244,
          "EX": 1305602425216.3464,
          "MI": 5997055849303.337,
          "SE": 341387092099.5197
        }
      },
      "_template": "levene_variance_test"
    },
    {
      "question": "Which pair of numeric variables in the dataset exhibits the strongest monotonic relationship? Return as JSON with keys: columns, spearman_rho, p_value, interpretation.",
      "hint": "Calculate Spearman correlation for all numeric columns, find the pair with the highest absolute value, and report the rho, p-value, and interpretation.",
      "n_steps": 6,
      "difficulty": "MEDIUM",
      "template_name": "spearman_rank_correlation",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 4 keys: \"columns\" (list of 2 column names, alphabetically sorted), \"spearman_rho\" (correlation coefficient rounded to 4 decimals), \"p_value\" (rounded to 6 decimals), and \"interpretation\" (string: \"strong\", \"moderate\", \"weak\", or \"negligible\"). Example: {\"columns\": [\"age\", \"income\"], \"spearman_rho\": 0.7234, \"p_value\": 0.000001, \"interpretation\": \"strong\"}",
      "ground_truth_hash": "cfc0c7f4d87bfd3c",
      "_ground_truth": {
        "columns": [
          "Unnamed: 0",
          "work_year"
        ],
        "spearman_rho": 0.8994,
        "p_value": 0.0,
        "interpretation": "strong"
      },
      "_template": "spearman_rank_correlation"
    },
    {
      "question": "Do the two most skewed salary-related variables become more correlated after applying a log transformation? Return as JSON with keys: columns, original_correlation, log_correlation, improvement, transformation_helpful.",
      "hint": "Find the numeric columns with the highest absolute skewness, calculate their Pearson correlation, apply a log1p transform to both, recalculate the correlation, then compare the absolute values.",
      "n_steps": 6,
      "difficulty": "HARD",
      "template_name": "correlation_change_analysis",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 5 keys: \"columns\" (list of 2 column names, alphabetically sorted), \"original_correlation\" (Pearson, rounded to 4 decimals), \"log_correlation\" (after log transform, rounded to 4 decimals), \"improvement\" (absolute difference, rounded to 4 decimals), and \"transformation_helpful\" (boolean, true if |log_corr| > |orig_corr|). Example: {\"columns\": [\"income\", \"spending\"], \"original_correlation\": 0.4567, \"log_correlation\": 0.7234, \"improvement\": 0.2667, \"transformation_helpful\": true}",
      "ground_truth_hash": "c08a63dec2148bfb",
      "_ground_truth": {
        "columns": [
          "salary",
          "salary_in_usd"
        ],
        "original_correlation": -0.0839,
        "log_correlation": 0.3419,
        "improvement": 0.2579,
        "transformation_helpful": "True"
      },
      "_template": "correlation_change_analysis"
    },
    {
      "question": "Which numeric attribute shows the greatest spread and how many extreme values does it contain? Return as JSON with keys: column, q1, q3, iqr, lower_fence, upper_fence, n_outliers.",
      "hint": "Find the numeric column with the highest variance, then compute its Q1, Q3, IQR, lower/upper fences, and count outliers.",
      "n_steps": 5,
      "difficulty": "EASY",
      "template_name": "iqr_outlier_analysis",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 7 keys: \"column\" (analyzed column), \"q1\" (25th percentile rounded to 4 decimals), \"q3\" (75th percentile rounded to 4 decimals), \"iqr\" (rounded to 4 decimals), \"lower_fence\" (rounded to 4 decimals), \"upper_fence\" (rounded to 4 decimals), and \"n_outliers\" (integer count). Example: {\"column\": \"salary\", \"q1\": 45000.0000, \"q3\": 75000.0000, \"iqr\": 30000.0000, \"lower_fence\": 0.0000, \"upper_fence\": 120000.0000, \"n_outliers\": 23}",
      "ground_truth_hash": "161820d5e0a0129b",
      "_ground_truth": {
        "column": "salary",
        "q1": 70000.0,
        "q3": 165000.0,
        "iqr": 95000.0,
        "lower_fence": -72500.0,
        "upper_fence": 307500.0,
        "n_outliers": 44
      },
      "_template": "iqr_outlier_analysis"
    },
    {
      "question": "Which numeric column shows the greatest variability and does its distribution appear normal? Return as JSON with keys: distribution, median, iqr.",
      "hint": "Find the numeric column with the highest variance, run a Shapiro\u2011Wilk test for normality, and if non\u2011normal report its median and inter\u2011quartile range.",
      "n_steps": 5,
      "difficulty": "HARD",
      "template_name": "conditional_normality",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 3 keys. If normal: {\"distribution\": \"normal\", \"mean\": <number>, \"std\": <number>}. If non-normal: {\"distribution\": \"non-normal\", \"median\": <number>, \"iqr\": <number>}. The \"iqr\" value is Q3 minus Q1 as a single number. All numeric values rounded to 3 decimal places.",
      "ground_truth_hash": "db71e935d89eed2a",
      "_ground_truth": {
        "distribution": "non-normal",
        "median": 115000.0,
        "iqr": 95000.0
      },
      "_template": "conditional_normality"
    },
    {
      "question": "Which categorical group has the highest average of the most variable numeric measurement in the dataset? Return as JSON with keys: category_column, best_category, target_column, mean_value.",
      "hint": "Identify the numeric column with the greatest variance, select a categorical column with 2\u201120 unique values, compute the mean of the numeric column per category, and report the category with the highest mean.",
      "n_steps": 5,
      "difficulty": "HARD",
      "template_name": "category_highest_target_mean",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 4 keys: \"category_column\" (the grouping column name), \"best_category\" (the category value with highest mean), \"target_column\" (the numeric column analyzed), and \"mean_value\" (rounded to 3 decimal places). Example: {\"category_column\": \"region\", \"best_category\": \"West\", \"target_column\": \"sales\", \"mean_value\": 1234.567}",
      "ground_truth_hash": "0b3a997aa1550de4",
      "_ground_truth": {
        "category_column": "experience_level",
        "best_category": "MI",
        "target_column": "salary",
        "mean_value": 480617.69
      },
      "_template": "category_highest_target_mean"
    },
    {
      "question": "I wonder how many numeric columns have extreme values and the total number of outliers across the dataset. Return as JSON with keys: columns_with_outliers, total_outliers.",
      "hint": "Flag values beyond 3 standard deviations from the mean for each numeric column, then count columns with any outliers and the overall outlier count.",
      "n_steps": 4,
      "difficulty": "MEDIUM",
      "template_name": "count_outlier_columns",
      "template_params": {
        "z_threshold": 3.0
      },
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 2 keys: \"columns_with_outliers\" (integer count of columns containing at least one outlier) and \"total_outliers\" (integer total count of outlier values across all columns). Example: {\"columns_with_outliers\": 3, \"total_outliers\": 47}",
      "ground_truth_hash": "a453df0b671a09fe",
      "_ground_truth": {
        "columns_with_outliers": 2,
        "total_outliers": 15
      },
      "_template": "count_outlier_columns"
    },
    {
      "question": "Which numeric column shows the greatest relative variability across the dataset? Return as JSON with keys: column, cv, mean, std.",
      "hint": "Calculate the coefficient of variation (std/mean*100) for each numeric column and select the one with the highest value.",
      "n_steps": 4,
      "difficulty": "EASY",
      "template_name": "coefficient_of_variation",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 4 keys: \"column\" (name of column with highest CV), \"cv\" (coefficient of variation as percentage rounded to 2 decimals), \"mean\" (rounded to 4 decimals), and \"std\" (rounded to 4 decimals). Example: {\"column\": \"price\", \"cv\": 45.23, \"mean\": 1234.5678, \"std\": 558.4567}",
      "ground_truth_hash": "e3abf26e5f87cab5",
      "_ground_truth": {
        "column": "salary",
        "cv": 476.65,
        "mean": 324000.0626,
        "std": 1544357.4866
      },
      "_template": "coefficient_of_variation"
    },
    {
      "question": "Which two numeric fields in this dataset are most strongly linearly related? Return as JSON with keys: columns, correlation.",
      "hint": "Compute the absolute correlation matrix for all numeric columns, zero out the diagonal, and identify the pair with the highest value.",
      "n_steps": 4,
      "difficulty": "MEDIUM",
      "template_name": "strongest_correlation",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly two keys: \"columns\" (a list of the two column names, alphabetically sorted) and \"correlation\" (the correlation coefficient rounded to 3 decimal places). Example: {\"columns\": [\"col_a\", \"col_b\"], \"correlation\": 0.847}",
      "ground_truth_hash": "8b55af674d0b057c",
      "_ground_truth": {
        "columns": [
          "Unnamed: 0",
          "work_year"
        ],
        "correlation": 0.887
      },
      "_template": "strongest_correlation"
    },
    {
      "question": "Which pair of numeric features in the dataset shows the weakest correlation? Return as JSON with keys: columns, correlation.",
      "hint": "Calculate the absolute correlation matrix for numeric columns, ignore the diagonal, and locate the smallest non\u2011zero value.",
      "n_steps": 4,
      "difficulty": "MEDIUM",
      "template_name": "weakest_correlation",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly two keys: \"columns\" (a list of the two column names, alphabetically sorted) and \"correlation\" (the absolute correlation value rounded to 3 decimal places). Example: {\"columns\": [\"col_a\", \"col_b\"], \"correlation\": 0.012}",
      "ground_truth_hash": "5ebdd5dac7b8593c",
      "_ground_truth": {
        "columns": [
          "remote_ratio",
          "salary"
        ],
        "correlation": 0.015
      },
      "_template": "weakest_correlation"
    },
    {
      "question": "Which numeric field in the dataset varies the most, and what is its average value? Return as JSON with keys: result.",
      "hint": "Identify the numeric column with the highest variance, then compute its mean.",
      "n_steps": 3,
      "difficulty": "MEDIUM",
      "template_name": "max_variance_mean",
      "template_params": null,
      "output_type": "scalar",
      "output_schema": "A single number (the mean), rounded to 3 decimal places",
      "ground_truth_hash": "4fedcd77320f26cc",
      "_ground_truth": 324000.063,
      "_template": "max_variance_mean"
    },
    {
      "question": "Which numeric column has the smallest mean and what is its standard deviation? Return as JSON with keys: std.",
      "hint": "Find the numeric column with the lowest mean, then calculate its standard deviation.",
      "n_steps": 3,
      "difficulty": "MEDIUM",
      "template_name": "min_mean_column_std",
      "template_params": null,
      "output_type": "scalar",
      "output_schema": "A single number (the standard deviation), rounded to 3 decimal places",
      "ground_truth_hash": "62ce484a8fdfb563",
      "_ground_truth": 40.709,
      "_template": "min_mean_column_std"
    },
    {
      "question": "I wonder if any columns in this dataset have a substantial amount of missing data (e.g., over 5%). Return as JSON with keys: count, columns.",
      "hint": "Calculate the missing percentage for each column, count those exceeding 5%, and list their names alphabetically.",
      "n_steps": 3,
      "difficulty": "EASY",
      "template_name": "count_high_missing_columns",
      "template_params": {
        "missing_threshold": 5.0
      },
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 2 keys: \"count\" (integer) and \"columns\" (list of column names, alphabetically sorted). Example: {\"count\": 3, \"columns\": [\"col_a\", \"col_b\", \"col_c\"]}",
      "ground_truth_hash": "2c42c4348e535666",
      "_ground_truth": {
        "count": 0,
        "columns": []
      },
      "_template": "count_high_missing_columns"
    },
    {
      "question": "Are there any columns in the dataset that have a high proportion of missing values, for example over 10%? Return as JSON with keys: count, columns.",
      "hint": "Calculate the percentage of missing values for each column, filter those above a 10% threshold, count them and list their names alphabetically.",
      "n_steps": 3,
      "difficulty": "EASY",
      "template_name": "count_high_missing_columns",
      "template_params": {
        "missing_threshold": 10.0
      },
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 2 keys: \"count\" (integer) and \"columns\" (list of column names, alphabetically sorted). Example: {\"count\": 3, \"columns\": [\"col_a\", \"col_b\", \"col_c\"]}",
      "ground_truth_hash": "2c42c4348e535666",
      "_ground_truth": {
        "count": 0,
        "columns": []
      },
      "_template": "count_high_missing_columns"
    },
    {
      "question": "Which numeric field in the dataset has the greatest spread, and what are its main percentile values? Return as JSON with keys: column, p10, p25, p50, p75, p90.",
      "hint": "Identify the numeric column with the largest range, then calculate its 10th, 25th, 50th, 75th, and 90th percentiles.",
      "n_steps": 3,
      "difficulty": "EASY",
      "template_name": "percentile_ranking",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 6 keys: \"column\" (analyzed column), \"p10\" (10th percentile rounded to 4 decimals), \"p25\" (25th percentile), \"p50\" (median), \"p75\" (75th percentile), and \"p90\" (90th percentile). Example: {\"column\": \"income\", \"p10\": 25000.0000, \"p25\": 40000.0000, \"p50\": 55000.0000, \"p75\": 75000.0000, \"p90\": 100000.0000}",
      "ground_truth_hash": "cefbdbce27e164c8",
      "_ground_truth": {
        "column": "salary",
        "p10": 42720.0,
        "p25": 70000.0,
        "p50": 115000.0,
        "p75": 165000.0,
        "p90": 237000.0
      },
      "_template": "percentile_ranking"
    },
    {
      "question": "Which numeric attribute in the dataset varies the most, and what are its basic descriptive statistics? Return as JSON with keys: column, count, mean, std, min, max, median, skewness, kurtosis.",
      "hint": "Identify the numeric column with the highest variance, then compute count, mean, std, min, max, median, skewness, and kurtosis for that column.",
      "n_steps": 3,
      "difficulty": "EASY",
      "template_name": "descriptive_summary",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 9 keys: \"column\", \"count\" (integer), \"mean\" (rounded to 4 decimals), \"std\", \"min\", \"max\", \"median\", \"skewness\", and \"kurtosis\" (all rounded to 4 decimals). Example: {\"column\": \"age\", \"count\": 1000, \"mean\": 35.4567, \"std\": 12.3456, \"min\": 18.0000, \"max\": 85.0000, \"median\": 34.0000, \"skewness\": 0.5678, \"kurtosis\": -0.2345}",
      "ground_truth_hash": "96265c3ce571ea3c",
      "_ground_truth": {
        "column": "salary",
        "count": 607,
        "mean": 324000.0626,
        "std": 1544357.4866,
        "min": 4000.0,
        "max": 30400000.0,
        "median": 115000.0,
        "skewness": 14.0529,
        "kurtosis": 247.426
      },
      "_template": "descriptive_summary"
    }
  ]
}