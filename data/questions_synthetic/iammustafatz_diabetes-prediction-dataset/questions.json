{
  "dataset_columns": [
    "gender",
    "age",
    "hypertension",
    "heart_disease",
    "smoking_history",
    "bmi",
    "HbA1c_level",
    "blood_glucose_level",
    "diabetes"
  ],
  "questions": [
    {
      "question": "Can we predict the most variable numeric health measurement using other clinical features? Return as JSON with keys: target, predictors, r_squared, adj_r_squared, n_significant, coefficients, p_values.",
      "hint": "Identify the numeric column with the highest variance, compute absolute correlations with other numeric columns, select the top three predictors, fit an OLS regression, and report the model statistics.",
      "n_steps": 10,
      "difficulty": "VERY_HARD",
      "template_name": "multiple_regression_top_predictors",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 6 keys: \"target\" (column name), \"predictors\" (list of 3 column names), \"r_squared\" (rounded to 4 decimals), \"adj_r_squared\" (rounded to 4 decimals), \"n_significant\" (integer count of predictors with p < 0.05), \"coefficients\" (dict mapping predictor names to coefficients rounded to 4 decimals), and \"p_values\" (dict mapping predictor names to p-values rounded to 6 decimals). Example: {\"target\": \"price\", \"predictors\": [\"sqft\", \"bedrooms\", \"age\"], \"r_squared\": 0.7234, \"adj_r_squared\": 0.7156, \"n_significant\": 2, \"coefficients\": {\"sqft\": 123.45, \"bedrooms\": 5000.12, \"age\": -200.34}, \"p_values\": {\"sqft\": 0.000001, \"bedrooms\": 0.023456, \"age\": 0.156789}}",
      "ground_truth_hash": "25d938658542560b",
      "_ground_truth": {
        "target": "blood_glucose_level",
        "predictors": [
          "diabetes",
          "HbA1c_level",
          "age"
        ],
        "r_squared": 0.176,
        "adj_r_squared": 0.176,
        "n_significant": 1,
        "coefficients": {
          "diabetes": 61.2395,
          "HbA1c_level": -0.0617,
          "age": 0.0047
        },
        "p_values": {
          "diabetes": 0.0,
          "HbA1c_level": 0.604539,
          "age": 0.382956
        }
      },
      "_template": "multiple_regression_top_predictors"
    },
    {
      "question": "Which numeric variable is the most skewed, and what are its mean, bootstrap 95% confidence interval and standard error? Return as JSON with keys: column, skewness, mean, ci_lower, ci_upper, std_error, n_bootstrap.",
      "hint": "Calculate absolute skewness for all numeric columns, select the highest, then perform bootstrap resampling on its values to estimate the mean, confidence interval and standard error.",
      "n_steps": 9,
      "difficulty": "VERY_HARD",
      "template_name": "bootstrap_ci_discovered",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 7 keys: \"column\" (name of most skewed column), \"skewness\" (rounded to 4 decimals), \"mean\" (rounded to 4 decimals), \"ci_lower\" (lower bound of 95% CI, rounded to 4 decimals), \"ci_upper\" (upper bound, rounded to 4 decimals), \"std_error\" (bootstrap standard error, rounded to 4 decimals), and \"n_bootstrap\" (integer, the number of bootstrap samples). Example: {\"column\": \"income\", \"skewness\": 2.3456, \"mean\": 50000.1234, \"ci_lower\": 48500.5678, \"ci_upper\": 51500.9012, \"std_error\": 750.3456, \"n_bootstrap\": 1000}",
      "ground_truth_hash": "e734389a7217c9ac",
      "_ground_truth": {
        "column": "heart_disease",
        "skewness": 4.7339,
        "mean": 0.0394,
        "ci_lower": 0.0382,
        "ci_upper": 0.0406,
        "std_error": 0.0006,
        "n_bootstrap": 1000
      },
      "_template": "bootstrap_ci_discovered"
    },
    {
      "question": "Does the most variable measurement differ across any demographic group with a few categories? Return as JSON with keys: question, hint.",
      "hint": "Find the numeric column with the highest variance, select a categorical column that has between 3 and 10 unique values, then compare the group means using a one\u2011way ANOVA.",
      "n_steps": 9,
      "difficulty": "VERY_HARD",
      "template_name": "anova_discovered_groups",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 11 keys: \"target_column\", \"grouping_column\", \"n_groups\" (integer), \"f_statistic\" (rounded to 4 decimals), \"p_value\" (rounded to 6 decimals), \"significant\" (boolean), \"best_group\" (category with highest mean), \"best_mean\" (rounded to 4 decimals), \"worst_group\" (category with lowest mean), \"worst_mean\" (rounded to 4 decimals), and \"eta_squared\" (effect size, rounded to 4 decimals). Example: {\"target_column\": \"sales\", \"grouping_column\": \"region\", \"n_groups\": 4, \"f_statistic\": 15.2345, \"p_value\": 0.000012, \"significant\": true, \"best_group\": \"West\", \"best_mean\": 1234.5678, \"worst_group\": \"East\", \"worst_mean\": 890.1234, \"eta_squared\": 0.1523}",
      "ground_truth_hash": "888c2ced0d180de0",
      "_ground_truth": {
        "target_column": "blood_glucose_level",
        "grouping_column": "gender",
        "n_groups": 3,
        "f_statistic": 14.7981,
        "p_value": 0.0,
        "significant": "True",
        "best_group": "Other",
        "best_mean": 139.4444,
        "worst_group": "Female",
        "worst_mean": 137.469,
        "eta_squared": 0.0003
      },
      "_template": "anova_discovered_groups"
    },
    {
      "question": "Which numeric variable shows the strongest relationship with the most variable measurement in the dataset? Return as JSON with keys: target, best_predictor, correlation, r_squared, coefficient, p_value.",
      "hint": "Find the numeric column with highest variance, compute absolute correlations with it, select the top correlated feature, fit a simple OLS regression, and report the statistics.",
      "n_steps": 8,
      "difficulty": "HARD",
      "template_name": "regression_most_predictive",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 6 keys: \"target\" (column name), \"best_predictor\" (column name), \"correlation\" (rounded to 3 decimals), \"r_squared\" (rounded to 4 decimals), \"coefficient\" (rounded to 4 decimals), and \"p_value\" (rounded to 6 decimals). Example: {\"target\": \"price\", \"best_predictor\": \"sqft\", \"correlation\": 0.834, \"r_squared\": 0.6956, \"coefficient\": 135.2847, \"p_value\": 0.000001}",
      "ground_truth_hash": "209c0e9b7aa666c2",
      "_ground_truth": {
        "target": "blood_glucose_level",
        "best_predictor": "diabetes",
        "correlation": 0.42,
        "r_squared": 0.176,
        "coefficient": 61.2422,
        "p_value": 0.0
      },
      "_template": "regression_most_predictive"
    },
    {
      "question": "Is the most variable numeric measurement significantly different between two groups formed by a median split of another feature? Return as JSON with keys: target_column, grouping_column, group1, group2, mean1, mean2, t_statistic, p_value, significant.",
      "hint": "Find the numeric column with highest variance, create a binary grouping column by splitting another numeric column at its median, then compare the groups' means with a t-test.",
      "n_steps": 8,
      "difficulty": "HARD",
      "template_name": "ttest_discovered_groups",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 9 keys: \"target_column\", \"grouping_column\", \"group1\", \"group2\", \"mean1\" (rounded to 4 decimals), \"mean2\" (rounded to 4 decimals), \"t_statistic\" (rounded to 4 decimals), \"p_value\" (rounded to 6 decimals), and \"significant\" (boolean, true if p < 0.05). Example: {\"target_column\": \"score\", \"grouping_column\": \"gender\", \"group1\": \"M\", \"group2\": \"F\", \"mean1\": 75.4321, \"mean2\": 78.1234, \"t_statistic\": -2.3456, \"p_value\": 0.019234, \"significant\": true}",
      "ground_truth_hash": "21c71646b7740102",
      "_ground_truth": {
        "target_column": "blood_glucose_level",
        "grouping_column": "_binary_group",
        "group1": "high",
        "group2": "low",
        "mean1": 142.3828,
        "mean2": 133.904,
        "t_statistic": 33.1055,
        "p_value": 0.0,
        "significant": "True"
      },
      "_template": "ttest_discovered_groups"
    },
    {
      "question": "Which numeric feature in this diabetes dataset is the most normally distributed? Return as JSON with keys: column, ks_statistic, p_value, is_normal, sample_mean, sample_std.",
      "hint": "Find the numeric column with the lowest absolute skewness, standardize its values, and perform a one\u2011sample Kolmogorov\u2013Smirnov test against the standard normal distribution.",
      "n_steps": 7,
      "difficulty": "MEDIUM",
      "template_name": "ks_normality_test",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 6 keys: \"column\" (tested column), \"ks_statistic\" (rounded to 4 decimals), \"p_value\" (rounded to 6 decimals), \"is_normal\" (boolean, true if p >= 0.05), \"sample_mean\" (rounded to 4 decimals), and \"sample_std\" (rounded to 4 decimals). Example: {\"column\": \"height\", \"ks_statistic\": 0.0456, \"p_value\": 0.234567, \"is_normal\": true, \"sample_mean\": 170.1234, \"sample_std\": 10.5678}",
      "ground_truth_hash": "a4bcd77b07f014f0",
      "_ground_truth": {
        "column": "age",
        "ks_statistic": 0.0457,
        "p_value": 0.0,
        "is_normal": "False",
        "sample_mean": 41.8859,
        "sample_std": 22.5168
      },
      "_template": "ks_normality_test"
    },
    {
      "question": "Is the most variable numeric measurement's variance consistent across different genders? Return as JSON with keys: target_column, grouping_column, n_groups, levene_statistic, p_value, variances_equal, group_variances.",
      "hint": "Identify the numeric column with highest variance, pick a categorical column with 2\u20116 unique values, then apply Levene's test to compare group variances.",
      "n_steps": 7,
      "difficulty": "HARD",
      "template_name": "levene_variance_test",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 7 keys: \"target_column\", \"grouping_column\", \"n_groups\" (integer), \"levene_statistic\" (rounded to 4 decimals), \"p_value\" (rounded to 6 decimals), \"variances_equal\" (boolean, true if p >= 0.05), and \"group_variances\" (dict mapping group names to variance rounded to 4 decimals). Example: {\"target_column\": \"score\", \"grouping_column\": \"class\", \"n_groups\": 3, \"levene_statistic\": 2.3456, \"p_value\": 0.098765, \"variances_equal\": true, \"group_variances\": {\"A\": 123.4567, \"B\": 145.6789, \"C\": 112.3456}}",
      "ground_truth_hash": "77d74c054b214996",
      "_ground_truth": {
        "target_column": "blood_glucose_level",
        "grouping_column": "gender",
        "n_groups": 3,
        "levene_statistic": 8.3251,
        "p_value": 0.000243,
        "variances_equal": "False",
        "group_variances": {
          "Female": 1608.2369,
          "Male": 1725.4031,
          "Other": 1114.2614
        }
      },
      "_template": "levene_variance_test"
    },
    {
      "question": "Which two numeric measurements in the dataset have the strongest monotonic relationship? Return as JSON with keys: columns, spearman_rho, p_value, interpretation.",
      "hint": "Calculate the Spearman correlation matrix for all numeric columns, find the pair with the highest absolute correlation, compute its rho and p-value, and classify the strength.",
      "n_steps": 6,
      "difficulty": "MEDIUM",
      "template_name": "spearman_rank_correlation",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 4 keys: \"columns\" (list of 2 column names, alphabetically sorted), \"spearman_rho\" (correlation coefficient rounded to 4 decimals), \"p_value\" (rounded to 6 decimals), and \"interpretation\" (string: \"strong\", \"moderate\", \"weak\", or \"negligible\"). Example: {\"columns\": [\"age\", \"income\"], \"spearman_rho\": 0.7234, \"p_value\": 0.000001, \"interpretation\": \"strong\"}",
      "ground_truth_hash": "3cef1b377ebc96b1",
      "_ground_truth": {
        "columns": [
          "age",
          "bmi"
        ],
        "spearman_rho": 0.3513,
        "p_value": 0.0,
        "interpretation": "weak"
      },
      "_template": "spearman_rank_correlation"
    },
    {
      "question": "Which two numeric variables are the most skewed and how does a log transformation affect their correlation? Return as JSON with keys: columns, original_correlation, log_correlation, improvement, transformation_helpful.",
      "hint": "Identify the two numeric columns with highest absolute skewness, compute their Pearson correlation, apply a log1p transform to both, recompute the correlation, and compare the absolute values.",
      "n_steps": 6,
      "difficulty": "HARD",
      "template_name": "correlation_change_analysis",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 5 keys: \"columns\" (list of 2 column names, alphabetically sorted), \"original_correlation\" (Pearson, rounded to 4 decimals), \"log_correlation\" (after log transform, rounded to 4 decimals), \"improvement\" (absolute difference, rounded to 4 decimals), and \"transformation_helpful\" (boolean, true if |log_corr| > |orig_corr|). Example: {\"columns\": [\"income\", \"spending\"], \"original_correlation\": 0.4567, \"log_correlation\": 0.7234, \"improvement\": 0.2667, \"transformation_helpful\": true}",
      "ground_truth_hash": "1ab5abc7b3de5607",
      "_ground_truth": {
        "columns": [
          "blood_glucose_level",
          "bmi"
        ],
        "original_correlation": 0.0913,
        "log_correlation": 0.0492,
        "improvement": 0.0421,
        "transformation_helpful": "False"
      },
      "_template": "correlation_change_analysis"
    },
    {
      "question": "Which numeric measurement in the dataset shows the greatest spread, and how many extreme values does it contain? Return as JSON with keys: column, q1, q3, iqr, lower_fence, upper_fence, n_outliers.",
      "hint": "Identify the numeric column with the highest variance, then calculate its Q1, Q3, IQR, lower and upper fences, and count the outliers.",
      "n_steps": 5,
      "difficulty": "EASY",
      "template_name": "iqr_outlier_analysis",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 7 keys: \"column\" (analyzed column), \"q1\" (25th percentile rounded to 4 decimals), \"q3\" (75th percentile rounded to 4 decimals), \"iqr\" (rounded to 4 decimals), \"lower_fence\" (rounded to 4 decimals), \"upper_fence\" (rounded to 4 decimals), and \"n_outliers\" (integer count). Example: {\"column\": \"salary\", \"q1\": 45000.0000, \"q3\": 75000.0000, \"iqr\": 30000.0000, \"lower_fence\": 0.0000, \"upper_fence\": 120000.0000, \"n_outliers\": 23}",
      "ground_truth_hash": "7a0bf823bc2c4e24",
      "_ground_truth": {
        "column": "blood_glucose_level",
        "q1": 100.0,
        "q3": 159.0,
        "iqr": 59.0,
        "lower_fence": 11.5,
        "upper_fence": 247.5,
        "n_outliers": 2038
      },
      "_template": "iqr_outlier_analysis"
    },
    {
      "question": "Which numeric measurement in the dataset has the highest variance, and does it follow a normal distribution or not? Return as JSON with keys: distribution, median, iqr.",
      "hint": "Find the column with the greatest variance, perform a normality test (e.g., Shapiro\u2011Wilk), and report median and IQR for a non\u2011normal distribution (or mean and std if normal).",
      "n_steps": 5,
      "difficulty": "HARD",
      "template_name": "conditional_normality",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 3 keys. If normal: {\"distribution\": \"normal\", \"mean\": <number>, \"std\": <number>}. If non-normal: {\"distribution\": \"non-normal\", \"median\": <number>, \"iqr\": <number>}. The \"iqr\" value is Q3 minus Q1 as a single number. All numeric values rounded to 3 decimal places.",
      "ground_truth_hash": "68b4842f3f3b8678",
      "_ground_truth": {
        "distribution": "non-normal",
        "median": 140.0,
        "iqr": 59.0
      },
      "_template": "conditional_normality"
    },
    {
      "question": "Which demographic group shows the highest average value for the most variable numeric measurement in the dataset? Return as JSON with keys: category_column, best_category, target_column, mean_value.",
      "hint": "Identify the numeric column with the greatest variance, pick a categorical column with moderate cardinality, compute the mean of the numeric column per category, and report the category with the highest mean.",
      "n_steps": 5,
      "difficulty": "HARD",
      "template_name": "category_highest_target_mean",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 4 keys: \"category_column\" (the grouping column name), \"best_category\" (the category value with highest mean), \"target_column\" (the numeric column analyzed), and \"mean_value\" (rounded to 3 decimal places). Example: {\"category_column\": \"region\", \"best_category\": \"West\", \"target_column\": \"sales\", \"mean_value\": 1234.567}",
      "ground_truth_hash": "92137939b8e3b087",
      "_ground_truth": {
        "category_column": "gender",
        "best_category": "Other",
        "target_column": "blood_glucose_level",
        "mean_value": 139.444
      },
      "_template": "category_highest_target_mean"
    },
    {
      "question": "Which two numeric variables show the strongest correlation, and how does that relationship shift after discarding extreme outliers? Return as JSON with keys: columns, original_correlation, outliers_removed, clean_correlation.",
      "hint": "Calculate absolute Pearson correlations among all numeric columns, select the pair with the highest value, filter out rows where either column exceeds 3 standard deviations from its mean, then recompute the correlation on the cleaned data.",
      "n_steps": 5,
      "difficulty": "HARD",
      "template_name": "correlation_after_outlier_removal",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 4 keys: \"columns\" (list of 2 column names, alphabetically sorted), \"original_correlation\" (rounded to 3 decimals), \"outliers_removed\" (integer count), and \"clean_correlation\" (rounded to 3 decimals). Example: {\"columns\": [\"col_a\", \"col_b\"], \"original_correlation\": 0.847, \"outliers_removed\": 12, \"clean_correlation\": 0.891}",
      "ground_truth_hash": "baab8fb4fe376960",
      "_ground_truth": {
        "columns": [
          "blood_glucose_level",
          "diabetes"
        ],
        "original_correlation": 0.42,
        "outliers_removed": 8500,
        "clean_correlation": NaN
      },
      "_template": "correlation_after_outlier_removal"
    },
    {
      "question": "How many numeric variables in the dataset contain outliers, and what is the overall number of outlier values across all numeric columns? Return as JSON with keys: columns_with_outliers, total_outliers.",
      "hint": "For each numeric column, flag values beyond 2.5 standard deviations from the mean, count per column, then summarize the number of columns with any outliers and the total outlier count.",
      "n_steps": 4,
      "difficulty": "MEDIUM",
      "template_name": "count_outlier_columns",
      "template_params": {
        "z_threshold": 2.5
      },
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 2 keys: \"columns_with_outliers\" (integer count of columns containing at least one outlier) and \"total_outliers\" (integer total count of outlier values across all columns). Example: {\"columns_with_outliers\": 3, \"total_outliers\": 47}",
      "ground_truth_hash": "2e514f621cedb4ad",
      "_ground_truth": {
        "columns_with_outliers": 6,
        "total_outliers": 26270
      },
      "_template": "count_outlier_columns"
    },
    {
      "question": "Which numeric feature in the dataset exhibits the highest relative variability? Return as JSON with keys: column, cv, mean, std.",
      "hint": "Calculate the coefficient of variation (std/mean*100) for each numeric column and pick the one with the largest value.",
      "n_steps": 4,
      "difficulty": "EASY",
      "template_name": "coefficient_of_variation",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 4 keys: \"column\" (name of column with highest CV), \"cv\" (coefficient of variation as percentage rounded to 2 decimals), \"mean\" (rounded to 4 decimals), and \"std\" (rounded to 4 decimals). Example: {\"column\": \"price\", \"cv\": 45.23, \"mean\": 1234.5678, \"std\": 558.4567}",
      "ground_truth_hash": "2f0fa58c172eb4e3",
      "_ground_truth": {
        "column": "heart_disease",
        "cv": 493.64,
        "mean": 0.0394,
        "std": 0.1946
      },
      "_template": "coefficient_of_variation"
    },
    {
      "question": "Which two numeric variables in the dataset show the strongest correlation? Return as JSON with keys: columns, correlation.",
      "hint": "Compute the absolute correlation matrix for numeric columns, set the diagonal to zero, and identify the pair with the highest value.",
      "n_steps": 4,
      "difficulty": "MEDIUM",
      "template_name": "strongest_correlation",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly two keys: \"columns\" (a list of the two column names, alphabetically sorted) and \"correlation\" (the correlation coefficient rounded to 3 decimal places). Example: {\"columns\": [\"col_a\", \"col_b\"], \"correlation\": 0.847}",
      "ground_truth_hash": "40131b3d9be7b7df",
      "_ground_truth": {
        "columns": [
          "blood_glucose_level",
          "diabetes"
        ],
        "correlation": 0.42
      },
      "_template": "strongest_correlation"
    },
    {
      "question": "Which two numeric variables have the weakest non\u2011zero correlation in this dataset? Return as JSON with keys: columns, correlation.",
      "hint": "Compute the absolute correlation matrix for the numeric columns, mask the diagonal and zero values, then find the minimum correlation pair.",
      "n_steps": 4,
      "difficulty": "MEDIUM",
      "template_name": "weakest_correlation",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly two keys: \"columns\" (a list of the two column names, alphabetically sorted) and \"correlation\" (the absolute correlation value rounded to 3 decimal places). Example: {\"columns\": [\"col_a\", \"col_b\"], \"correlation\": 0.012}",
      "ground_truth_hash": "38a90554971fe105",
      "_ground_truth": {
        "columns": [
          "bmi",
          "heart_disease"
        ],
        "correlation": 0.061
      },
      "_template": "weakest_correlation"
    },
    {
      "question": "Which numeric feature in the dataset has the highest variance, and what is its average value? Return as JSON with keys: result.",
      "hint": "Find the numeric column with the greatest variance, then compute its mean.",
      "n_steps": 3,
      "difficulty": "MEDIUM",
      "template_name": "max_variance_mean",
      "template_params": null,
      "output_type": "scalar",
      "output_schema": "A single number (the mean), rounded to 3 decimal places",
      "ground_truth_hash": "abe84014470d61cd",
      "_ground_truth": 138.058,
      "_template": "max_variance_mean"
    },
    {
      "question": "Which numeric variable in the dataset has the smallest average value? Return as JSON with keys: question, hint.",
      "hint": "Identify the numeric column with the lowest mean, then calculate its standard deviation (rounded to 3 decimal places).",
      "n_steps": 3,
      "difficulty": "MEDIUM",
      "template_name": "min_mean_column_std",
      "template_params": null,
      "output_type": "scalar",
      "output_schema": "A single number (the standard deviation), rounded to 3 decimal places",
      "ground_truth_hash": "0e51a908f3d7743e",
      "_ground_truth": 0.195,
      "_template": "min_mean_column_std"
    },
    {
      "question": "Are any columns in this dataset missing a large share of their values? Return as JSON with keys: count, columns.",
      "hint": "Compute the missing percentage for each column and count those above a 5% threshold.",
      "n_steps": 3,
      "difficulty": "EASY",
      "template_name": "count_high_missing_columns",
      "template_params": {
        "missing_threshold": 5.0
      },
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 2 keys: \"count\" (integer) and \"columns\" (list of column names, alphabetically sorted). Example: {\"count\": 3, \"columns\": [\"col_a\", \"col_b\", \"col_c\"]}",
      "ground_truth_hash": "2c42c4348e535666",
      "_ground_truth": {
        "count": 0,
        "columns": []
      },
      "_template": "count_high_missing_columns"
    },
    {
      "question": "Are there any features in the dataset that have a substantial amount of missing data? Return as JSON with keys: count, columns.",
      "hint": "Calculate the percentage of missing values per column and identify those exceeding a 10% threshold.",
      "n_steps": 3,
      "difficulty": "EASY",
      "template_name": "count_high_missing_columns",
      "template_params": {
        "missing_threshold": 10.0
      },
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 2 keys: \"count\" (integer) and \"columns\" (list of column names, alphabetically sorted). Example: {\"count\": 3, \"columns\": [\"col_a\", \"col_b\", \"col_c\"]}",
      "ground_truth_hash": "2c42c4348e535666",
      "_ground_truth": {
        "count": 0,
        "columns": []
      },
      "_template": "count_high_missing_columns"
    },
    {
      "question": "Which numeric measurement shows the greatest spread in this health dataset, and what are its key percentile values? Return as JSON with keys: column, p10, p25, p50, p75, p90.",
      "hint": "Find the numeric column with the largest range, then compute its 10th, 25th, 50th, 75th, and 90th percentiles.",
      "n_steps": 3,
      "difficulty": "EASY",
      "template_name": "percentile_ranking",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 6 keys: \"column\" (analyzed column), \"p10\" (10th percentile rounded to 4 decimals), \"p25\" (25th percentile), \"p50\" (median), \"p75\" (75th percentile), and \"p90\" (90th percentile). Example: {\"column\": \"income\", \"p10\": 25000.0000, \"p25\": 40000.0000, \"p50\": 55000.0000, \"p75\": 75000.0000, \"p90\": 100000.0000}",
      "ground_truth_hash": "cadc40a00c030760",
      "_ground_truth": {
        "column": "blood_glucose_level",
        "p10": 85.0,
        "p25": 100.0,
        "p50": 140.0,
        "p75": 159.0,
        "p90": 200.0
      },
      "_template": "percentile_ranking"
    },
    {
      "question": "Which numeric variable in the dataset exhibits the greatest variability, and what are its key descriptive statistics? Return as JSON with keys: column, count, mean, std, min, max, median, skewness, kurtosis.",
      "hint": "Find the numeric column with the highest variance, then compute its count, mean, standard deviation, min, max, median, skewness, and kurtosis.",
      "n_steps": 3,
      "difficulty": "EASY",
      "template_name": "descriptive_summary",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 9 keys: \"column\", \"count\" (integer), \"mean\" (rounded to 4 decimals), \"std\", \"min\", \"max\", \"median\", \"skewness\", and \"kurtosis\" (all rounded to 4 decimals). Example: {\"column\": \"age\", \"count\": 1000, \"mean\": 35.4567, \"std\": 12.3456, \"min\": 18.0000, \"max\": 85.0000, \"median\": 34.0000, \"skewness\": 0.5678, \"kurtosis\": -0.2345}",
      "ground_truth_hash": "c257d24850d8cb1e",
      "_ground_truth": {
        "column": "blood_glucose_level",
        "count": 100000,
        "mean": 138.0581,
        "std": 40.7081,
        "min": 80.0,
        "max": 300.0,
        "median": 140.0,
        "skewness": 0.8217,
        "kurtosis": 1.7376
      },
      "_template": "descriptive_summary"
    }
  ]
}