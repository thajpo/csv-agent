{
  "dataset_columns": [
    "gender",
    "race/ethnicity",
    "parental level of education",
    "lunch",
    "test preparation course",
    "math score",
    "reading score",
    "writing score"
  ],
  "questions": [
    {
      "question": "Which numeric score column is the most skewed, and what are its mean, skewness, 95% confidence interval, bootstrap standard error, and number of bootstrap samples? Return as JSON with keys: column, skewness, mean, ci_lower, ci_upper, std_error, n_bootstrap.",
      "hint": "Calculate absolute skewness for each numeric column, select the one with the highest value, then use bootstrap resampling to estimate the mean, its confidence interval, and standard error.",
      "n_steps": 9,
      "difficulty": "VERY_HARD",
      "template_name": "bootstrap_ci_discovered",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 7 keys: \"column\" (name of most skewed column), \"skewness\" (rounded to 4 decimals), \"mean\" (rounded to 4 decimals), \"ci_lower\" (lower bound of 95% CI, rounded to 4 decimals), \"ci_upper\" (upper bound, rounded to 4 decimals), \"std_error\" (bootstrap standard error, rounded to 4 decimals), and \"n_bootstrap\" (integer, the number of bootstrap samples). Example: {\"column\": \"income\", \"skewness\": 2.3456, \"mean\": 50000.1234, \"ci_lower\": 48500.5678, \"ci_upper\": 51500.9012, \"std_error\": 750.3456, \"n_bootstrap\": 1000}",
      "ground_truth_hash": "08705dcfb5d04a20",
      "_ground_truth": {
        "column": "writing score",
        "skewness": 0.2894,
        "mean": 68.054,
        "ci_lower": 67.0962,
        "ci_upper": 68.9821,
        "std_error": 0.4863,
        "n_bootstrap": 1000
      },
      "_template": "bootstrap_ci_discovered"
    },
    {
      "question": "Does the test score with the greatest variability differ across student demographic groups? Return as JSON with keys: target_column, grouping_column, n_groups, f_statistic, p_value, significant, best_group, best_mean, worst_group, worst_mean, eta_squared.",
      "hint": "Find the numeric column with the highest variance, pick a categorical column that has between 3 and 10 unique values, then compare group means with a one\u2011way ANOVA and compute effect size.",
      "n_steps": 9,
      "difficulty": "VERY_HARD",
      "template_name": "anova_discovered_groups",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 11 keys: \"target_column\", \"grouping_column\", \"n_groups\" (integer), \"f_statistic\" (rounded to 4 decimals), \"p_value\" (rounded to 6 decimals), \"significant\" (boolean), \"best_group\" (category with highest mean), \"best_mean\" (rounded to 4 decimals), \"worst_group\" (category with lowest mean), \"worst_mean\" (rounded to 4 decimals), and \"eta_squared\" (effect size, rounded to 4 decimals). Example: {\"target_column\": \"sales\", \"grouping_column\": \"region\", \"n_groups\": 4, \"f_statistic\": 15.2345, \"p_value\": 0.000012, \"significant\": true, \"best_group\": \"West\", \"best_mean\": 1234.5678, \"worst_group\": \"East\", \"worst_mean\": 890.1234, \"eta_squared\": 0.1523}",
      "ground_truth_hash": "776985fff70a7574",
      "_ground_truth": {
        "target_column": "writing score",
        "grouping_column": "race/ethnicity",
        "n_groups": 5,
        "f_statistic": 7.1624,
        "p_value": 1.1e-05,
        "significant": "True",
        "best_group": "group E",
        "best_mean": 71.4071,
        "worst_group": "group A",
        "worst_mean": 62.6742,
        "eta_squared": 0.028
      },
      "_template": "anova_discovered_groups"
    },
    {
      "question": "Which numeric test score varies the most and is most strongly linked to another score, and how well does that relationship predict the target? Return as JSON with keys: target, best_predictor, correlation, r_squared, coefficient, p_value.",
      "hint": "Identify numeric columns, pick the one with highest variance as the target, compute absolute correlations with the others, choose the strongest, fit a simple OLS regression and report the statistics.",
      "n_steps": 8,
      "difficulty": "HARD",
      "template_name": "regression_most_predictive",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 6 keys: \"target\" (column name), \"best_predictor\" (column name), \"correlation\" (rounded to 3 decimals), \"r_squared\" (rounded to 4 decimals), \"coefficient\" (rounded to 4 decimals), and \"p_value\" (rounded to 6 decimals). Example: {\"target\": \"price\", \"best_predictor\": \"sqft\", \"correlation\": 0.834, \"r_squared\": 0.6956, \"coefficient\": 135.2847, \"p_value\": 0.000001}",
      "ground_truth_hash": "ca7a1a9e71f66d92",
      "_ground_truth": {
        "target": "writing score",
        "best_predictor": "reading score",
        "correlation": 0.955,
        "r_squared": 0.9113,
        "coefficient": 0.9935,
        "p_value": 0.0
      },
      "_template": "regression_most_predictive"
    },
    {
      "question": "Is there a significant difference in the most variable exam score between the two genders? Return as JSON with keys: target_column, grouping_column, group1, group2, mean1, mean2, t_statistic, p_value, significant.",
      "hint": "Identify the numeric column with the highest variance, choose a binary categorical column (like gender) for grouping, then compare group means with a t-test.",
      "n_steps": 8,
      "difficulty": "HARD",
      "template_name": "ttest_discovered_groups",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 9 keys: \"target_column\", \"grouping_column\", \"group1\", \"group2\", \"mean1\" (rounded to 4 decimals), \"mean2\" (rounded to 4 decimals), \"t_statistic\" (rounded to 4 decimals), \"p_value\" (rounded to 6 decimals), and \"significant\" (boolean, true if p < 0.05). Example: {\"target_column\": \"score\", \"grouping_column\": \"gender\", \"group1\": \"M\", \"group2\": \"F\", \"mean1\": 75.4321, \"mean2\": 78.1234, \"t_statistic\": -2.3456, \"p_value\": 0.019234, \"significant\": true}",
      "ground_truth_hash": "6ea026dfb845f916",
      "_ground_truth": {
        "target_column": "writing score",
        "grouping_column": "gender",
        "group1": "female",
        "group2": "male",
        "mean1": 72.4672,
        "mean2": 63.3112,
        "t_statistic": 9.9796,
        "p_value": 0.0,
        "significant": "True"
      },
      "_template": "ttest_discovered_groups"
    },
    {
      "question": "Which numeric score in the student dataset is closest to a normal distribution, and does it actually follow normality? Return as JSON with keys: column, ks_statistic, p_value, is_normal, sample_mean, sample_std.",
      "hint": "Identify the numeric column with the smallest absolute skewness, compute its mean and std, standardize the data, then perform a one\u2011sample Kolmogorov\u2011Smirnov test against a standard normal distribution.",
      "n_steps": 7,
      "difficulty": "MEDIUM",
      "template_name": "ks_normality_test",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 6 keys: \"column\" (tested column), \"ks_statistic\" (rounded to 4 decimals), \"p_value\" (rounded to 6 decimals), \"is_normal\" (boolean, true if p >= 0.05), \"sample_mean\" (rounded to 4 decimals), and \"sample_std\" (rounded to 4 decimals). Example: {\"column\": \"height\", \"ks_statistic\": 0.0456, \"p_value\": 0.234567, \"is_normal\": true, \"sample_mean\": 170.1234, \"sample_std\": 10.5678}",
      "ground_truth_hash": "203a7cfb88c4379e",
      "_ground_truth": {
        "column": "reading score",
        "ks_statistic": 0.0439,
        "p_value": 0.041308,
        "is_normal": "False",
        "sample_mean": 69.169,
        "sample_std": 14.6002
      },
      "_template": "ks_normality_test"
    },
    {
      "question": "Do the variances of the most variable test score differ between male and female students? Return as JSON with keys: target_column, grouping_column, n_groups, levene_statistic, p_value, variances_equal, group_variances.",
      "hint": "Find the numeric column with the highest variance, choose a categorical column with 2\u20116 groups (e.g., gender), compute each group's variance, and run Levene's test for equality of variances.",
      "n_steps": 7,
      "difficulty": "HARD",
      "template_name": "levene_variance_test",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 7 keys: \"target_column\", \"grouping_column\", \"n_groups\" (integer), \"levene_statistic\" (rounded to 4 decimals), \"p_value\" (rounded to 6 decimals), \"variances_equal\" (boolean, true if p >= 0.05), and \"group_variances\" (dict mapping group names to variance rounded to 4 decimals). Example: {\"target_column\": \"score\", \"grouping_column\": \"class\", \"n_groups\": 3, \"levene_statistic\": 2.3456, \"p_value\": 0.098765, \"variances_equal\": true, \"group_variances\": {\"A\": 123.4567, \"B\": 145.6789, \"C\": 112.3456}}",
      "ground_truth_hash": "9ce4ea134373ab27",
      "_ground_truth": {
        "target_column": "writing score",
        "grouping_column": "gender",
        "n_groups": 2,
        "levene_statistic": 0.0069,
        "p_value": 0.933627,
        "variances_equal": "True",
        "group_variances": {
          "female": 220.3693,
          "male": 199.2002
        }
      },
      "_template": "levene_variance_test"
    },
    {
      "question": "Do writing scores differ between genders? Return as JSON with keys: target_column, grouping_column, group1, group2, median1, median2, u_statistic, p_value.",
      "hint": "Find the numeric column with highest absolute skewness, then use the binary gender column to split the data and compare medians with a Mann\u2011Whitney U test.",
      "n_steps": 6,
      "difficulty": "MEDIUM",
      "template_name": "mann_whitney_u_test",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 8 keys: \"target_column\", \"grouping_column\", \"group1\", \"group2\", \"median1\" (rounded to 4 decimals), \"median2\" (rounded to 4 decimals), \"u_statistic\" (rounded to 2 decimals), and \"p_value\" (rounded to 6 decimals). Example: {\"target_column\": \"score\", \"grouping_column\": \"treatment\", \"group1\": \"control\", \"group2\": \"experimental\", \"median1\": 72.5000, \"median2\": 78.0000, \"u_statistic\": 1234.50, \"p_value\": 0.034567}",
      "ground_truth_hash": "d9e0478f6d6bc1a0",
      "_ground_truth": {
        "target_column": "writing score",
        "grouping_column": "gender",
        "group1": "female",
        "group2": "male",
        "median1": 74.0,
        "median2": 64.0,
        "u_statistic": 169956.5,
        "p_value": 0.0
      },
      "_template": "mann_whitney_u_test"
    },
    {
      "question": "Which two numeric score columns show the strongest monotonic relationship? Return as JSON with keys: columns, spearman_rho, p_value, interpretation.",
      "hint": "Calculate the Spearman correlation matrix for all numeric columns, set the diagonal to zero, and identify the pair with the highest absolute correlation.",
      "n_steps": 6,
      "difficulty": "MEDIUM",
      "template_name": "spearman_rank_correlation",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 4 keys: \"columns\" (list of 2 column names, alphabetically sorted), \"spearman_rho\" (correlation coefficient rounded to 4 decimals), \"p_value\" (rounded to 6 decimals), and \"interpretation\" (string: \"strong\", \"moderate\", \"weak\", or \"negligible\"). Example: {\"columns\": [\"age\", \"income\"], \"spearman_rho\": 0.7234, \"p_value\": 0.000001, \"interpretation\": \"strong\"}",
      "ground_truth_hash": "3074903bf96c2af6",
      "_ground_truth": {
        "columns": [
          "reading score",
          "writing score"
        ],
        "spearman_rho": 0.949,
        "p_value": 0.0,
        "interpretation": "strong"
      },
      "_template": "spearman_rank_correlation"
    },
    {
      "question": "Do the two most skewed score columns exhibit a stronger relationship after applying a log transformation? Return as JSON with keys: columns, original_correlation, log_correlation, improvement, transformation_helpful.",
      "hint": "Find the numeric columns with highest absolute skewness, compute their Pearson correlation, apply a log1p transform to both, recompute the correlation, and compare the absolute values.",
      "n_steps": 6,
      "difficulty": "HARD",
      "template_name": "correlation_change_analysis",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 5 keys: \"columns\" (list of 2 column names, alphabetically sorted), \"original_correlation\" (Pearson, rounded to 4 decimals), \"log_correlation\" (after log transform, rounded to 4 decimals), \"improvement\" (absolute difference, rounded to 4 decimals), and \"transformation_helpful\" (boolean, true if |log_corr| > |orig_corr|). Example: {\"columns\": [\"income\", \"spending\"], \"original_correlation\": 0.4567, \"log_correlation\": 0.7234, \"improvement\": 0.2667, \"transformation_helpful\": true}",
      "ground_truth_hash": "56169dc16ad83c78",
      "_ground_truth": {
        "columns": [
          "reading score",
          "writing score"
        ],
        "original_correlation": 0.9546,
        "log_correlation": 0.9586,
        "improvement": 0.004,
        "transformation_helpful": "True"
      },
      "_template": "correlation_change_analysis"
    },
    {
      "question": "Which numeric measurement shows the most spread and how many extreme values does it contain? Return as JSON with keys: column, q1, q3, iqr, lower_fence, upper_fence, n_outliers.",
      "hint": "Identify the numeric column with the highest variance, compute its Q1, Q3, IQR, lower/upper fences (1.5*IQR), and count observations outside the fences.",
      "n_steps": 5,
      "difficulty": "EASY",
      "template_name": "iqr_outlier_analysis",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 7 keys: \"column\" (analyzed column), \"q1\" (25th percentile rounded to 4 decimals), \"q3\" (75th percentile rounded to 4 decimals), \"iqr\" (rounded to 4 decimals), \"lower_fence\" (rounded to 4 decimals), \"upper_fence\" (rounded to 4 decimals), and \"n_outliers\" (integer count). Example: {\"column\": \"salary\", \"q1\": 45000.0000, \"q3\": 75000.0000, \"iqr\": 30000.0000, \"lower_fence\": 0.0000, \"upper_fence\": 120000.0000, \"n_outliers\": 23}",
      "ground_truth_hash": "5972f527434e4bea",
      "_ground_truth": {
        "column": "writing score",
        "q1": 57.75,
        "q3": 79.0,
        "iqr": 21.25,
        "lower_fence": 25.875,
        "upper_fence": 110.875,
        "n_outliers": 5
      },
      "_template": "iqr_outlier_analysis"
    },
    {
      "question": "Which measurement shows the greatest variability among students, and does its distribution appear normal? Return as JSON with keys: distribution, median, iqr.",
      "hint": "Identify the numeric column with highest variance, test normality (e.g., Shapiro\u2011Wilk), then report median and IQR for non\u2011normal data.",
      "n_steps": 5,
      "difficulty": "HARD",
      "template_name": "conditional_normality",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 3 keys. If normal: {\"distribution\": \"normal\", \"mean\": <number>, \"std\": <number>}. If non-normal: {\"distribution\": \"non-normal\", \"median\": <number>, \"iqr\": <number>}. The \"iqr\" value is Q3 minus Q1 as a single number. All numeric values rounded to 3 decimal places.",
      "ground_truth_hash": "91fde79bbd84c7d6",
      "_ground_truth": {
        "distribution": "non-normal",
        "median": 69.0,
        "iqr": 21.25
      },
      "_template": "conditional_normality"
    },
    {
      "question": "Which demographic group tends to have the highest average score on the most variable subject? Return as JSON with keys: category_column, best_category, target_column, mean_value.",
      "hint": "Identify the numeric column with the largest variance, then calculate its mean for each categorical column and select the category with the highest mean.",
      "n_steps": 5,
      "difficulty": "HARD",
      "template_name": "category_highest_target_mean",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 4 keys: \"category_column\" (the grouping column name), \"best_category\" (the category value with highest mean), \"target_column\" (the numeric column analyzed), and \"mean_value\" (rounded to 3 decimal places). Example: {\"category_column\": \"region\", \"best_category\": \"West\", \"target_column\": \"sales\", \"mean_value\": 1234.567}",
      "ground_truth_hash": "0aa523e1addc6020",
      "_ground_truth": {
        "category_column": "gender",
        "best_category": "female",
        "target_column": "writing score",
        "mean_value": 72.467
      },
      "_template": "category_highest_target_mean"
    },
    {
      "question": "Which two numeric scores are most strongly related, and does removing extreme outliers change that relationship? Return as JSON with keys: columns, original_correlation, outliers_removed, clean_correlation.",
      "hint": "Calculate absolute correlations among numeric columns, identify the highest pair, filter out rows beyond 3\u202fstd devs for both columns, then recalculate the correlation.",
      "n_steps": 5,
      "difficulty": "HARD",
      "template_name": "correlation_after_outlier_removal",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 4 keys: \"columns\" (list of 2 column names, alphabetically sorted), \"original_correlation\" (rounded to 3 decimals), \"outliers_removed\" (integer count), and \"clean_correlation\" (rounded to 3 decimals). Example: {\"columns\": [\"col_a\", \"col_b\"], \"original_correlation\": 0.847, \"outliers_removed\": 12, \"clean_correlation\": 0.891}",
      "ground_truth_hash": "05ff4bdea54b8b1e",
      "_ground_truth": {
        "columns": [
          "reading score",
          "writing score"
        ],
        "original_correlation": 0.955,
        "outliers_removed": 5,
        "clean_correlation": 0.952
      },
      "_template": "correlation_after_outlier_removal"
    },
    {
      "question": "How many of the numeric measurements contain extreme values, and what is the total number of such outliers? Return as JSON with keys: columns_with_outliers, total_outliers.",
      "hint": "Identify outliers as points farther than 3 standard deviations from the mean for each numeric column, then count columns with any outliers and sum all outlier occurrences.",
      "n_steps": 4,
      "difficulty": "MEDIUM",
      "template_name": "count_outlier_columns",
      "template_params": {
        "z_threshold": 3.0
      },
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 2 keys: \"columns_with_outliers\" (integer count of columns containing at least one outlier) and \"total_outliers\" (integer total count of outlier values across all columns). Example: {\"columns_with_outliers\": 3, \"total_outliers\": 47}",
      "ground_truth_hash": "457331f5b1818d68",
      "_ground_truth": {
        "columns_with_outliers": 3,
        "total_outliers": 12
      },
      "_template": "count_outlier_columns"
    },
    {
      "question": "I wonder how many of the numeric score columns contain extreme values and what the total number of such outliers is. Return as JSON with keys: columns_with_outliers, total_outliers.",
      "hint": "Flag values that lie more than 2.5 standard deviations from the mean in each numeric column, then count columns with any outliers and sum all outlier occurrences.",
      "n_steps": 4,
      "difficulty": "MEDIUM",
      "template_name": "count_outlier_columns",
      "template_params": {
        "z_threshold": 2.5
      },
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 2 keys: \"columns_with_outliers\" (integer count of columns containing at least one outlier) and \"total_outliers\" (integer total count of outlier values across all columns). Example: {\"columns_with_outliers\": 3, \"total_outliers\": 47}",
      "ground_truth_hash": "71969c629fd0f690",
      "_ground_truth": {
        "columns_with_outliers": 3,
        "total_outliers": 32
      },
      "_template": "count_outlier_columns"
    },
    {
      "question": "Which numeric test score has the highest relative variability among students? Return as JSON with keys: column, cv, mean, std.",
      "hint": "Calculate the coefficient of variation (std/mean*100) for each numeric column and pick the one with the largest value.",
      "n_steps": 4,
      "difficulty": "EASY",
      "template_name": "coefficient_of_variation",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 4 keys: \"column\" (name of column with highest CV), \"cv\" (coefficient of variation as percentage rounded to 2 decimals), \"mean\" (rounded to 4 decimals), and \"std\" (rounded to 4 decimals). Example: {\"column\": \"price\", \"cv\": 45.23, \"mean\": 1234.5678, \"std\": 558.4567}",
      "ground_truth_hash": "5edc4843156508a6",
      "_ground_truth": {
        "column": "math score",
        "cv": 22.94,
        "mean": 66.089,
        "std": 15.1631
      },
      "_template": "coefficient_of_variation"
    },
    {
      "question": "Which two numeric scores in the dataset are most strongly correlated? Return as JSON with keys: columns, correlation.",
      "hint": "Compute the absolute correlation matrix for numeric columns, identify the off\u2011diagonal pair with the highest value, and report the two column names (alphabetically) and that correlation rounded to three decimals.",
      "n_steps": 4,
      "difficulty": "MEDIUM",
      "template_name": "strongest_correlation",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly two keys: \"columns\" (a list of the two column names, alphabetically sorted) and \"correlation\" (the correlation coefficient rounded to 3 decimal places). Example: {\"columns\": [\"col_a\", \"col_b\"], \"correlation\": 0.847}",
      "ground_truth_hash": "f700884d56c19588",
      "_ground_truth": {
        "columns": [
          "reading score",
          "writing score"
        ],
        "correlation": 0.955
      },
      "_template": "strongest_correlation"
    },
    {
      "question": "Which two numeric test scores have the weakest correlation with each other? Return as JSON with keys: columns, correlation.",
      "hint": "Calculate the absolute correlation matrix for the numeric columns, ignore the diagonal, and find the pair with the smallest non\u2011zero correlation.",
      "n_steps": 4,
      "difficulty": "MEDIUM",
      "template_name": "weakest_correlation",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly two keys: \"columns\" (a list of the two column names, alphabetically sorted) and \"correlation\" (the absolute correlation value rounded to 3 decimal places). Example: {\"columns\": [\"col_a\", \"col_b\"], \"correlation\": 0.012}",
      "ground_truth_hash": "10b887e249d35065",
      "_ground_truth": {
        "columns": [
          "math score",
          "writing score"
        ],
        "correlation": 0.803
      },
      "_template": "weakest_correlation"
    },
    {
      "question": "Which measurement among the scores varies the most across students? Return as JSON with keys: result.",
      "hint": "Identify the numeric column with the highest variance, then calculate its mean.",
      "n_steps": 3,
      "difficulty": "MEDIUM",
      "template_name": "max_variance_mean",
      "template_params": null,
      "output_type": "scalar",
      "output_schema": "A single number (the mean), rounded to 3 decimal places",
      "ground_truth_hash": "6f38b316463e56af",
      "_ground_truth": 68.054,
      "_template": "max_variance_mean"
    },
    {
      "question": "Which numeric score has the lowest average and how much does it vary? Return as JSON with keys: std.",
      "hint": "Compute the mean of each numeric column, identify the smallest, then calculate its standard deviation.",
      "n_steps": 3,
      "difficulty": "MEDIUM",
      "template_name": "min_mean_column_std",
      "template_params": null,
      "output_type": "scalar",
      "output_schema": "A single number (the standard deviation), rounded to 3 decimal places",
      "ground_truth_hash": "4d47fa98fb024dc1",
      "_ground_truth": 15.163,
      "_template": "min_mean_column_std"
    },
    {
      "question": "Are there any columns in this student scores dataset that have a substantial amount of missing data (e.g., more than 5%)? Return as JSON with keys: count, columns.",
      "hint": "Compute the missing\u2011value percentage for each column and list those exceeding a 5% threshold.",
      "n_steps": 3,
      "difficulty": "EASY",
      "template_name": "count_high_missing_columns",
      "template_params": {
        "missing_threshold": 5.0
      },
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 2 keys: \"count\" (integer) and \"columns\" (list of column names, alphabetically sorted). Example: {\"count\": 3, \"columns\": [\"col_a\", \"col_b\", \"col_c\"]}",
      "ground_truth_hash": "2c42c4348e535666",
      "_ground_truth": {
        "count": 0,
        "columns": []
      },
      "_template": "count_high_missing_columns"
    },
    {
      "question": "Are there any features in this dataset that have a large proportion of missing values? Return as JSON with keys: count, columns.",
      "hint": "Calculate the missing\u2011value percentage for each column and count those above a 10% threshold.",
      "n_steps": 3,
      "difficulty": "EASY",
      "template_name": "count_high_missing_columns",
      "template_params": {
        "missing_threshold": 10.0
      },
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 2 keys: \"count\" (integer) and \"columns\" (list of column names, alphabetically sorted). Example: {\"count\": 3, \"columns\": [\"col_a\", \"col_b\", \"col_c\"]}",
      "ground_truth_hash": "2c42c4348e535666",
      "_ground_truth": {
        "count": 0,
        "columns": []
      },
      "_template": "count_high_missing_columns"
    },
    {
      "question": "Which numeric measurement varies the most across students? Return as JSON with keys: column, p10, p25, p50, p75, p90.",
      "hint": "Identify the numeric column with the greatest range, then calculate its 10th, 25th, 50th, 75th, and 90th percentiles.",
      "n_steps": 3,
      "difficulty": "EASY",
      "template_name": "percentile_ranking",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 6 keys: \"column\" (analyzed column), \"p10\" (10th percentile rounded to 4 decimals), \"p25\" (25th percentile), \"p50\" (median), \"p75\" (75th percentile), and \"p90\" (90th percentile). Example: {\"column\": \"income\", \"p10\": 25000.0000, \"p25\": 40000.0000, \"p50\": 55000.0000, \"p75\": 75000.0000, \"p90\": 100000.0000}",
      "ground_truth_hash": "5c3255252f7a243e",
      "_ground_truth": {
        "column": "math score",
        "p10": 47.0,
        "p25": 57.0,
        "p50": 66.0,
        "p75": 77.0,
        "p90": 86.0
      },
      "_template": "percentile_ranking"
    },
    {
      "question": "Which numeric measurement in the student scores dataset varies the most, and what are its key descriptive statistics? Return as JSON with keys: column, count, mean, std, min, max, median, skewness, kurtosis.",
      "hint": "Identify the numeric column with the highest variance, then compute its count, mean, standard deviation, min, max, median, skewness, and kurtosis.",
      "n_steps": 3,
      "difficulty": "EASY",
      "template_name": "descriptive_summary",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 9 keys: \"column\", \"count\" (integer), \"mean\" (rounded to 4 decimals), \"std\", \"min\", \"max\", \"median\", \"skewness\", and \"kurtosis\" (all rounded to 4 decimals). Example: {\"column\": \"age\", \"count\": 1000, \"mean\": 35.4567, \"std\": 12.3456, \"min\": 18.0000, \"max\": 85.0000, \"median\": 34.0000, \"skewness\": 0.5678, \"kurtosis\": -0.2345}",
      "ground_truth_hash": "d5cb4106ed86211f",
      "_ground_truth": {
        "column": "writing score",
        "count": 1000,
        "mean": 68.054,
        "std": 15.1957,
        "min": 10.0,
        "max": 100.0,
        "median": 69.0,
        "skewness": -0.2894,
        "kurtosis": -0.0334
      },
      "_template": "descriptive_summary"
    }
  ]
}