{
  "dataset_columns": [
    "State/UTs",
    "Total Cases",
    "Active",
    "Discharged",
    "Deaths",
    "Active Ratio",
    "Discharge Ratio",
    "Death Ratio",
    "Population"
  ],
  "questions": [
    {
      "question": "Which numeric variable with the greatest variability can be explained by a few other measurements, and how well do those predictors perform? Return as JSON with keys: target, predictors, r_squared, adj_r_squared, n_significant, coefficients, p_values.",
      "hint": "Identify numeric columns, choose the one with highest variance as the target, compute absolute correlations to find the three strongest predictors, fit an OLS regression and report the model statistics.",
      "n_steps": 10,
      "difficulty": "VERY_HARD",
      "template_name": "multiple_regression_top_predictors",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 6 keys: \"target\" (column name), \"predictors\" (list of 3 column names), \"r_squared\" (rounded to 4 decimals), \"adj_r_squared\" (rounded to 4 decimals), \"n_significant\" (integer count of predictors with p < 0.05), \"coefficients\" (dict mapping predictor names to coefficients rounded to 4 decimals), and \"p_values\" (dict mapping predictor names to p-values rounded to 6 decimals). Example: {\"target\": \"price\", \"predictors\": [\"sqft\", \"bedrooms\", \"age\"], \"r_squared\": 0.7234, \"adj_r_squared\": 0.7156, \"n_significant\": 2, \"coefficients\": {\"sqft\": 123.45, \"bedrooms\": 5000.12, \"age\": -200.34}, \"p_values\": {\"sqft\": 0.000001, \"bedrooms\": 0.023456, \"age\": 0.156789}}",
      "ground_truth_hash": "5b1579a58509c401",
      "_ground_truth": {
        "target": "Population",
        "predictors": [
          "Death Ratio",
          "Discharge Ratio",
          "Deaths"
        ],
        "r_squared": 0.0347,
        "adj_r_squared": -0.0558,
        "n_significant": 0,
        "coefficients": {
          "Death Ratio": -113901089.2376,
          "Discharge Ratio": -96793731.3464,
          "Deaths": -138.5886
        },
        "p_values": {
          "Death Ratio": 0.782031,
          "Discharge Ratio": 0.809399,
          "Deaths": 0.68211
        }
      },
      "_template": "multiple_regression_top_predictors"
    },
    {
      "question": "Which numeric column in the Covid-19 statewise dataset shows the greatest skewness, and what is its mean and 95% confidence interval using bootstrap resampling? Return as JSON with keys: column, skewness, mean, ci_lower, ci_upper, std_error, n_bootstrap.",
      "hint": "Identify numeric columns, compute absolute skewness for each, pick the highest, then bootstrap the mean to obtain the confidence interval and standard error.",
      "n_steps": 9,
      "difficulty": "VERY_HARD",
      "template_name": "bootstrap_ci_discovered",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 7 keys: \"column\" (name of most skewed column), \"skewness\" (rounded to 4 decimals), \"mean\" (rounded to 4 decimals), \"ci_lower\" (lower bound of 95% CI, rounded to 4 decimals), \"ci_upper\" (upper bound, rounded to 4 decimals), \"std_error\" (bootstrap standard error, rounded to 4 decimals), and \"n_bootstrap\" (integer, the number of bootstrap samples). Example: {\"column\": \"income\", \"skewness\": 2.3456, \"mean\": 50000.1234, \"ci_lower\": 48500.5678, \"ci_upper\": 51500.9012, \"std_error\": 750.3456, \"n_bootstrap\": 1000}",
      "ground_truth_hash": "e0bfbd7ebbc53c8f",
      "_ground_truth": {
        "column": "Active Ratio",
        "skewness": 5.9306,
        "mean": 0.005,
        "ci_lower": 0.0,
        "ci_upper": 0.0142,
        "std_error": 0.0044,
        "n_bootstrap": 1000
      },
      "_template": "bootstrap_ci_discovered"
    },
    {
      "question": "Is there a significant difference in the most variable numeric measurement between two groups formed by splitting another numeric feature at its median? Return as JSON with keys: target_column, grouping_column, group1, group2, mean1, mean2, t_statistic, p_value, significant.",
      "hint": "Identify the numeric column with the highest variance, create a binary grouping column by comparing another numeric column to its median, then compare the group means with a t-test.",
      "n_steps": 8,
      "difficulty": "HARD",
      "template_name": "ttest_discovered_groups",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 9 keys: \"target_column\", \"grouping_column\", \"group1\", \"group2\", \"mean1\" (rounded to 4 decimals), \"mean2\" (rounded to 4 decimals), \"t_statistic\" (rounded to 4 decimals), \"p_value\" (rounded to 6 decimals), and \"significant\" (boolean, true if p < 0.05). Example: {\"target_column\": \"score\", \"grouping_column\": \"gender\", \"group1\": \"M\", \"group2\": \"F\", \"mean1\": 75.4321, \"mean2\": 78.1234, \"t_statistic\": -2.3456, \"p_value\": 0.019234, \"significant\": true}",
      "ground_truth_hash": "3edc029940351a73",
      "_ground_truth": {
        "target_column": "Population",
        "grouping_column": "_binary_group",
        "group1": "low",
        "group2": "high",
        "mean1": 47228319.8889,
        "mean2": 32208895.6667,
        "t_statistic": 0.8894,
        "p_value": 0.38003,
        "significant": "False"
      },
      "_template": "ttest_discovered_groups"
    },
    {
      "question": "Which numeric measurement in the Covid\u201119 state data most closely follows a normal distribution? Return as JSON with keys: column, ks_statistic, p_value, is_normal, sample_mean, sample_std.",
      "hint": "Select the numeric column with the smallest absolute skewness, standardize its values, then run a Kolmogorov\u2011Smirnov test against a standard normal distribution.",
      "n_steps": 7,
      "difficulty": "MEDIUM",
      "template_name": "ks_normality_test",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 6 keys: \"column\" (tested column), \"ks_statistic\" (rounded to 4 decimals), \"p_value\" (rounded to 6 decimals), \"is_normal\" (boolean, true if p >= 0.05), \"sample_mean\" (rounded to 4 decimals), and \"sample_std\" (rounded to 4 decimals). Example: {\"column\": \"height\", \"ks_statistic\": 0.0456, \"p_value\": 0.234567, \"is_normal\": true, \"sample_mean\": 170.1234, \"sample_std\": 10.5678}",
      "ground_truth_hash": "3de997af5c0efd37",
      "_ground_truth": {
        "column": "Death Ratio",
        "ks_statistic": 0.1404,
        "p_value": 0.437281,
        "is_normal": "True",
        "sample_mean": 1.0978,
        "sample_std": 0.4948
      },
      "_template": "ks_normality_test"
    },
    {
      "question": "Does the most skewed numeric variable differ between states when grouped by a binary split of another measurement? Return as JSON with keys: target_column, grouping_column, group1, group2, median1, median2, u_statistic, p_value.",
      "hint": "Identify the numeric column with the highest absolute skewness, create a binary grouping based on the median of another numeric column, then compare the groups using a Mann\u2011Whitney U test.",
      "n_steps": 6,
      "difficulty": "MEDIUM",
      "template_name": "mann_whitney_u_test",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 8 keys: \"target_column\", \"grouping_column\", \"group1\", \"group2\", \"median1\" (rounded to 4 decimals), \"median2\" (rounded to 4 decimals), \"u_statistic\" (rounded to 2 decimals), and \"p_value\" (rounded to 6 decimals). Example: {\"target_column\": \"score\", \"grouping_column\": \"treatment\", \"group1\": \"control\", \"group2\": \"experimental\", \"median1\": 72.5000, \"median2\": 78.0000, \"u_statistic\": 1234.50, \"p_value\": 0.034567}",
      "ground_truth_hash": "a294aa62323fab3a",
      "_ground_truth": {
        "target_column": "Active Ratio",
        "grouping_column": "_binary_group",
        "group1": "low",
        "group2": "high",
        "median1": 0.0,
        "median2": 0.0,
        "u_statistic": 152.5,
        "p_value": 0.552453
      },
      "_template": "mann_whitney_u_test"
    },
    {
      "question": "Which pair of numeric variables in the Covid-19 statewise dataset exhibits the strongest monotonic relationship? Return as JSON with keys: columns, spearman_rho, p_value, interpretation.",
      "hint": "Calculate the absolute Spearman correlation matrix for all numeric columns, ignore the diagonal, and identify the pair with the highest correlation.",
      "n_steps": 6,
      "difficulty": "MEDIUM",
      "template_name": "spearman_rank_correlation",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 4 keys: \"columns\" (list of 2 column names, alphabetically sorted), \"spearman_rho\" (correlation coefficient rounded to 4 decimals), \"p_value\" (rounded to 6 decimals), and \"interpretation\" (string: \"strong\", \"moderate\", \"weak\", or \"negligible\"). Example: {\"columns\": [\"age\", \"income\"], \"spearman_rho\": 0.7234, \"p_value\": 0.000001, \"interpretation\": \"strong\"}",
      "ground_truth_hash": "2390238116ed3233",
      "_ground_truth": {
        "columns": [
          "Discharged",
          "Total Cases"
        ],
        "spearman_rho": 1.0,
        "p_value": 0.0,
        "interpretation": "strong"
      },
      "_template": "spearman_rank_correlation"
    },
    {
      "question": "I wonder how the relationship between the two most skewed numeric variables changes after a log transformation. Return as JSON with keys: columns, original_correlation, log_correlation, improvement, transformation_helpful.",
      "hint": "Identify the two numeric columns with the highest absolute skewness, compute their Pearson correlation, apply a log transform to both columns, recompute the correlation, and compare the absolute values.",
      "n_steps": 6,
      "difficulty": "HARD",
      "template_name": "correlation_change_analysis",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 5 keys: \"columns\" (list of 2 column names, alphabetically sorted), \"original_correlation\" (Pearson, rounded to 4 decimals), \"log_correlation\" (after log transform, rounded to 4 decimals), \"improvement\" (absolute difference, rounded to 4 decimals), and \"transformation_helpful\" (boolean, true if |log_corr| > |orig_corr|). Example: {\"columns\": [\"income\", \"spending\"], \"original_correlation\": 0.4567, \"log_correlation\": 0.7234, \"improvement\": 0.2667, \"transformation_helpful\": true}",
      "ground_truth_hash": "641fef21adf3ae54",
      "_ground_truth": {
        "columns": [
          "Deaths",
          "Total Cases"
        ],
        "original_correlation": 0.9446,
        "log_correlation": 0.8555,
        "improvement": 0.0891,
        "transformation_helpful": "False"
      },
      "_template": "correlation_change_analysis"
    },
    {
      "question": "Which numeric attribute in the COVID\u201119 state data shows the greatest spread, and how many extreme values does it contain? Return as JSON with keys: column, q1, q3, iqr, lower_fence, upper_fence, n_outliers.",
      "hint": "Find the numeric column with the highest variance, compute its 25th and 75th percentiles, derive the IQR and fences, then count data points outside those fences.",
      "n_steps": 5,
      "difficulty": "EASY",
      "template_name": "iqr_outlier_analysis",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 7 keys: \"column\" (analyzed column), \"q1\" (25th percentile rounded to 4 decimals), \"q3\" (75th percentile rounded to 4 decimals), \"iqr\" (rounded to 4 decimals), \"lower_fence\" (rounded to 4 decimals), \"upper_fence\" (rounded to 4 decimals), and \"n_outliers\" (integer count). Example: {\"column\": \"salary\", \"q1\": 45000.0000, \"q3\": 75000.0000, \"iqr\": 30000.0000, \"lower_fence\": 0.0000, \"upper_fence\": 120000.0000, \"n_outliers\": 23}",
      "ground_truth_hash": "c2bec8d2f250db9d",
      "_ground_truth": {
        "column": "Population",
        "q1": 1695472.75,
        "q3": 69799859.75,
        "iqr": 68104387.0,
        "lower_fence": -100461107.75,
        "upper_fence": 171956440.25,
        "n_outliers": 1
      },
      "_template": "iqr_outlier_analysis"
    },
    {
      "question": "Which numeric measurement in the COVID\u201119 state data shows the greatest variability, and does its distribution appear normal? Return as JSON with keys: distribution, median, iqr (or mean, std).",
      "hint": "Find the numeric column with the highest variance, test its normality using Shapiro\u2011Wilk (sample if large), then report median and IQR for non\u2011normal or mean and std for normal.",
      "n_steps": 5,
      "difficulty": "HARD",
      "template_name": "conditional_normality",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 3 keys. If normal: {\"distribution\": \"normal\", \"mean\": <number>, \"std\": <number>}. If non-normal: {\"distribution\": \"non-normal\", \"median\": <number>, \"iqr\": <number>}. The \"iqr\" value is Q3 minus Q1 as a single number. All numeric values rounded to 3 decimal places.",
      "ground_truth_hash": "aac8a071d49107bf",
      "_ground_truth": {
        "distribution": "non-normal",
        "median": 24100881.5,
        "iqr": 68104387.0
      },
      "_template": "conditional_normality"
    },
    {
      "question": "Which state/UT has the highest average value of the most variable numeric measurement? Return as JSON with keys: category_column, best_category, target_column, mean_value.",
      "hint": "Identify the numeric column with the largest variance, then compute its mean for each state/UT and select the state with the highest mean.",
      "n_steps": 5,
      "difficulty": "HARD",
      "template_name": "category_highest_target_mean",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 4 keys: \"category_column\" (the grouping column name), \"best_category\" (the category value with highest mean), \"target_column\" (the numeric column analyzed), and \"mean_value\" (rounded to 3 decimal places). Example: {\"category_column\": \"region\", \"best_category\": \"West\", \"target_column\": \"sales\", \"mean_value\": 1234.567}",
      "ground_truth_hash": "c170e26b2d9559d7",
      "_ground_truth": {
        "category_column": "State/UTs",
        "best_category": "Dadra and Nagar Haveli and Daman and Diu",
        "target_column": "Population",
        "mean_value": 231502578.0
      },
      "_template": "category_highest_target_mean"
    },
    {
      "question": "Which two numeric variables in the Covid-19 statewise data are most strongly correlated, and does that relationship change after removing extreme outliers? Return as JSON with keys: columns, original_correlation, outliers_removed, clean_correlation.",
      "hint": "Compute the absolute correlation matrix to find the top pair, filter out rows where either value is more than 3 standard deviations from its mean, then recalculate the correlation.",
      "n_steps": 5,
      "difficulty": "HARD",
      "template_name": "correlation_after_outlier_removal",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 4 keys: \"columns\" (list of 2 column names, alphabetically sorted), \"original_correlation\" (rounded to 3 decimals), \"outliers_removed\" (integer count), and \"clean_correlation\" (rounded to 3 decimals). Example: {\"columns\": [\"col_a\", \"col_b\"], \"original_correlation\": 0.847, \"outliers_removed\": 12, \"clean_correlation\": 0.891}",
      "ground_truth_hash": "54a514f19d89d43d",
      "_ground_truth": {
        "columns": [
          "Discharged",
          "Total Cases"
        ],
        "original_correlation": 1.0,
        "outliers_removed": 2,
        "clean_correlation": 1.0
      },
      "_template": "correlation_after_outlier_removal"
    },
    {
      "question": "Do any of the numeric measurements contain unusually extreme values that could be considered outliers? Return as JSON with keys: columns_with_outliers, total_outliers.",
      "hint": "For each numeric column, compare values to the mean \u00b1 3\u202f\u00d7\u202fstandard deviation, count outliers, then summarize how many columns have outliers and the total number of outlier entries.",
      "n_steps": 4,
      "difficulty": "MEDIUM",
      "template_name": "count_outlier_columns",
      "template_params": {
        "z_threshold": 3.0
      },
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 2 keys: \"columns_with_outliers\" (integer count of columns containing at least one outlier) and \"total_outliers\" (integer total count of outlier values across all columns). Example: {\"columns_with_outliers\": 3, \"total_outliers\": 47}",
      "ground_truth_hash": "012af027edb28fa8",
      "_ground_truth": {
        "columns_with_outliers": 6,
        "total_outliers": 8
      },
      "_template": "count_outlier_columns"
    },
    {
      "question": "How many numeric columns have extreme outlier values and what is the total count of those outliers? Return as JSON with keys: columns_with_outliers, total_outliers.",
      "hint": "For each numeric column, calculate mean and standard deviation, flag values farther than 2.5\u202f\u00d7\u202fstd from the mean, then count columns with any flags and sum all flagged values.",
      "n_steps": 4,
      "difficulty": "MEDIUM",
      "template_name": "count_outlier_columns",
      "template_params": {
        "z_threshold": 2.5
      },
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 2 keys: \"columns_with_outliers\" (integer count of columns containing at least one outlier) and \"total_outliers\" (integer total count of outlier values across all columns). Example: {\"columns_with_outliers\": 3, \"total_outliers\": 47}",
      "ground_truth_hash": "63307b609bae8fbd",
      "_ground_truth": {
        "columns_with_outliers": 8,
        "total_outliers": 10
      },
      "_template": "count_outlier_columns"
    },
    {
      "question": "Which numeric measurement in the dataset shows the greatest relative variability? Return as JSON with keys: column, cv, mean, std.",
      "hint": "Calculate the coefficient of variation (std/mean*100) for each numeric column and identify the one with the highest value.",
      "n_steps": 4,
      "difficulty": "EASY",
      "template_name": "coefficient_of_variation",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 4 keys: \"column\" (name of column with highest CV), \"cv\" (coefficient of variation as percentage rounded to 2 decimals), \"mean\" (rounded to 4 decimals), and \"std\" (rounded to 4 decimals). Example: {\"column\": \"price\", \"cv\": 45.23, \"mean\": 1234.5678, \"std\": 558.4567}",
      "ground_truth_hash": "5a759bebc7edf7f5",
      "_ground_truth": {
        "column": "Active Ratio",
        "cv": 533.45,
        "mean": 0.005,
        "std": 0.0267
      },
      "_template": "coefficient_of_variation"
    },
    {
      "question": "Which two numeric variables in the dataset are most strongly linearly related? Return as JSON with keys: columns, correlation.",
      "hint": "Compute the absolute correlation matrix, zero out the diagonal, and locate the pair with the maximum value.",
      "n_steps": 4,
      "difficulty": "MEDIUM",
      "template_name": "strongest_correlation",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly two keys: \"columns\" (a list of the two column names, alphabetically sorted) and \"correlation\" (the correlation coefficient rounded to 3 decimal places). Example: {\"columns\": [\"col_a\", \"col_b\"], \"correlation\": 0.847}",
      "ground_truth_hash": "c9e9cc430d33b5de",
      "_ground_truth": {
        "columns": [
          "Discharged",
          "Total Cases"
        ],
        "correlation": 1.0
      },
      "_template": "strongest_correlation"
    },
    {
      "question": "Which pair of numeric variables in the dataset have the weakest (non-zero) correlation? Return as JSON with keys: columns, correlation.",
      "hint": "Calculate the absolute correlation matrix, ignore the diagonal and zero values, then identify the minimum correlation pair.",
      "n_steps": 4,
      "difficulty": "MEDIUM",
      "template_name": "weakest_correlation",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly two keys: \"columns\" (a list of the two column names, alphabetically sorted) and \"correlation\" (the absolute correlation value rounded to 3 decimal places). Example: {\"columns\": [\"col_a\", \"col_b\"], \"correlation\": 0.012}",
      "ground_truth_hash": "9de545acc315d038",
      "_ground_truth": {
        "columns": [
          "Active Ratio",
          "Population"
        ],
        "correlation": 0.009
      },
      "_template": "weakest_correlation"
    },
    {
      "question": "Which numeric metric varies the most across the states and what is its average? Return as JSON with keys: mean.",
      "hint": "Identify the numeric column with the highest variance, then compute its mean.",
      "n_steps": 3,
      "difficulty": "MEDIUM",
      "template_name": "max_variance_mean",
      "template_params": null,
      "output_type": "scalar",
      "output_schema": "A single number (the mean), rounded to 3 decimal places",
      "ground_truth_hash": "a49b41b8201fdba3",
      "_ground_truth": 39718607.778,
      "_template": "max_variance_mean"
    },
    {
      "question": "Which numeric column has the lowest average, and what is its standard deviation? Return as JSON with key: std.",
      "hint": "Calculate the mean of each numeric column, find the column with the smallest mean, then compute its standard deviation.",
      "n_steps": 3,
      "difficulty": "MEDIUM",
      "template_name": "min_mean_column_std",
      "template_params": null,
      "output_type": "scalar",
      "output_schema": "A single number (the standard deviation), rounded to 3 decimal places",
      "ground_truth_hash": "44896291821a8010",
      "_ground_truth": 0.027,
      "_template": "min_mean_column_std"
    },
    {
      "question": "Are there any columns in the dataset that have a high proportion of missing values? Return as JSON with keys: count, columns.",
      "hint": "Calculate the percentage of missing values per column and count those exceeding a 5% threshold.",
      "n_steps": 3,
      "difficulty": "EASY",
      "template_name": "count_high_missing_columns",
      "template_params": {
        "missing_threshold": 5.0
      },
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 2 keys: \"count\" (integer) and \"columns\" (list of column names, alphabetically sorted). Example: {\"count\": 3, \"columns\": [\"col_a\", \"col_b\", \"col_c\"]}",
      "ground_truth_hash": "2c42c4348e535666",
      "_ground_truth": {
        "count": 0,
        "columns": []
      },
      "_template": "count_high_missing_columns"
    },
    {
      "question": "Are there any columns in the dataset that have a high proportion of missing values? Return as JSON with keys: count, columns.",
      "hint": "Calculate the missing percentage for each column, compare against a 10% threshold, then count and list columns exceeding it.",
      "n_steps": 3,
      "difficulty": "EASY",
      "template_name": "count_high_missing_columns",
      "template_params": {
        "missing_threshold": 10.0
      },
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 2 keys: \"count\" (integer) and \"columns\" (list of column names, alphabetically sorted). Example: {\"count\": 3, \"columns\": [\"col_a\", \"col_b\", \"col_c\"]}",
      "ground_truth_hash": "2c42c4348e535666",
      "_ground_truth": {
        "count": 0,
        "columns": []
      },
      "_template": "count_high_missing_columns"
    },
    {
      "question": "Which numeric attribute varies the most across Indian states, and what are its key percentile values? Return as JSON with keys: column, p10, p25, p50, p75, p90.",
      "hint": "Find the numeric column with the largest range, then compute its 10th, 25th, 50th, 75th, and 90th percentiles.",
      "n_steps": 3,
      "difficulty": "EASY",
      "template_name": "percentile_ranking",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 6 keys: \"column\" (analyzed column), \"p10\" (10th percentile rounded to 4 decimals), \"p25\" (25th percentile), \"p50\" (median), \"p75\" (75th percentile), and \"p90\" (90th percentile). Example: {\"column\": \"income\", \"p10\": 25000.0000, \"p25\": 40000.0000, \"p50\": 55000.0000, \"p75\": 75000.0000, \"p90\": 100000.0000}",
      "ground_truth_hash": "f853d22dc951c0b1",
      "_ground_truth": {
        "column": "Population",
        "p10": 716008.0,
        "p25": 1695472.75,
        "p50": 24100881.5,
        "p75": 69799859.75,
        "p90": 96299548.0
      },
      "_template": "percentile_ranking"
    },
    {
      "question": "Which numeric column in the COVID\u201119 statewise dataset shows the greatest variability, and what are its key descriptive statistics? Return as JSON with keys: column, count, mean, std, min, max, median, skewness, kurtosis.",
      "hint": "Identify the numeric column with the highest variance, then compute its count, mean, standard deviation, min, max, median, skewness, and kurtosis.",
      "n_steps": 3,
      "difficulty": "EASY",
      "template_name": "descriptive_summary",
      "template_params": null,
      "output_type": "dict",
      "output_schema": "A JSON object with exactly 9 keys: \"column\", \"count\" (integer), \"mean\" (rounded to 4 decimals), \"std\", \"min\", \"max\", \"median\", \"skewness\", and \"kurtosis\" (all rounded to 4 decimals). Example: {\"column\": \"age\", \"count\": 1000, \"mean\": 35.4567, \"std\": 12.3456, \"min\": 18.0000, \"max\": 85.0000, \"median\": 34.0000, \"skewness\": 0.5678, \"kurtosis\": -0.2345}",
      "ground_truth_hash": "746392f8a7ba6871",
      "_ground_truth": {
        "column": "Population",
        "count": 36,
        "mean": 39718607.7778,
        "std": 50509132.9597,
        "min": 66001.0,
        "max": 231502578.0,
        "median": 24100881.5,
        "skewness": 1.9207,
        "kurtosis": 4.7137
      },
      "_template": "descriptive_summary"
    }
  ]
}